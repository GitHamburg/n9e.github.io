[
  {
    "content": " 采用Docker Compose做编排，用于单机快速启动环境做测试，包含了MySQL、Redis、Prometheus、Ibex、Nightingale、Telegraf\n 从Github下载夜莺的源码，进入docker目录，执行docker-compose up -d即可，docker-compose会自动拉取镜像并启动，查看各个容器启动状态，使用命令docker-compose ps，都是Up状态则表示启动成功，如果ibex、nserver、nwebapi等模块一直在Restarting，可能是数据库容器启动太慢了没有准备好，可以执行docker-compose down停掉再重新尝试启动测试：\nulric@mac.home:~/workspace/gopath/src/n9e/docker$ docker-compose up -d Creating network \"docker_nightingale\" with driver \"bridge\" Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done ulric@mac.home:~/workspace/gopath/src/n9e/docker$ docker-compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u003e10090/tcp, 0.0.0.0:20090-\u003e20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u003e3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u003e19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u003e18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u003e9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u003e6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u003e8092/udp, 0.0.0.0:8094-\u003e8094/tcp, 0.0.0.0:8125-\u003e8125/udp 更多docker-compose相关知识请参考官网\nWarning启动成功之后，建议把initsql目录下的内容挪走，这样下次重启的时候，DB就不会重新初始化了。否则下次启动mysql还是会自动执行initsql下面的sql文件导致DB重新初始化，页面上创建的规则、用户等都会丢失\n 服务启动之后，浏览器访问nwebapi的端口，即18000，默认用户是root，密码是root.2020\n",
    "description": "",
    "tags": null,
    "title": "使用Docker Compose快速部署",
    "uri": "/quickstart/compose/"
  },
  {
    "content": "姿势一：只是把Nightingale作为WEBUI 只部署n9e-webapi和n9e-server，配合Prometheus以及各类Exporter，可以在夜莺WEBUI上查看监控数据，配置监控大盘，配置告警规则、屏蔽规则、订阅规则，查看活跃告警、历史告警。且各类配置可以按照业务组拆分归组，相互之间没有影响。\n说只是作为WEBUI，其实不止，这种工作模式实际是替换掉了Prometheus内置的告警引擎+alertmanager，只需用Prometheus存时序数据，用Exporter抓取数据即可。\n姿势二：使用Telegraf替代各类Exporter Telegraf是个all-in-one的架构，一个二进制可以搞定机器、网络设备、中间件、数据库、Statsd等各种采集能力，相比散落的各类Exporter而言，维护成本更低一些，Telegraf支持通过OpenTSDB这个output plugin来对接夜莺。\n此时就可以解锁夜莺的对象管理能力，因为Telegraf采集的数据，会流经n9e-server，n9e-server就可以从监控数据中解析出监控对象信息（标签中的ident或host，就表示监控对象标识），知道最近有哪些监控对象在上报数据，哪些监控对象已经失联了，就可以顺道做NODATA逻辑。\n对象管理页面中，可以给监控对象打标签，这些标签会附到相关时序数据上，即：某个对象如果打了bg=cloud标签，这个对象有监控数据上报的时候，比如上报了cpu_usage_idle的监控数据，系统就可以从监控数据中解析出ident，然后根据ident找到页面上打的标签，然后把标签附到时序数据上。\n过半的监控数据其实都可以关联到某个监控对象，看图的时候先找到监控对象，再查监控数据是个挺顺畅的路径，所以，这就是对象视角看图页面的设计初衷，用了Telegraf，也就可以解锁使用这个页面的功能了。\n姿势三：使用VictoriaMetrics替换Prometheus时序存储 因为Prometheus时序存储是单机版，对于大规模场景，推荐使用VictoriaMetrics或者M3DB，因为M3DB有些复杂，一般建议使用VictoriaMetrics，VictoriaMetrics和Prometheus的查询接口完全兼容，所以夜莺也可以对接VictoriaMetrics，通过Prometheus协议的查询接口来查询VictoriaMetrics的数据。\n 所以大规模集群环境建议的组合方式是Nightingale+Telegraf+VictorMetrics，简称NTVM，如果是规模不大，组合方式是Nightingale+Telegraf+Prometheus，简称NTP，如果Telegraf的采集能力在某些场景下不足，可以用对应场景的Exporter来补齐。\n",
    "description": "",
    "tags": null,
    "title": "使用夜莺的的几种实践姿势",
    "uri": "/best-practice/fccloud-usage/"
  },
  {
    "content": "如果您对Docker的使用非常熟悉，建议利用Docker compose的方式快速启动测试，请参考使用Docker Compose快速部署，如果对Docker不熟悉，那就用二进制方式部署，也非常简单，最小的可运行环境是Prometheus+MySQL+Redis+Nightingale，请参考快速在生产环境部署启动单机版。这个最小的环境只有Prometheus采集到的自身的一些监控指标，略显单薄，此时，我们可以引入Telegraf，采集机器、网络设备、各类中间件的指标，请参考使用Telegraf采集监控数据。\n如果公司体量很大，建议把单机版本的Prometheus替换为VictoriaMetrics，请参考使用VictoriaMetrics作为时序库。或者直接部署多个Prometheus，按照业务线或者按照地域来划分集群，此时你可能需要接入多个Prom/VM/M3DB集群，在引入多个TSDB的过程中，就要同步使用夜莺的多Server部署模型了，请参考生产环境部署高可用集群版\n",
    "description": "",
    "tags": null,
    "title": "安装部署",
    "uri": "/quickstart/"
  },
  {
    "content": " 本节讲述如何部署单机版，单机版对于很多中小公司足够用了，简单高效、快速直接，建议使用云主机，性能不够了直接升配，可以应对每秒上报的数据点小于100万的情形，如果只是监控机器（每台机器每个周期大概采集200个数据点）采集周期频率设置10秒的话，支撑上限是5万台\n 如果仅仅是为了快速测试，Docker部署方式是最快的，不过很多朋友未必有Docker环境，另外为了减少引入更多技术栈，增强生产环境稳定性，有些朋友可能也不愿意用Docker，那本篇就来讲解如何快速部署单机版，单机版的配套时序库是使用Prometheus。如果要监控的机器有几千台，服务有几百个，单机版的容量无法满足，可以上集群版，集群版的时序库建议使用VictoriaMetrics，也可以使用M3DB，不过M3DB的架构更复杂，很多朋友无法搞定，选择简单的VictoriaMetrics，对大部分公司来讲，足够用了。我们先来看一下服务端架构：\n 核心模块server：server是用来做告警的，会从数据库中同步告警规则，然后读取Prometheus的数据做告警判断。server也可以接收监控数据上报，然后通过remote write协议写入多个时序库。server也依赖redis，用redis存储了server本身以及监控对象的心跳信息 核心模块webapi：提供restful api，用于和前端JavaScript交互，把一些用户配置类的信息写入mysql，鉴权采用jwt，jwt的token使用redis存储，在单机部署的方式下，server的redis和webapi的redis可以复用  环境准备 依赖的组件有：mysql、redis、prometheus，这三个组件都是开源软件，请大家自行安装，其中prometheus在启动的时候要注意开启 --enable-feature=remote-write-receiver 这里也提供一个小脚本来安装这3个组件，大家可以参考：\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service  cat \u003c\u003cEOF \u003e/etc/systemd/system/prometheus.service [Unit] Description=\"prometheus\" Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \"SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\" # install redis yum install -y redis systemctl enable redis systemctl restart redis 上例中mysql的root密码设置为了1234，建议维持这个不变，后续就省去了修改配置文件的麻烦。\n安装夜莺组件 mkdir -p /opt/n9e \u0026\u0026 cd /opt/n9e tarball=n9e-5.0.0-ga-05.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.0.0-ga-05/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u003c docker/initsql/n9e.sql nohup ./n9e server \u0026\u003e server.log \u0026 nohup ./n9e webapi \u0026\u003e webapi.log \u0026 # check logs # check port 如果启动成功，server默认会监听在19000端口，webapi会监听在18000端口，且日志没有报错。上面使用nohup简单演示，生产环境建议用systemd托管，相关service文件可以在etc/service目录下找到。\n配置文件etc/server.conf和etc/webapi.conf中都含有mysql的连接地址配置，检查一下用户名和密码，prometheus如果使用上面的脚本安装，默认会监听本机9090端口，server.conf和webapi.conf中的prometheus相关地址都不用修改就是对的。\n好了，浏览器访问webapi的端口（默认是18000）就可以体验相关功能了，默认用户是root，密码是root.2020。如果安装过程出现问题，可以参考 视频教程\n接下来，你可能需要：\n 安装Telegraf采集更多监控数据  ",
    "description": "",
    "tags": null,
    "title": "快速在生产环境部署启动单机版",
    "uri": "/quickstart/standalone/"
  },
  {
    "content": " Telegraf 是 InfluxData 开源的一款采集器，可以采集操作系统、各种中间件的监控指标，采集目标列表，看起来是非常丰富，Telegraf是一个大一统的设计，即一个二进制可以采集CPU、内存、mysql、mongodb、redis、snmp等，不像Prometheus的exporter，每个监控对象一个exporter，管理起来略麻烦。一个二进制分发起来确实比较方便。\n 这里提供快速安装的教程，Telegraf的更多知识，请参考Telegraf官网，笔者之前也写了一个Telegraf调研笔记，大家亦可参考。\nTelegraf下载地址在这里，根据自己的平台选择对应的二进制下载即可。笔者的环境是CentOS，下面是安装脚本，/opt/telegraf/telegraf.conf 是一个经过删减的干净的配置文件，指定了opentsdb output plugin，这个plugin的写入地址配置的是n9e-server，所以，Telegraf采集的数据会被推送给n9e-server，二者贯通：\n#!/bin/sh  version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u003c\u003cEOF \u003e /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false [[outputs.opentsdb]] host = \"http://127.0.0.1\" port = 19000 http_batch_size = 50 http_path = \"/opentsdb/put\" debug = false separator = \"_\" [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\", \"iso9660\", \"overlay\", \"aufs\", \"squashfs\"] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\"uptime_format\"] [[inputs.net]] ignore_protocol_stats = true EOF cat \u003c\u003cEOF \u003e /etc/systemd/system/telegraf.service [Unit] Description=\"telegraf\" After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  Warning/opt/telegraf/telegraf.conf的内容是个删减版，只是为了让大家快速跑起来，如果要采集更多监控对象，比如mysql、redis、tomcat等，还是要仔细去阅读从tarball里解压出来的那个配置文件，那里有很详细的注释，也可以参考官方提供的各个采集插件下的README\n 网友分享  Telegraf的Linux版安装分享 Telegraf的Windows版安装分享  ",
    "description": "",
    "tags": null,
    "title": "使用Telegraf采集监控数据",
    "uri": "/quickstart/telegraf/"
  },
  {
    "content": " VictoriaMetrics 架构简单，可靠性高，在性能，成本，可扩展性方面表现出色，社区活跃，且和 Prometheus 生态绑定紧密。夜莺推荐您在生产环境中使用 VictoriaMetrics 作为时序数据库。\n VictoriaMetrics 提供单机版和集群版。如果您的每秒写入数据点数小于100万，VictoriaMetrics 官方默认推荐您使用单机版，单机版可以通过增加服务器的CPU核心数，增加内存，增加IOPS来获得线性的性能提升。且单机版易于配置和运维。\n接下来的文章，介绍在夜莺中，以 VictoriaMetrics 集群版本作为时序数据库为例，完整的安装和配置过程。\nvmstorage、vminsert、vmselect 三者组合构成 VictoriaMetrics 的集群功能，三者都可以通过启动多个实例来分担承载流量。\n vmstorage 是数据存储模块：\n  其数据保存在-storageDataPath指定的目录中，默认为./vmstorage-data/，vmstorage 是有状态模块，删除 storage node 会丢失约 1/N的历史数据（N 为集群中 vmstorage node 的节点数量）。增加 storage node，则需要同步修改 vminsert 和 vmselect 的启动参数，将新加入的storage node节点地址通过命令行参数 -storageNode传入给vminsert和vmselect。 vmstorage 启动后，会监听三个端口，分别是 -httpListenAddr :8482、-vminsertAddr :8400、-vmselectAddr :8401。端口8400负责接收来自 vminsert 的写入请求，端口8401负责接收来自 vmselect 的数据查询请求，端口8482则是 vmstorage 自身提供的 http api 接口。   vminsert 接收来自客户端的数据写入请求，并负责转发到选定的vmstorage：\n  vminsert 接收到数据写入请求后，按照 jump consistent hash 算法，将数据转发到选定的某个vmstorage node 上。vminsert 本身是无状态模块，可以增加或者删除一个或多个实例，而不会造成数据的损失。vminsert 模块通过启动时的参数 -storageNode xxx,yyy,zzz 来感知到整个 vmstorage 集群的完整 node 地址列表。 vminsert 启动后，会监听一个端口-httpListenAddr :8480。该端口实现了 prometheus remote_write协议，因此可以接收和解析通过 remote_write 协议写入的数据。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8480/insert/\u003caccount_id\u003e/prometheus/api/v1/write。 更多 URL Format 可以参考 VictoriaMetrics官网。   vmselect 接收来自客户端的数据查询请求，并负责转发到所有的 vmstorage 查询结果并合并：\n  vmselect 启动后，会监听一个端口-httpListenAddr :8481。该端口实现了 prometheus remote_query等协议，因此可以接收和解析 remote_query 协议的查询。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8481/select/\u003caccount_id\u003e/prometheus/api/v1/query。 更多 URL Format 可以参考 VictoriaMetrics官网。  下载和安装 VictoriaMetrics 集群版  去 vm release 下载编译好的二进制版本，比如我们选择下载 v1.69.0 amd64。 解压缩后得到：  $ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  启动三个 vmstorage 实例(可以用下面的脚本快速生成不同实例的启动命令)：  #!/bin/bash  for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\"\" fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\"nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath\\ -httpListenAddr :$httpListenAddr\\ -vminsertAddr :$vminsertAddr\\ -vmselectAddr :$vmselectAddr\\ \u0026\u003e ${pp}vmstor.log \u0026\" echo $prog (exec \"$prog\") done 也可以输入以下命令行启动三个实例：\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026\u003e vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026\u003e 1vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026\u003e 2vmstor.log \u0026  启动一个 vminsert 实例：  nohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026\u003evminsert.log \u0026  启动一个 vmselect 实例：  nohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026\u003evmselect.log \u0026  查看 vmstorage，vminsert，vmselect 的 /metrics 接口:  curl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  n9e-server通过remote write接口写入时序库，vm作为时序库的一个选择，其remote write接口地址为：http://127.0.0.1:8480/insert/0/prometheus/api/v1/write 把这个地址配置到server.conf当中即可，配置完了重启n9e-server  [[Writers]] Name = \"vm\" Url = \"http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\"  修改您的 n9e-webapi 的配置文件 ./etc/webapi.conf 如下：  [[Clusters]] # Prometheus cluster name Name = \"Default\" # Prometheus APIs base url Prom = \"http://127.0.0.1:8481/select/0/prometheus\" 然后，重新启动n9e-webapi，这样夜莺就可以通过 remote query 查询到 victoriametrics 集群的数据了。\nInfon9e-webapi 的安装、配置和启动，请参考 这里。\n FAQ  VictoriaMetrics 单机版本如何保障数据的可靠性？  vm 针对磁盘IO有针对性的优化，单机版可以考虑将数据的可靠性保障交给 EBS 等云盘来保证。\n  VictoriaMetrics 如何评估容量？  参考vm的官方文档。\n  VictoriaMetrics 集群版本增加或者删除vmstorage Node的时候，数据如何再平衡？  vm 不支持扩缩容节点时，对数据进行自动的再平衡。\n  VictoriaMetrics 的数据大小如何查看？  可以通过 vmstorage 实例暴露的 /metrics 接口来获取到相应的统计数据，譬如：\n $ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\"indexdb\"} 609291 vm_data_size_bytes{type=\"storage/big\"} 0 vm_data_size_bytes{type=\"storage/small\"} 8749893  vminsert 在将数据写入多个 vmstorage Node的时候，是按照什么规则将数据写入到不同的 node 上的？  采用jump consistent hash 对数据进行分片，写入到相应的storage node上。\n  vmselect 在接到查询请求的时候，如何定位到请求的数据是在哪个 storage node上的？  vmselect 并不知道每个metrics对应的数据分布的storage node，vmselect会对所有的storage node发起查询请求，最后进行数据合并，并返回。\n  VictoriaMetrics 和 M3db 的对比和选择？  m3db架构设计上更高级，实现难度高，m3db在时序数据功能之后，重点解决了自动扩缩容，数据自动平衡等运维难题。但是因此也更复杂，可靠性目前也更难保证。VictoriaMetrics架构设计上的tradeoff 更倾向于简单可靠，重点优化了单机版的性能，强调垂直扩展，同时和prometheus 生态做到兼容，甚至于在很多的点上做到了加强。但是 VictoriaMetrics 对于时序数据downsample，节点的自动扩缩容，数据自动再平衡等高级功能和分布式能力，是有缺失的。\n   相关资料  使用 Docker Compose 快速部署 VictoriaMetrics。 使用 Helm Chart 快速在 Kubernetes中部署 VictoriaMetrics。 使用 VictoriaMetrics Operator 在 Kubernetes中部署 VictoriaMetrics。 VictoriaMetrics 集群版架构：   ",
    "description": "",
    "tags": null,
    "title": "使用VictoriaMetrics作为时序库",
    "uri": "/quickstart/victoriametrics/"
  },
  {
    "content": "由于Prometheus没有集群版本，受限于容量问题，很多公司会搭建多套Prometheus，比如按照业务拆分，不同的业务使用不同的Prometheus集群，或者按照地域拆分，不同的地域使用不同的Prometheus集群。这里是以Prometheus来举例，VictoriaMetrics、M3DB都有集群版本，不过有时为了不相互干扰和地域网络问题，也会拆成多个集群。对于多集群的协同，需要在夜莺里做一些配置，架构图如下：\n比如，我们有两个时序库，在北京搭建了一个Prometheus，在广州搭建了一个VictoriaMetrics，n9e-webapi会把这两个时序库作为DataSource，所以在n9e-webapi的配置文件中，要配置上这俩存储的地址，举例：\n[[Clusters]] # cluster name Name = \"Prom-Beijing\" # Prometheus APIs base url Prom = \"http://10.2.3.4:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 [[Clusters]] # cluster name Name = \"VM-Guangzhou\" # Prometheus APIs base url Prom = \"http://172.21.0.8:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 另外图上也可以看出，一个n9e-server对应一个时序库，所以在n9e-server的配置文件中，也需要配置对应的时序库的地址，比如北京的server，配置如下，Writers下面的Url配置的是remote write的地址，而Reader下面配置的Url是实现Prometheus原生查询接口的BaseUrl\n[Reader] # prometheus base url Url = \"http://127.0.0.1:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Name = \"prom\" Url = \"http://127.0.0.1:9090/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 上海区域用的是VictoriaMetrics，所以Url略有不同，配置如下：\n[Reader] # prometheus base url Url = \"http://127.0.0.1:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Name = \"vm\" Url = \"http://127.0.0.1:8480/insert/0/prometheus/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 n9e-webapi是要响应前端ajax请求的，前端会从n9e-webapi查询监控数据，n9e-webapi自身不存储监控数据，而是仅仅做了一个代理，把请求代理给后端的时序库，前端读取数据时会调用Prometheus的那些原生接口，即：/api/v1/query /api/v1/query_range /api/v1/labels 这种接口，所以注意啦，n9e-webapi中配置的Clusters下面的Url，都是要支持Prometheus原生接口的BaseUrl。\n对于n9e-server，有两个重要作用，一个是接收监控数据，然后转发给后端多个Writer，所以，Writer可以配置多个，配置文件是toml格式，[[Writers]]双中括号这种就表示数组，数据写给后端存储，走的协议是Prometheus的Remote Write，所以，所有支持Remote Write的存储，都可以使用。n9e-server的另一个重要作用，是做告警判断，会周期性从mysql同步告警规则，然后根据用户配置的Promeql调用时序库的 query 接口，所以n9e-server的Reader下面的Url，也是要配置支持Prometheus原生接口的BaseUrl。另外注意，Writer可以配置多个，但是Reader只能配置一个。比如监控数据可以写一份到Prometheus存储近期数据用于告警判断，再写一份到OpenTSDB存储长期数据，Writer就可以配置为Prometheus和OpenTSDB这两个，而Reader只配置Prometheus即可。\n",
    "description": "",
    "tags": null,
    "title": "接入多个Prom/VM/M3DB集群",
    "uri": "/quickstart/multitsdb/"
  },
  {
    "content": "对于规模相对较小的公司，比如几百台机器这个体量，个人认为单机版足够用了，使用云主机部署，性能不足可以直接升配，存储使用云存储保证，硬件故障云平台也会自动把虚拟机热迁移走，非常省心。那如果咱们体量确实比较大，或者没有云主机这种基础设施，这里会讲解集群版的部署方式。\n单中心，单集群，接入公司所有数据 首先，来讲解一种普适性比较高的架构方式，就是单中心大集群模式。比如某公司，虽然有3个机房，但是相互之间有专线打通，链路很好，为了便于维护，倾向于在中心搭建一套监控集群，其他机房的机器上只需要部署监控客户端（推荐Telegraf）即可，架构图如下：\n图中时序库使用Prometheus表示，当然，也可以选用VictoriaMetrics或者M3DB等，n9e-server部署了3台机器，n9e-webapi也部署了3台机器，当然，可以混部，即一台机器上既部署n9e-server，也部署n9e-webapi，监控客户端Telegraf要上报监控数据所以要调用n9e-server的接口，为了高可用，可以在n9e-server前面架设负载均衡，比如LVS，Telegraf的output plugin配置vip即可。负责与前端交互的n9e-webapi也部署了多个，为了高可用也是在前面架设负载均衡，这样终端用户访问的时候，也是访问vip，某个n9e-webapi如果挂掉，负载均衡可以自动感知并摘除，用户无感。\n图中redis画了两个，n9e-webapi依赖一个redis，n9e-server也依赖一个redis，在单中心、单集群模式下，可以复用一个redis。redis采用的是标准版，非集群版、非Sentinel版，这点大家要注意。\n多套存储，多套server集群，单套webapi集群 在接入多个Prom/VM/M3DB集群一节中，介绍了夜莺可以接入多个时序库，在夜莺的架构中，时序库和n9e-server是一一对应的，每接入一套时序库，就一定要部署一套n9e-server，所谓的这一套n9e-server，可以是单实例模式，也可以是多实例模式。\n比如在北京机房部署了一套Prometheus时序库，就需要在北京机房部署一套n9e-server，在广州机房部署了一套VictoriaMetrics，就需要在广州机房也部署一套n9e-server，每套n9e-server都要对应一个redis，此时，ne9-server的redis不建议与n9e-webapi的redis复用（虽然从原理上也支持），建议n9e-server的redis部署到n9e-server所在的机房，避免机房割裂时n9e-server连不上redis。\n",
    "description": "",
    "tags": null,
    "title": "生产环境部署高可用集群版",
    "uri": "/quickstart/clusters/"
  },
  {
    "content": "要说业务组这个概念，可能要先聊聊机器分组的设计，之前为此专门写过一篇公众号文章《设计篇-监控系统机器分组设计，你是我的知音么？》，建议感兴趣的朋友读一读。反正最终，以现在的认知来看，用标签来做机器分组是最合适的，虽然标签没有那么直观，但是足够灵活，再佐以业务组这个设计，做相关筛选的时候，先用业务组做第一层筛选，后面再用标签来筛，标签不够直观这个缺点可以被大大的规避。\n再说各种规则，比如告警规则、屏蔽规则、订阅规则，这些规则如果没有一种归组管理方式，就是全公司的规则都平铺到一个表格里，会显得非常混乱。比如我是某个业务线的研发人员，我肯定就关心自己业务线的那些规则，才不想看到别的业务线的规则呢。所以我们需要一个规则分组机制，类似一个namespace的东西，来对这些规则分个组。\n再就是权限，这些告警规则、监控对象、自愈脚本等，谁可以修改维护？总得关联到具体的一些人上。对于某个产品的相关规则、监控对象等，是由一批相同的人来维护的，所以抽象一个业务组这样的概念，把这些资产都归到这个业务组里，也方便配置权限。另外就是告警自愈以及机器上跑脚本，这个动作比较危险，要好好控制权限，机器隶属业务组，业务组有管理人员，这种管理模式相对比较简单清晰。\n综上，我们设计了业务组这个概念，夜莺中的各种实体大都是归到业务组的，比如监控对象、各类规则、自愈脚本等，业务组一般是一个自闭环的组织，他们自己管理自己的机器设备，自己管理自己的告警规则，跟其他的业务组没什么交集。举个例子，比如公司的DBA团队，管理了公司的所有mysql数据库以及相关的机器，这种就可以单独建立一个业务组；再比如基础网络的同学，管理了公司所有的网络设备，跟其他业务线关系不大，就可以建立一个专门的业务组，放置网络设备监控对象，以及相关的告警规则。\n当然了，公司也可能有个统一的运维团队，管理所有的告警规则，普通研发人员都不会去创建告警规则，这种情况，这个统一的运维团队可以创建一个业务组，比如叫infra，放置公司所有的监控对象，配置告警规则。其他各个团队，可以创建自己的业务组，然后订阅infra的告警规则（订阅可以跨业务组订阅），每个业务团队创建的业务组里只有订阅规则，与其他业务组隔离，比较清晰较为容易管理。\n 对于监控对象，只要有监控数据上报，n9e-server就会自动从监控对象中解析到ident标签，取其值当做监控对象，注册到mysql监控对象这个表里。刚注册上来的监控对象是未归组的，此时应该由Admin角色的人去把这些监控对象做分配，分配给不同的业务组，分完之后，各个业务组的人就自己玩自己的就好了。\n业务组的人，对于刚刚分配过来的监控对象设备，建议首先做的事情，就是打上一个bg的标签，比如bg=cloud表示相关的监控对象都隶属cloud这个Business Group。未来这些监控对象告警了，告警事件中会自动带上bg=cloud这个标签，收报警的人就可以立刻知道这是哪个bg的监控对象。\n",
    "description": "",
    "tags": null,
    "title": "探讨业务组的设计和最佳实践",
    "uri": "/best-practice/busi-group-design/"
  },
  {
    "content": "概述 所谓的告警自愈，典型手段是在告警触发时自动回调某个webhook地址，在这个webhook里写告警自愈的逻辑，夜莺默认支持这种方式。另外，夜莺还可以更进一步，配合ibex这个模块，在告警触发的时候，自动去告警的机器执行某个脚本，这种机制可以大幅简化构建运维自愈链路的工作量，毕竟，不是所有的运维人员都擅长写http server，但所有的运维人员，都擅长写脚本。这种方式是典型的物理机时代的产物，希望各位朋友用不到这个工具（说明贵司的IT技术已经走得非常靠前了）。\n架构 ibex模块，类似之前夜莺v3版本中的job模块，可以批量执行脚本，其架构非常简单，包括server和agentd两个模块，agentd周期性调用server的rpc接口，询问有哪些任务要执行，如果有分配给自己的任务，就从server拿到任务脚本信息，在本地fork一个进程运行，然后将结果上报给服务端。为了简化部署，server和agentd融合成了一个二进制，就是ibex，通过传入不同的参数来启动不同的角色。ibex架构图如下：\n项目地址  Git仓库：https://gitee.com/cnperl/ibex Linux安装包：http://49.233.250.79/ibex-1.0.0.tar.gz 其他环境的包需要自行编译，编译方法参考这里  安装启动 下载安装包之后，解压缩，在etc下可以找到服务端和客户端的配置文件，在sql目录下可以找到初始化sql脚本。\n初始化sql mysql \u003c sql/ibex.sql 启动server server的配置文件是etc/server.conf，注意修改里边的mysql连接地址，配置正确的mysql用户名和密码。然后就可以直接启动了：\nnohup ./ibex server \u0026\u003e server.log \u0026 ibex没有web页面，只提供api接口，鉴权方式是http basic auth，basic auth的用户名和密码默认都是ibex，在etc/server.conf中可以找到，如果ibex部署在互联网，一定要修改默认用户名和密码，当然，因为n9e要调用ibex，所以n9e的server.conf和webapi.conf中也配置了ibex的basic auth账号信息，要改就要一起改啦。\n启动agentd 客户端的配置非常非常简单，agentd.conf内容如下：\n# debug, release RunMode = \"release\" # task meta storage dir MetaDir = \"./meta\" [HTTP] Enable = true # http listening address Host = \"0.0.0.0\" # http listening port Port = 2090 # https cert file path CertFile = \"\" # https key file path KeyFile = \"\" # whether print access log PrintAccessLog = true # whether enable pprof PProf = false # http graceful shutdown timeout, unit: s ShutdownTimeout = 30 # max content length: 64M MaxContentLength = 67108864 # http server read timeout, unit: s ReadTimeout = 20 # http server write timeout, unit: s WriteTimeout = 40 # http server idle timeout, unit: s IdleTimeout = 120 [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\"10.2.3.4:20090\"] # $ip or $hostname or specified string Host = \"telegraf01\" 客户端的HTTP接口用处不大，可以把Enable设置为false，关闭监听，重点关注Heartbeat这个部分，Interval是心跳频率，默认是1000毫秒，如果机器量比较小，比如小于1000台，维持1000没问题，如果机器量比较大，可以适当调大这个频率，比如2000或者3000，可以减轻服务端的压力。Servers是个数组，配置的是ibex-server的地址，ibex-server可以启动多个，多个地址都配置到这里即可，Host这个字段，是本机的唯一标识，有三种配置方式，如果配置为$ip，系统会自动探测本机的IP，如果是$hostname，系统会自动探测本机的hostname，如果是其他字符串，那就直接把该字符串作为本机的唯一标识。每个机器上都要部署ibex-agentd，不同的机器要保证Host字段获取的内容不能重复。\n另外，Telegraf的配置文件中，有下面这么一段：\n[agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false 其中hostname默认留空，表示自动探测本机的hostname，如果写了具体的某个字符串，那就把写的那个字符串作为监控数据的host字段的内容，这个hostname字段要和ibex的agentd.conf中的Host字段保持一致，典型的做法有：\n Telegraf中把hostname配置为空，Telegraf自动获取本机hostname，ibex的Host配置为$hostname，ibex也会自动获取本机hostname，这样Telegraf和ibex可以获取到相同的标识内容 Telegraf中手工把hostname配置为本机的ip，ibex则把Host配置为$ip，这样二者也可以获取到相同的标识内容 Telegraf和ibex都使用某个特定写死的字符串来作为标识信息，这样也OK，但是要保证不同的机器，这个字符串不能重复  下面是启动ibex-agentd的命令：\nnohup ./ibex agentd \u0026\u003e agentd.log \u0026 另外，细心的读者应该会发现ibex的压缩包里的etc目录下有个service目录，里边准备好了两个service样例文件，便于大家使用systemd来管理ibex进程，生产环境，建议使用systemd来管理。\n",
    "description": "",
    "tags": null,
    "title": "告警自愈依赖的脚本下发执行模块",
    "uri": "/quickstart/ibex/"
  },
  {
    "content": " 本节讲述Nightingale的源码编译方式，分前后端两部分。另外，如果用到告警自愈模块，会用到ibex这个模块，本节也会一并讲解ibex模块的编译方法\n 后端 Nightingale后端采用Go语言编写，编译的前置条件就是配置Go的开发环境。\n配置Go环境 到Go官网选择对应的版本下载，我的环境是Linux，选择的go1.17.3.linux-amd64.tar.gz，直接下载到/root目录下了，然后解压缩，即Go的内容都放到了/root/go目录下了。同时准备gopath目录，如下：\ncd /root \u0026\u0026 mkdir -p gopath/src echo \"GOROOT=/root/go\" \u003e\u003e .bash_profile echo \"GOPATH=/root/gopath\" \u003e\u003e .bash_profile echo 'export PATH=$GOROOT/bin:$GOPATH/bin:$PATH' \u003e\u003e .bash_profile source .bash_profile 编译n9e git clone https://github.com/didi/nightingale.git # 国内配置一下代理，可以加速编译 export GOPROXY=https://goproxy.cn # 执行编译 cd n9e \u0026\u0026 make 编译完成之后如果生成二进制：n9e，就表示编译成功！想要快速入门Go语言？可以参考GOCN的资料！\n编译ibex 如果需要告警自愈能力，夜莺依赖ibex做命令下发执行，ibex的编译和n9e几乎一模一样，如下：\ngit clone https://gitee.com/cnperl/ibex.git # 国内配置一下代理，可以加速编译 export GOPROXY=https://goproxy.cn # 执行编译 cd ibex \u0026\u0026 make 编译完成之后如果生成二进制：ibex，就表示编译成功！\n前端 git clone https://github.com/n9e/fe-v5.git cd fe-v5 git checkout v5.1 npm install npm run build ",
    "description": "",
    "tags": null,
    "title": "源码编译夜莺前后端及告警自愈模块",
    "uri": "/quickstart/compile/"
  },
  {
    "content": "从夜莺5.1版本开始，摒弃了之前数据PUSH型的告警规则，完全使用PromQL来触发告警，相比之前确实灵活了很多，不过学习成本会略高一丢丢，权衡之下，我们认为这是值得的。下面用几条简单的PromQL来入门一下PromQL的用法，至于更多使用知识，请参考Prometheus官网\n需求1：客户端失联告警\ntarget_up == 0 target_up是夜莺自动生成的一个监控指标，用于监控采集客户端是否存活，如果采集客户端在持续上报监控数据，target_up的值就是1，如果采集客户端不再上报监控数据了，这个指标的值就变成0了，所以，PromQL如上配置，即可在监控客户端失联的时候告警，为了防止网络抖动的情况，或临时restart进程，告警规则里，持续时长一般配置为60秒，给出一定的容错周期。\n监控数据和监控客户端是如何关联的呢？就看监控数据中的ident标签，或host标签，如果有这俩标签中的一个，系统就认为这个监控数据是跟某个监控客户端相关的，就认为在这一时刻，监控客户端是活着的。\n需求2：对整机的CPU空闲率告警\nCPU空闲率的指标是cpu_usage_idle，我们直接用promql查询这个指标，可以看到，有很多Label，比如：cpu=\"cpu0\"说明这个监控指标标识的是0号cpu的数据，我们要处理整机的CPU空闲率，应该用这个Label：cpu=\"cpu-total\"\ncpu_usage_idle{cpu=\"cpu-total\"} \u003c 25 上面的promql只是指定了cpu=\"cpu-total\"这一个标签，没有指定是哪个机器，那就表示对所有机器生效，任何一台机器的CPU空闲率小于25就告警。\n 简单的PromQL一般就是指定metric，然后在{}中指定筛选标签，和之前夜莺的告警配置规则是一个道理，但是PromQL远不止可以做这些，还可以做很多更复杂的表达式计算，更多知识请参考：Prometheus官网\n 下面是一条Prometheus的告警规则，对照这条规则，咱们看一下是怎么对应到夜莺的功能的。\ngroups: - name: example # 报警规则组的名字 rules: - alert: InstanceDown # 检测job的状态，持续1分钟metrices不能访问会发给altermanager进行报警 expr: up == 0 for: 1m # 持续时间，表示持续一分钟获取不到信息，则触发报警 labels: severity: danger # 自定义标签 annotations: summary: \"Instance {{ $labels.instance }} down\" # 自定义摘要  description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than  groups.name，报警规则组的名称，有点像是夜莺里的业务组的概念 alert，表示告警规则名称，和夜莺里的规则名称类似 expr，是一条promql表达式，和夜莺的告警规则里的promql对应 for，对应夜莺告警规则里的持续时长 labels，对应夜莺告警规则里的附加标签 annotations，夜莺没有这个概念，夜莺在处理发送内容时，会有统一的几个模板来生成告警内容 evaluation_interval，这个是在Prometheus的global段的配置，表示规则执行频率，对应夜莺规则里的执行频率  当然，夜莺的告警规则还有一些其他配置，比如：\n 规则备注：未来发送告警消息的时候，会把备注信息带上 告警级别：默认分了3个级别，夜莺把告警级别做成一个单独的字段了，如果是Prometheus生态的话，做成标签即可 生效集群：夜莺可以接入多个Prometheus、VictoriaMetrics、M3DB集群，所以，告警规则具体是生效到哪个集群，需要有个配置指定 预案链接：每一条触发的告警，都应该对应一个预案，这是最佳实践，所以告警规则里可以指定预案链接，发送告警消息的时候也可以带上 生效配置：控制该调告警规则是否生效，如果生效，具体是在哪些时间点生效 通知媒介：配置告警发送的时候是发邮件、还是发钉钉、发企业微信等 告警接收组：配置告警通知的时候，通知哪些人，配置成组相当比较好管理，比如某人离职，只要从组里移除即可，不需要修改每条告警规则 启用恢复通知：一般告警的时候会发一条通知，恢复的时候也可以发一条通知，如果只想收告警，不想收恢复，可以在这里关闭 重复发送频率：即通道静默时间，告警发出之后，如果一直没有恢复，过xx时间之后，会重复通知 回调地址：可以配置多个webhook地址，告警之后，会依次调用，POST方式，把告警事件内容序列化为JSON，放到POST Body中，webhook对应的逻辑就可以从中解析出告警事件，做一些自动化处理逻辑  ",
    "description": "",
    "tags": null,
    "title": "告警规则",
    "uri": "/usage/alert-rule/"
  },
  {
    "content": "临时屏蔽部分告警通知 屏蔽规则，是针对告警事件的，大家在生成的告警事件中可以看到每个事件有很多标签，屏蔽规则就是针对这些标签配置过滤规则，满足过滤规则的，就不生成告警事件了。\n比如，我想屏蔽所有设备失联的告警，把标签key配置为：__name__，运算符：==，标签value：target_up即可。运算符=~表示正则，针对标签value，可以填写正则表达式，匹配一批的告警事件。运算符in表示数组包含的关系，即value可以配置多个。\n系统整体维护关掉所有通知 比如在某个时间段，全公司要做整体维护，预知会生成大量告警事件，就想把所有告警都先不发送，就只生成事件便于后面留档排查。这种情况不好做屏蔽规则，毕竟，不同的告警事件，标签很多都不一样。提供一个简单办法，把notify.py临时改个名字，这样n9e-server发送的时候就找不到这个脚本了，于是就没法发送了，此时页面上仍然可以看到告警事件。\n",
    "description": "",
    "tags": null,
    "title": "屏蔽规则",
    "uri": "/usage/alert-mute/"
  },
  {
    "content": "某个告警除了某个组的人关心，可能其他人也关心，就配置订阅规则，比如K8S平台的运维人员要作为告警接收人来接收所有K8S的告警，但是K8S的一些重大网络故障会影响整个K8S集群上面的业务方，上层业务也会关心这类告警，此时业务方就可以订阅K8S集群的部分重大告警。\n对于订阅规则，还有一种场景，比如运维团队管理了公司所有的告警规则，比如内存利用率的告警，不同业务线的人只关心自己的，那不同业务线的人就可以通过订阅规则，只订阅自己业务线的机器的告警。只需简单的为这批机器打上业务线标签，就可以通过这些标签做过滤。\n当然，有的公司推行DevOps文化，自己的狗粮自己吃，自己的服务自己运维，我这个业务线关心哪些告警，就自己创建一个业务组，配置相关策略，跟别的业务线没有任何关系，也不需要由特定的某个团队帮我配置，这样也是可以的，不同公司文化不同，组织架构职能分工不同，大家就根据自己的公司情况来规划即可。\n不过，从性能上讲，建议多使用订阅规则，让整体的告警规则变少，因为告警规则每次判断，都要查询时序库，如果告警规则量很大，对时序库的压力是很大的。当然，对性能的影响也没有那么夸张，把这个信息透传给大家，大家自行把握就好。\n",
    "description": "",
    "tags": null,
    "title": "订阅规则",
    "uri": "/usage/alert-subscribe/"
  },
  {
    "content": "告警通知媒介，是说发告警的时候，发送邮件、钉钉、企微之类的，夜莺默认提供的就是这三种，在告警规则配置的时候，可以勾选想通过什么方式发送。页面上的选项，来自webapi.conf的配置文件，NotifyChannels这个配置项，所以，如果想扩展一种新的通知媒介，就要修改这个配置了。比如我们加上一个新的发送方式，叫feishu，即，把NotifyChannels设置为：NotifyChannels = [ \"email\", \"dingtalk\", \"wecom\", \"feishu\" ]，页面上就能看到feishu这个选项了。\n虽然这里加了新的通知媒介，用户可以勾选了，但是没有具体的处理逻辑也没有用，为了便于扩展，夜莺在etc/script目录下放置了一个notify.py，告警通知最终都是通过这个脚本发送的，如果我们想加入feishu的发送逻辑，那就要修改这个脚本。这个脚本总共不超过200行，还是比较容易理解的。\n原理上来讲，告警判断是n9e-server这个模块负责的，n9e-server生成告警事件之后，会把告警事件序列化为JSON，然后调用notify.py，调用脚本的时候，会把告警事件那个大JSON，传给这个notify.py的标准输入，作为脚本的一个输入信息。剩下的就交由这个脚本了。如果夜莺处理过告警发送了，会在夜莺的启动目录下找到一个.payload的隐藏文件，这个文件的内容就是n9e-server序列化的JSON内容，相当于n9e-server先生成了.payload文件，然后调用 ./etc/script/notify.py \u003c .payload 所以，如果大家发现脚本工作不正常，可以用这个命令做测试。\n这种方式，大家可以修改notify.py，非常非常灵活，想加入一些新的通知媒介，或者想和自己的系统做一些打通工作，都非常简单。这个设计其实从夜莺5.0版本就引入了，反馈最多的几个问题如下，这里也做一一解答：\n1. n9e-server报错找不到这个文件\n通常是因为启动路径不对，要去夜莺的etc目录的同级目录启动n9e-server，如果是用systemd托管的就要把WorkingDirectory配对。\n2. python找不到requests库\n在5.0版本的时候，调用微信、钉钉的接口，都是用的requests这个库，所以需要手工提前安装一下。不过从5.1开始，就不用这个库了，用了内置的urllib2，减少外部依赖。\n3. python找不到bottle库\n在5.0版本的时候，告警事件作为JSON传给notify.py，notify.py要发送邮件、钉钉等，需要拼接发送的内容，拼接发送内容的过程中，用到了模板库，bottle是个模板库，为了减少外部依赖，5.1版本做了新的设计，发送内容的拼接不再放在notify.py里了，由n9e-server来做。etc/template目录下放置了多个模板文件（大家想扩展新的模板的话，直接在这个目录下新增即可，以.tpl作为文件后缀），每次n9e-server调用notify.py的时候，都会调用这些模板文件，把告警事件的各个字段传入，拼成具体的通知消息。这些通知消息也会放到序列化的那个大JSON中传给notify.py。我们在notify.py中可以看到这么一行代码：mail_body = payload.get('tpls').get(\"mailbody.tpl\", \"mailbody.tpl not found\")，这就是从JSON中获取n9e-server提前拼好的邮件内容。\n",
    "description": "",
    "tags": null,
    "title": "多种告警通知媒介的支持",
    "uri": "/usage/alert-notify/"
  },
  {
    "content": "本节并无太多要讲的内容，菜单里的【活跃告警】，就是列出了当前所有的未恢复活跃告警，如果某个告警恢复了，就会自动从这个列表中删除，这个页面还是蛮重要的，可以作为日常巡检的一项，每天上下班的时候都看一下，看看哪些事件还没恢复，漏了处理。\n活跃告警可以删除，这个操作比较危险，一定要弄明白原理。通常情况下，我们是无需手工删除的，比如cpu_usage_idle告警了，会自动创建一条告警事件，当cpu_usage_idle的值恢复了，即这条告警变成恢复状态了，系统就会自动从活跃告警中删除，所以，通常情况下，就让系统自动处理就好了。\n但是，如果某个指标的标签发生变化，或者机器下线，相关的告警就再也无法恢复了，这个不好理解，详细解释一下：\n指标标签发生变化\n比如这个告警规则：cpu_usage_idle{cpu=\"cpu-total\"} \u003c 25，拿着这个promql去promdash查询，得到的结果可以看到，有cpu和ident两个标签，ident表示的监控对象，此时，如果我们去对象管理页面，修改这个监控对象的标签，后面新上报的监控数据，就会自动打上新标签，继续拿着刚才的promql去promdash查询，会发现表格里很快会出现新的记录，和之前的记录并存，从时序库的角度来看，就是多了一条新的series。\n就相当于：之前有个series告警了，还没恢复呢，又来了一个新的series，老的series不再上报监控数据，所以老的告警事件就永远都不会恢复了。当然，我们可以调整一下这个promql，忽略掉其他的额外的标签，比如avg(cpu_usage_idle{cpu=\"cpu-total\"}) by (ident)，这样一来，即使在监控对象的页面修改了标签，这个新的promql永远都只有ident这一个标签，因为这个新的promql是根据ident做了聚合。虽然标签稳定了，但是本人不推荐大家这么做，这样做了之后，cpu=\"cpu-total\"这个标签就丢了。\n机器下线\n比如某个机器的某个指标报警了，比如内存利用率的一个指标，还没恢复呢，这个机器下线了，上面的客户端也不再上报监控数据了，那这个告警事件就永远都不会消失了，这种情况，我们知道是怎么回事，就可以手工删除对应的告警事件。省的放那没用，还碍眼。\n 另外，左侧的业务组旁边，带有一个数字徽章，表示的是这个业务组下的活跃告警数量，这种方式可以让我们快速知道哪个业务组下的告警规则触发了及其活跃事件数量。\n",
    "description": "",
    "tags": null,
    "title": "当前告警活跃事件",
    "uri": "/usage/alert-cur-event/"
  },
  {
    "content": "相比【活跃告警】，【历史告警】数量更多，会把恢复状态的消息也存档展示，用处不是很大，主要是留档查问题用的，这个表的数量增加会比较快，大家要经常关注一下，如果表的数量很多，比如超过100万，建议做一下清理，量太大的话会影响告警处理的速度，因为每一条告警事件都要往这个表里插入。\n",
    "description": "",
    "tags": null,
    "title": "全部历史告警事件",
    "uri": "/usage/alert-his-event/"
  },
  {
    "content": "部署了Telegraf即可采集到常见的监控指标了，Telegraf具体使用前面有章节介绍了，这里不再赘述，这里主要提供常见大盘配置和告警规则配置的JSON，便于大家快速上手。\nLinux操作系统监控大盘 [ { \"name\": \"Linux基本监控指标-Telegraf采集\", \"tags\": \"HOST\", \"configs\": \"{\\\"var\\\":[{\\\"name\\\":\\\"host\\\",\\\"definition\\\":\\\"label_values(mem_free, ident)\\\"}]}\", \"chart_groups\": [ { \"name\": \"Default chart group\", \"weight\": 0, \"charts\": [ { \"configs\": \"{\\\"name\\\":\\\"整机CPU空闲率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"cpu_usage_idle{cpu=\\\\\\\"cpu-total\\\\\\\", ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":35,\\\"yplotline2\\\":15,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"asc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":0,\\\"i\\\":\\\"0\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"内存可用率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mem_available_percent{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":30,\\\"yplotline2\\\":15,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"asc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":0,\\\"i\\\":\\\"1\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"硬盘利用率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"disk_used_percent{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":87,\\\"yplotline2\\\":92,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":0,\\\"i\\\":\\\"2\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"IO.UTIL(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(diskio_io_time{ident=\\\\\\\"$host\\\\\\\"}[1m])/10\\\"}],\\\"yplotline1\\\":90,\\\"yplotline2\\\":null,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":2,\\\"i\\\":\\\"3\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"网卡每分钟丢包数（个）\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"increase(net_drop_in{ident=\\\\\\\"$host\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"net_drop_in ident:{{ident}} interface:{{interface}}\\\"},{\\\"PromQL\\\":\\\"increase(net_drop_out{ident=\\\\\\\"$host\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"net_drop_out ident:{{ident}} interface:{{interface}}\\\"}],\\\"yplotline1\\\":5,\\\"yplotline2\\\":20,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":2,\\\"i\\\":\\\"4\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"TCP_TIME_WAIT数量\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"netstat_tcp_time_wait{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":null,\\\"yplotline2\\\":20000,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":2,\\\"i\\\":\\\"5\\\"}}\", \"weight\": 0 } ] } ] } ] Linux操作系统常用告警规则 [ { \"name\": \"有地址PING不通，请注意\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"ping_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"有监控对象失联\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"target_up != 1\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"有端口探测失败，请注意\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"net_response_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"机器负载-CPU较高，请关注\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"cpu_usage_idle{cpu=\\\"cpu-total\\\"} \u003c 25\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"机器负载-内存较高，请关注\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"mem_available_percent \u003c 25\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"硬盘-IO非常繁忙\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"rate(diskio_io_time[1m])/10 \u003e 99\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"硬盘-预计再有4小时写满\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"predict_linear(disk_free[1h], 4*3600) \u003c 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网卡-入向有丢包\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"increase(net_drop_in[1m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网卡-出向有丢包\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"increase(net_drop_out[1m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网络连接-TME_WAIT数量超过2万\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"netstat_tcp_time_wait \u003e 20000\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-有进程数为0，某进程可能挂了\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_lookup_running == 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-进程句柄限制过小\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_rlimit_num_fds_soft \u003c 2048\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-采集失败\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_lookup_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] } ] Grafana大盘 笔者做了一个Grafana大盘：https://grafana.com/grafana/dashboards/15365使用Telegraf做采集、Prometheus做数据源、Nightingale生成的target_up指标来标识机器是否up，欢迎试用\n",
    "description": "",
    "tags": null,
    "title": "监控Linux操作系统",
    "uri": "/best-practice/linux_host/"
  },
  {
    "content": "Telegraf内置支持snmp的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在telegraf.conf中搜索inputs.snmp，即可找到对应的配置，例子如下：\n[[inputs.snmp]] agents = [\"udp://172.25.79.194:161\"] timeout = \"5s\" version = 3 agent_host_tag = \"ident\" retries = 1 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysUpTime.0\" name = \"uptime\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysName.0\" name = \"source\" is_tag = true [[inputs.snmp.table]] oid = \"IF-MIB::ifTable\" name = \"interface\" inherit_tags = [\"source\"] [[inputs.snmp.table.field]] oid = \"IF-MIB::ifDescr\" name = \"ifDescr\" is_tag = true 上面非常关键的部分是：agent_host_tag = \"ident\"，因为夜莺对ident这个标签会特殊对待处理，把携有这个标签的数据当做隶属某个监控对象的数据，机器和网络设备都是典型的期望作为监控对象来管理的，所以snmp的采集中，我们把网络设备的ip放到ident这个标签里带上去。\n另外这个采集规则是v3的校验方法，不同的公司可能配置的校验方式不同，请各位参照telegraf.conf中那些snmp相关的注释仔细核对，如果是v2会简单很多，把上例中的如下部分：\nversion = 3 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" 换成：\nversion = 2 community = \"public\" 即可，当然了，community要改成你们自己的，这里写的public只是举个例子。\ninputs.snmp.field相关的那些配置，可以采集到各个网口的监控指标，更多的使用方式请参考官网\n 另外，snmp的采集，建议大家使用专门的Telegraf来做，因为和机器、中间件等的采集频率可能不同，比如边缘交换机，我们5min采集一次就够了，如果按照默认的配置可是10s采集一次，实在是太频繁了，可能会给一些老式交换机造成比较大的压力，采集频率在telegraf.conf的最上面[agent]部分，边缘交换机建议配置为：\n[agent] interval = \"300s\" flush_interval = \"300s\" 核心交换机可以配置的频繁一些，比如60s或者120s，请各位网络工程师朋友自行斟酌。\n",
    "description": "",
    "tags": null,
    "title": "使用SNMP采集网络设备的指标",
    "uri": "/best-practice/snmp/"
  },
  {
    "content": "所谓的告警自愈，主要是靠告警规则中配置webhook，即在告警和恢复的时候，自动调用指定的webhook地址，在这个webhook中写自动处理的逻辑。这个功能大部分监控系统都支持，不过对于运维人员，这个门槛可能稍高。夜莺和ibex（类似之前v3版本中的job模块）整合，可以做到告警的时候自动执行某个脚本，运维人员只需要写脚本即可，这个门槛会低一些。\n自愈脚本 在这个页面提前准备好一些自愈脚本，python、perl、ruby都行，只要机器上有对应的运行环境，系统会为每个自愈脚本生成一个ID，这个ID后面用于配置到告警规则那里形成联动。\n执行历史 保存了所有告警自愈的调用历史，可以查看执行结果，包括脚本的stdout和stderr等\n告警规则关联自愈脚本 告警规则中可以配置回调地址，比如${ibex}/11就表示这个回调是个特殊的回调，是要和告警自愈脚本打通，11表示的是自愈脚本的编号。如果我想在某个告警规则触发告警的时候，执行第22号脚本，就配置为：${ibex}/22，告警规则和自愈脚本都是要归属某个业务组的，规则关联的脚本只能是同业务组的。\n默认情况下，脚本的执行是去告警的那个机器执行，如果想把脚本放在特定的机器执行，可以这么配置：${ibex}/11/c3-center01.bj，c3-center01.bj表示希望脚本放到这个机器执行，这个机器需要和告警规则隶属于相同的业务组。典型的是这个机器是这个业务组的中控机，在中控机上跑一些自愈逻辑。\n额外说明 对于告警回调的处理，这里额外交代一下，默认情况下，不管是告警消息还是恢复消息，都会调用webhook，有时，webhook只需要在告警的时候才做处理，在恢复的时候啥都不做，此时，webhook逻辑要去看IsRecovered这个字段，这个字段如果是1就表示是恢复消息，如果这个字段是0就表示是告警消息。如果是${ibex}这种回调，系统会自动判断，只在告警的时候才触发，恢复的时候不触发，这点也请注意。因为从使用角度，自愈脚本只需要在告警的时候运行，恢复的时候，脚本是无需执行的。\n",
    "description": "",
    "tags": null,
    "title": "告警自愈",
    "uri": "/usage/selfhealing/"
  },
  {
    "content": "Google提出了应用监控的4个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面3个指标都可以通过内嵌SDK的方式埋点采集。夜莺核心模块有两个，webapi主要是提供http接口给JavaScript调用，server主要是负责接收监控数据，处理告警规则，这两个模块都引入了Prometheus的Go的SDK，用此方式做App Performance监控，本节以夜莺的代码为例，讲解如何使用Prometheus的SDK。\nwebapi监控 webapi模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的Label做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于HTTP请求，规划4个核心Label，分别是：service、code、path、method。service标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如webapi模块，就定义为n9e-webapi，code是http返回的状态码，200就表示成功数量，其他code就是失败的，后面我们可以据此统计成功率，method是HTTP方法，GET、POST、PUT、DELETE等，比如新增用户和获取用户列表可能都是/api/n9e/users，从路径上无法区分，只能再加上method才能区分开。\npath着重说一下，表示请求路径，比如上面提到的/api/n9e/users，但是，在restful实践中，url中经常会有参数，比如获取编号为1的用户的信息，接口是/api/n9e/user/1，获取编号为2的用户信息，接口是/api/n9e/user/2，如果这俩带有用户编号的url都作为Label，会造成时序库索引爆炸，而且从业务方使用角度来看，我们也不关注编号为1的用户获取请求还是编号为2的用户获取请求，而是关注整体的GET /api/n9e/user/:id这个接口的监控数据。所以我们在设置Label的时候，要把path设置为/api/n9e/user/:id，而不是那具体的带有用户编号的url路径。夜莺用的gin框架，gin框架有个FullPath方法就是获取这个信息的，比较方便。\n首先，我们在webapi下面创建一个stat包，放置相关统计变量：\npackage stat import ( \"time\" \"github.com/prometheus/client_golang/prometheus\" ) const Service = \"n9e-webapi\" var ( labels = []string{\"service\", \"code\", \"path\", \"method\"} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"uptime\", Help: \"HTTP service uptime.\", }, []string{\"service\"}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"http_request_count_total\", Help: \"Total number of HTTP requests made.\", }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \"http_request_duration_seconds\", Help: \"HTTP request latencies in seconds.\", }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } } uptime变量是顺手为之，统计进程启动了多久时间，不用太关注，RequestCounter和RequestDuration，分别统计请求流量和请求延迟。Init方法是在webapi模块进程初始化的时候调用，所以进程一起，就会自动注册好。\n然后我们写一个middleware，在请求进来的时候拦截一下，省的每个请求都要去统计，middleware方法的代码如下：\nimport ( ... promstat \"github.com/didi/nightingale/v5/src/webapi/stat\" ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\"%d\", c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } } 有了这个middleware之后，new出gin的engine的时候，就立马Use一下，代码如下：\n... r := gin.New() r.Use(stat()) ... 最后，监控数据要通过/metrics接口暴露出去，我们要暴露这个请求端点，代码如下：\nimport ( ... \"github.com/prometheus/client_golang/prometheus/promhttp\" ) func configRoute(r *gin.Engine, version string) { ... r.GET(\"/metrics\", gin.WrapH(promhttp.Handler())) } 如上，每个webapi的接口的流量和成功率都可以监控到了。如果你也部署了夜莺，请求webapi的端口(默认是18000)的/metrics接口看看吧。\nInfo如果服务部署多个实例，甚至多个region，多个环境，上面的4个Label就不够用了，因为只有这4个Label不足以唯一标识一个具体的实例，此时需要env、region、instance这种Label，这些Label不需要在代码里埋点，在采集的时候一般可以附加额外的标签，通过附加标签的方式来处理即可\n server监控 server模块的监控，和webapi模块的监控差异较大，因为关注点不同，webapi关注的是HTTP接口的请求量和延迟，而server模块关注的是接收了多少监控指标，内部事件队列的长度，从数据库同步告警规则花费多久，同步了多少条数据等，所以，我们也需要在server的package下创建一个stat包，stat包下放置stat.go，内容如下：\npackage stat import ( \"github.com/prometheus/client_golang/prometheus\" ) const ( namespace = \"n9e\" subsystem = \"server\" ) var ( // 各个周期性任务的执行耗时 \tGaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_duration\", Help: \"Cron method use duration, unit: ms.\", }, []string{\"cluster\", \"name\"}) // 从数据库同步数据的时候，同步的条数 \tGaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_sync_number\", Help: \"Cron sync number.\", }, []string{\"cluster\", \"name\"}) // 从各个接收接口接收到的监控数据总量 \tCounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"samples_received_total\", Help: \"Total number samples received.\", }, []string{\"cluster\", \"channel\"}) // 产生的告警总量 \tCounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alerts_total\", Help: \"Total number alert events.\", }, []string{\"cluster\"}) // 内存中的告警事件队列的长度 \tGaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alert_queue_size\", Help: \"The size of alert queue.\", }, []string{\"cluster\"}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) } 定义一个监控指标，除了name之外，还可以设置namespace、subsystem，最终通过/metrics接口暴露的时候，可以发现：监控指标的最终名字，就是$namespace_$subsystem_$name，三者拼接在一起。webapi模块的监控代码中我们看到了counter类型和histogram类型的处理，这次我们拿GaugeAlertQueueSize举例，这是个GAUGE类型的统计数据，起一个goroutine周期性获取队列长度，然后Set到GaugeAlertQueueSize中：\npackage engine import ( \"context\" \"time\" \"github.com/didi/nightingale/v5/src/server/config\" promstat \"github.com/didi/nightingale/v5/src/server/stat\" ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } } 另外，Init方法要在server模块初始化的时候调用，server的router.go中要暴露/metrics端点路径，这些就不再详述了，大家可以扒拉一下夜莺的代码看一下。\n数据抓取 应用自身的监控数据已经通过/metrics接口暴露了，后续采集规则可以在prometheus.yml中配置，prometheus.yml中有个section叫：scrape_configs可以配置抓取目标，这是Prometheus范畴的知识了，大家可以参考Prometheus官网。\n参考资料  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  ",
    "description": "",
    "tags": null,
    "title": "内嵌Prometheus SDK做APM",
    "uri": "/best-practice/promapm/"
  },
  {
    "content": "StatsD简介 在内嵌Prometheus SDK做APM一节中，我们介绍了业务进程内嵌Prometheus的SDK做埋点，这种方式，会把监控数据聚合计算的逻辑放在业务进程中，比如一些平均值、分位值的计算，可能会对业务进程造成影响，本节要介绍的StatsD的方式，理念是把指标聚合计算的逻辑挪到业务进程之外，业务进程调用埋点函数的时候，通过UDP推送给StatsD，即使StatsD挂了，也不会对业务进程造成影响。\nStatsD的简介，网上一搜一大把，请大家自行Google，这里就不重复描述了。核心要理解一下StatsD的设计理念、协议、支持的各个语言的SDK（在附录里有）即可，下面直接拿一个小例子讲解如何利用Telegraf支持StatsD协议的数据，数据只要进了Telegraf了，就意味着可以推到夜莺了，夜莺就相当于支持了StatsD的埋点监控采集能力。\nTelegraf启用StatsD 在Telegraf的配置文件中搜索inputs.statsd就能看到对应的section：\n[[inputs.statsd]] protocol = \"udp\" service_address = \":8125\" percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0] metric_separator = \"_\" 启用如上配置，percentiles略微有点多，可以配置的少一点，比如percentiles = [50.0, 90.0, 99.0, 100.0]，这样整体计算存储压力也会小一些。重启Telegraf，Telegraf就会在8125端口监听udp协议，接收业务埋点数据的上报。即，Telegraf实现了StatsD的协议，可以作为StatsD的Server使用。\n在业务程序中埋点 附录里罗列了一些客户端SDK，这里笔者使用Go语言的一个SDK来测试，实现了一个很小的web程序，代码如下：\npackage main import ( \"fmt\" \"math/rand\" \"net/http\" \"time\" \"github.com/smira/go-statsd\" ) var client *statsd.Client func homeHandler(w http.ResponseWriter, r *http.Request) { start := time.Now() // random sleep \tnum := rand.Int31n(100) time.Sleep(time.Duration(num) * time.Millisecond) fmt.Fprintf(w, \"duration: %d\", num) client.Incr(\"requests.counter,page=home\", 1) client.PrecisionTiming(\"requests.latency,page=home\", time.Since(start)) } func main() { // init client \tclient = statsd.NewClient(\"localhost:8125\", statsd.TagStyle(statsd.TagFormatInfluxDB), statsd.MaxPacketSize(1400), statsd.MetricPrefix(\"http.\"), statsd.DefaultTags(statsd.StringTag(\"service\", \"n9e-webapi\"), statsd.StringTag(\"region\", \"bj\")), ) defer client.Close() http.HandleFunc(\"/\", homeHandler) http.ListenAndServe(\":8000\", nil) } 这个web服务只有一个根路径，逻辑也很简单，就是随机sleep几十个毫秒当做业务处理时间。整体逻辑是这样的：首先，我们要通过statsd.NewClient初始化一个statsd的客户端，参数中指定了StatsD的Server地址（在本例中就是Telegraf的8125），指定了所有监控指标的前缀是http.，还指定了两个全局Tag，一个是service=n9e-webapi，另一个是region=bj，通过TagStyle指定了要发送的是InfluxDB样式（因为数据是发给Telegraf的，Telegraf是InfluxDB生态的）的标签。然后，在请求的具体处理逻辑里上报了两个监控指标，一个是requests.counter，另一个是requests.latency，并且，为这俩指标指定了一个指标级别的标签page=home，整体看起来还是比较简单的。\n测试方法 上面的Go程序编译一下，启动，会作为一个web server监听在8000端口，然后周期性请求这个web server的地址做测试，这个web server接收到请求之后，就调用statsd的sdk，statsd的sdk的核心逻辑就是把数据发给Telegraf的8125，然后就是Telegraf处理聚合逻辑，聚合之后的数据每10s（默认flush频率）发给夜莺。\n在页面上，应该可以看到http_requests_latency和http_requests_counter打头的相关指标，比如http_requests_latency_mean这个指标，会看到这个指标有如下几个标签：\n ident: VM-0-4-centos 这个标签其实是Telegraf原始的host标签，夜莺的规范里叫ident，所以做了一下rename metric_type: timing 这个显然是把statsd的数据类型也做为标签了，其他数据类型还有gauge、counter、set等 page: home 这是我们代码里附到监控指标后面的标签，Telegraf自动帮解析出来了 service: n9e-webapi NewClient时候附加的全局默认标签 region: bj NewClient时候附加的全局默认标签  附录资料  Measure Anything, Measure Everything Statsd支持的的客户端SDK列表  ",
    "description": "",
    "tags": null,
    "title": "内嵌Statsd SDK做APM",
    "uri": "/best-practice/statsd/"
  },
  {
    "content": "人员组织 虽然人员组织这个菜单是放到了最后，但是文档里还是要先讲一下，绝大部分功能都依赖业务组这个概念。不过一旦业务组创建完成，就基本不怎么变动操作了，所以菜单放到了后面。\n用户管理 简单，就是管理系统中的所有用户，系统默认会初始化进去一个root账号，这个root账号是个管理角色，可以创建其他普通用户、修改其他用户的信息。用户认证也可以对接LDAP，这样就无需管理员去创建用户了，LDAP的配置在webapi.conf中。\n团队管理 团队就是用户组，包含多个用户。主要有两个作用：1、作为告警接收组，配置告警规则的时候，可以通过指定告警接收组的方式告诉系统当发生告警的时候通知哪些人；2、管理业务组，业务组下可以有多个团队，有的团队是ro权限，即只读，有的是rw权限，即读写权限。\n业务组管理 业务组相当于一个namespace，下面可以包含用户组、监控对象、告警规则、订阅规则、屏蔽规则、监控大盘、自愈脚本等，是一个可以自闭环的组织，类似一个BU，或者大的业务线。当然，一些小的组织，如果管理（主要是指管理监控对象、告警规则等）上可以自闭环（无需假手其他团队，自己这个团队就能搞定），也可以创建一个单独的业务组。比如夜莺研发团队，管理了100台机器，部署了夜莺的服务，这些机器、这些服务/机器的告警规则都是夜莺研发团队自己搞，那完全可以创建一个夜莺的业务组自己去管理。\n对象管理 对象管理主要是针对机器和网络设备的管理，如果监控数据推送给n9e-server，n9e-server会从监控数据结构中解析出监控对象的标识信息（标签中的ident或host字段），然后把监控对象信息写入数据库，之后，用户可以在对象管理页面，对监控对象做管理：包括分配这些对象给指定的业务组、给这些监控对象设置标签、修改备注等。\n这个版本的夜莺，取消了之前版本的树状结构，主要是靠业务组+标签的方式来配合解决机器分组的问题，关于这块的设计，有一篇文章来专门探讨：《探讨业务组的设计和最佳实践》\n监控看图 为了让大家尽量用一个平台搞定监控告警的所有事情，夜莺中内置了查看监控数据的能力，包括即时查询（就是类似PromDash的看图能力）、监控大盘（是类似Grafana的Dashboard配置，不过图表类型支持较少）、对象视角看图（是一个先选择监控对象再看相关监控数据的特殊视角，运维工程师会很喜欢）\n即时查询 解决以下问题：\n 检查某个监控数据是否在正常上报 测试promql，测试好的promql用于配置告警规则 生产环境故障，临时查一些监控指标的数据  监控大盘 解决以下问题：\n 日常巡检 知识传递，由专业的人做好大盘，新同事看这些大盘能更便于理解和达成监控目标 生产环境故障，查看监控数据  对象视角 在夜莺系统里，认为监控对象是个很关键的概念，值得赋予一定的管理功能。比如很多监控数据都隶属于某个监控对象，比如某个机器的磁盘利用率，或者某个交换机的某个网口的流量，那在查看这些监控数据的时候，我们会倾向于先找到对应的监控对象，再根据监控对象查找相关监控指标。对象视角的看图方式，就是为此而生。\n什么样的监控数据认为是隶属于某个监控对象的？就看监控数据中是否有ident这个tag，如果有，就认为ident指定的是监控对象的标识，就认为这条监控数据是关联到某个监控对象的，当然，Telegraf采集的监控数据，会打上host标签，标识这个监控数据是来自哪个机器，host这个标签会被夜莺rename成ident。\n告警管理 夜莺对告警的处理，分为3个规则的管理：告警规则、屏蔽规则、订阅规则；活跃告警和历史告警的展示；以及告警自愈。\n告警规则 最主要用的是告警规则，用于配置告警阈值，有些监控数据可能不想告警，比如有规划的维护周期，可以配置屏蔽规则，某个告警除了某个组的人关心，可能其他人也关心，就配置订阅规则，比如K8S平台的运维人员要作为告警接收人来接收所有K8S的告警，但是K8S的一些重大网络故障会影响整个K8S集群，上层业务也会关心这类告警，此时业务方就可以订阅K8S集群的部分重大告警。\n对于订阅规则，还有一种场景，比如运维团队管理了公司所有的告警规则，比如内存利用率的告警，不同业务线的人只关心自己的，那不同业务线的人就可以通过订阅规则，只订阅自己业务线的机器的告警。只需简单的为这批机器打上业务线标签，就可以通过这些标签做过滤。\n告警事件 活跃告警，即当前未恢复的告警，这个信息很关键，通常每天都要巡检，甚至投到作战大屏上，时刻关注；历史告警，就是所有历史告警，包括报警消息和恢复消息，算是一个存档。\n告警自愈 告警自愈是类似夜莺v4里边的job平台，可以在告警发生的时候，自动触发某个脚本的执行，比如某个宿主机报警说硬盘不够用，可以自动跑个脚本清理一下无用的数据，比如K8S宿主机的话，可以清理一些没用的镜像。\n",
    "description": "",
    "tags": null,
    "title": "功能介绍",
    "uri": "/usage/"
  },
  {
    "content": "大家对产品功能有哪些疑问可以告诉我们，我们补充到最佳实践章节。\n",
    "description": "",
    "tags": null,
    "title": "理念实战",
    "uri": "/best-practice/"
  },
  {
    "content": "对于MySQL、Redis、MongoDB、Tomcat、RabbitMQ、Ceph、Cassandra、Consul等等各类中间件、数据库，Telegraf都可以监控，Prometheus生态也提供了各类Exporter，直接用就好了，如果有优化建议，就提PR，夜莺生态再搞一套采集意义不大，能够良好的集成，与社区协同起来才是关键。\n本节起了一个巨大的标题，不过并不准备事无巨细的讲解每个中间件的采集配置，Telegraf的入门在这里，每个中间件都在这里成一个目录，目录下README就是文档。如果有Telegraf解决不了的，Google一下Exporter解决方案，互相补充一下。\n数据采集有了Telegraf和Exporter，问题就不大了，但是，对于某一个具体的监控对象，比如MySQL，各个指标是什么意思？应该着重关注哪些指标？哪些指标应该配置告警规则？报警的时候应该如何处理？这就是非常专业的领域知识了，欢迎大家写博客分享，并把博客链接放到本节下面 :)\n MySQL监控分享 By xxx  ",
    "description": "",
    "tags": null,
    "title": "使用Telegraf和Exporter监控中间件",
    "uri": "/best-practice/middleware/"
  },
  {
    "content": "对于监控系统的API，通常有如下几个使用场景：1、读写监控数据 2、以个人用户身份调用API做一些操作，不想去WEB上操作 3、第三方系统调用监控的API做包装，用户在第三方系统操作，实际这个第三方系统底层是调用的监控的接口。\n1.读写监控数据 对于这个场景，大家可以直接绕过夜莺，调用后端时序库的读写接口。对于写监控数据而言，如果想要走夜莺的接口，请调用n9e-server的/opentsdb/put接口，POST方法，该接口实现了OpenTSDB的数据协议，监控数据做成JSON放到HTTP Request Body中，举例：\n[ { \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 }, { \"metric\": \"cpu_usage_util\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 69.5 } ] 显然，JSON最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：\n{ \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 } 服务端会看第一个字符是否是[，来判断上报的是数组，还是单个对象，自动做相应的Decode。如果觉得上报的内容太过占用带宽，也可以做gzip压缩，此时上报的数据，要带有Content-Encoding: gzip的Header。\nOK，上面是推送监控数据的接口，至于查询监控数据，请大家直接调用后端时序库的接口，即Prometheus那些/api/v1/query /api/v1/query_range之类的接口。相关接口文档请参考：Prometheus官网\n2.以个人身份模仿WEB操作 这种方式，页面上JavaScript可以调用的所有接口，你都可以用程序调用，打开chrome的开发者工具，扒拉这些接口，还是非常容易的。当然，要先登录，登录调用webapi模块的/api/n9e/auth/login接口，系统使用jwt认证，如果登录成功，会返回access_token和refresh_token，每次调用的时候都要把access_token放到Header里，access_token差不多15分钟过期，之后可以重新调用登录接口换token，也可以调用/api/n9e/auth/refresh接口用refresh_token换一个新的access_token，当然，也会顺道返回一个新的refresh_token，举例：\n# 调用登录接口拿到access_token和refresh_token记录下来，后面调用其他接口的时候会用到 [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\"username\": \"root\", \"password\": \"root.2020\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\",\"user\":{\"id\":1,\"username\":\"root\",\"nickname\":\"超管\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true}},\"err\":\"\"} # access_token放到Authorization这个Header里，Bearer的验证方式 [root@10-255-0-34 ~]# curl -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\" 'http://localhost:18000/api/n9e/self/profile' {\"dat\":{\"id\":1,\"username\":\"root\",\"nickname\":\"超管\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true},\"err\":\"\"} # 如果token过期了，后端会返回异常HTTP状态码，此时要调用refresh接口换取新的token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\"},\"err\":\"\"} 3.第三方系统调用夜莺 比如第三方系统想获取夜莺中的所有未恢复告警，或者获取夜莺中的全量用户列表，这些需求，建议走/v1/n9e打头的接口，这些接口走BasicAuth认证，BasicAuth的用户名和密码在webapi.conf中可以找到，就是BasicAuth那个section的配置。当前这个阶段，还没有哪个系统会依赖夜莺的接口，所以，这个/v1/n9e前缀的接口目前一个都还没有提供，不过代码框架已经搭起来了，代码在src/webapi/router/router.go文件中，service那个路由Group，如果贵司要封装夜莺的接口，可能要在这个路由分组下加一些路由配置了。作为开源软件，说清楚原理就好了，如果贵司仍然搞不明白可以联系我们，我们提供商业技术支持服务 :-)\n",
    "description": "",
    "tags": null,
    "title": "API",
    "uri": "/api/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": " 夜莺是新一代国产智能监控系统。对云原生场景、传统物理机虚拟机场景，都有很好的支持，10分钟完成搭建，1小时熟悉使用，经受了滴滴生产环境海量数据的验证，希望打造国产监控的标杆之作，一起参与进来吧！\n 新版简介 Nightingale在2020.3.20发布v1版本，目前是v5.0版本，从这个版本开始，与Prometheus、VictoriaMetrics、Grafana、Telegraf等生态做了协同集成，力争打造国内最好用的开源运维监控系统。\n与Open-Falcon的区别 因为开发Open-Falcon和Nightingale的是一拨人，所以很多社区伙伴会比较好奇，为何要新做一个监控开源软件。核心点是Open-Falcon和Nightingale的差异点实在是太大了，Nightingale并非是Open-Falcon设计逻辑的一个延续，就看做两个不同的软件就好。\nOpen-Falcon是14年开发的，当时是想解决Zabbix的一些容量问题，可以看做是物理机时代的产物，整个设计偏向运维视角，虽然数据结构上已经开始设计了标签，但是查询语法还是比较简单，无法应对比较复杂的场景。\nNightingale直接支持PromQL，支持Prometheus、M3DB、VictoriaMetrics多种时序库，支持Telegraf做监控数据采集，支持Grafana看图，整个设计更加云原生，虽然也保留了机器归组的逻辑以应对物理机时代的需求，但是设计上，更倾向于使用标签来分组，而不是HostGroup或者树形结构。\n与Prometheus的区别 Nightingale可以简单看做是Prometheus的一个企业级版本，把Prometheus当做Nightingale的一个内部组件-时序库，当然，也不是必须的，时序库除了Prometheus，还可以使用VictoriaMetrics、M3DB等。各种Exporter也可以继续使用，不过我们更推荐使用All-in-one的Telegraf，运维代价会更小一些。\nNightingale可以接入多个Prometheus/M3DB/VictoriaMetrics，可以允许用户在页面上配置告警规则、屏蔽规则、订阅规则，在页面上查看告警事件，配置告警自愈机制，管理监控对象，配置监控大盘等，就把Nightingale看做是Prometheus的一个WEBUI也是可以的，不过实际上，它远远不止是一个WEBUI，用一下就会深有感触。\n项目代码  后端：💡 https://github.com/didi/nightingale 前端：💡 https://github.com/n9e/fe-v5  系统架构 夜莺5.1的设计非常简单，核心是server和webapi两个模块，webapi无状态，放到中心端，承接前端请求，将用户配置写入数据库；server是告警引擎和数据转发模块，一般随着时序库走，一个时序库就对应一套server，每套server可以只用一个server实例，也可以多个实例组成集群，server可以接收Telegraf上报的数据，写入后端时序库，周期性从数据库同步告警规则，然后查询时序库做告警判断。每套server依赖一个redis。架构图如下：\n加入社区  微信公号:__n9e__（夜莺监控） 知识星球：夜莺开源社区  钉钉交流群：\n",
    "description": "",
    "tags": null,
    "title": "夜莺手册",
    "uri": "/"
  }
]
