[
  {
    "content": " 采用Docker Compose做编排，用于单机快速启动环境做测试，包含了MySQL、Redis、Prometheus、Ibex、Nightingale、Telegraf\n 从Github下载夜莺的源码，进入docker目录，执行docker-compose up -d即可，docker-compose会自动拉取镜像并启动，查看各个容器启动状态，使用命令docker-compose ps，都是Up状态则表示启动成功，如果ibex、nserver、nwebapi等模块一直在Restarting，可能是数据库容器启动太慢了没有准备好，可以执行docker-compose down停掉再重新尝试启动测试：\nulric@mac.home:~/workspace/gopath/src/n9e/docker$ docker-compose up -d Creating network \"docker_nightingale\" with driver \"bridge\" Creating mysql ... done Creating redis ... done Creating prometheus ... done Creating ibex ... done Creating agentd ... done Creating nwebapi ... done Creating nserver ... done Creating telegraf ... done ulric@mac.home:~/workspace/gopath/src/n9e/docker$ docker-compose ps Name Command State Ports ---------------------------------------------------------------------------------------------------------------------------- agentd /app/ibex agentd Up 10090/tcp, 20090/tcp ibex /app/ibex server Up 0.0.0.0:10090-\u003e10090/tcp, 0.0.0.0:20090-\u003e20090/tcp mysql docker-entrypoint.sh mysqld Up 0.0.0.0:3306-\u003e3306/tcp, 33060/tcp nserver /app/n9e server Up 18000/tcp, 0.0.0.0:19000-\u003e19000/tcp nwebapi /app/n9e webapi Up 0.0.0.0:18000-\u003e18000/tcp, 19000/tcp prometheus /bin/prometheus --config.f ... Up 0.0.0.0:9090-\u003e9090/tcp redis docker-entrypoint.sh redis ... Up 0.0.0.0:6379-\u003e6379/tcp telegraf /entrypoint.sh telegraf Up 0.0.0.0:8092-\u003e8092/udp, 0.0.0.0:8094-\u003e8094/tcp, 0.0.0.0:8125-\u003e8125/udp 更多docker-compose相关知识请参考官网\nWarning启动成功之后，建议把initsql目录下的内容挪走，这样下次重启的时候，DB就不会重新初始化了。否则下次启动mysql还是会自动执行initsql下面的sql文件导致DB重新初始化，页面上创建的规则、用户等都会丢失\n 服务启动之后，浏览器访问nwebapi的端口，即18000，默认用户是root，密码是root.2020\n",
    "description": "",
    "tags": null,
    "title": "使用Docker Compose快速部署",
    "uri": "/quickstart/compose/"
  },
  {
    "content": "姿势一：只是把Nightingale作为WEBUI 只部署n9e-webapi和n9e-server，配合Prometheus以及各类Exporter，可以在夜莺WEBUI上查看监控数据，配置监控大盘，配置告警规则、屏蔽规则、订阅规则，查看活跃告警、历史告警。且各类配置可以按照业务组拆分归组，相互之间没有影响。\n说只是作为WEBUI，其实不止，这种工作模式实际是替换掉了Prometheus内置的告警引擎+alertmanager，只需用Prometheus存时序数据，用Exporter抓取数据即可。\n姿势二：使用Telegraf替代各类Exporter Telegraf是个all-in-one的架构，一个二进制可以搞定机器、网络设备、中间件、数据库、Statsd等各种采集能力，相比散落的各类Exporter而言，维护成本更低一些，Telegraf支持通过OpenTSDB这个output plugin来对接夜莺。\n此时就可以解锁夜莺的对象管理能力，因为Telegraf采集的数据，会流经n9e-server，n9e-server就可以从监控数据中解析出监控对象信息（标签中的ident或host，就表示监控对象标识），知道最近有哪些监控对象在上报数据，哪些监控对象已经失联了，就可以顺道做NODATA逻辑。\n对象管理页面中，可以给监控对象打标签，这些标签会附到相关时序数据上，即：某个对象如果打了bg=cloud标签，这个对象有监控数据上报的时候，比如上报了cpu_usage_idle的监控数据，系统就可以从监控数据中解析出ident，然后根据ident找到页面上打的标签，然后把标签附到时序数据上。\n过半的监控数据其实都可以关联到某个监控对象，看图的时候先找到监控对象，再查监控数据是个挺顺畅的路径，所以，这就是对象视角看图页面的设计初衷，用了Telegraf，也就可以解锁使用这个页面的功能了。\n姿势三：使用VictoriaMetrics替换Prometheus时序存储 因为Prometheus时序存储是单机版，对于大规模场景，推荐使用VictoriaMetrics或者M3DB，因为M3DB有些复杂，一般建议使用VictoriaMetrics，VictoriaMetrics和Prometheus的查询接口完全兼容，所以夜莺也可以对接VictoriaMetrics，通过Prometheus协议的查询接口来查询VictoriaMetrics的数据。\n 所以大规模集群环境建议的组合方式是Nightingale+Telegraf+VictorMetrics，简称NTVM，如果是规模不大，组合方式是Nightingale+Telegraf+Prometheus，简称NTP，如果Telegraf的采集能力在某些场景下不足，可以用对应场景的Exporter来补齐。\n",
    "description": "",
    "tags": null,
    "title": "使用夜莺的的几种实践姿势",
    "uri": "/best-practice/fccloud-usage/"
  },
  {
    "content": "如果您对Docker的使用非常熟悉，建议利用Docker compose的方式快速启动测试，请参考使用Docker Compose快速部署，如果对Docker不熟悉，那就用二进制方式部署，也非常简单，最小的可运行环境是Prometheus+MySQL+Redis+Nightingale，请参考快速在生产环境部署启动单机版。这个最小的环境只有Prometheus采集到的自身的一些监控指标，略显单薄，此时，我们可以引入Telegraf，采集机器、网络设备、各类中间件的指标，请参考使用Telegraf采集监控数据。\n如果公司体量很大，建议把单机版本的Prometheus替换为VictoriaMetrics，请参考使用VictoriaMetrics作为时序库。或者直接部署多个Prometheus，按照业务线或者按照地域来划分集群，此时你可能需要接入多个Prom/VM/M3DB集群，在引入多个TSDB的过程中，就要同步使用夜莺的多Server部署模型了，请参考生产环境部署高可用集群版\n",
    "description": "",
    "tags": null,
    "title": "安装部署",
    "uri": "/quickstart/"
  },
  {
    "content": " 本节讲述如何部署单机版，单机版对于很多中小公司足够用了，简单高效、快速直接，建议使用云主机，性能不够了直接升配，可以应对每秒上报的数据点小于100万的情形，如果只是监控机器（每台机器每个周期大概采集200个数据点）采集周期频率设置10秒的话，支撑上限是5万台\n 如果仅仅是为了快速测试，Docker部署方式是最快的，不过很多朋友未必有Docker环境，另外为了减少引入更多技术栈，增强生产环境稳定性，有些朋友可能也不愿意用Docker，那本篇就来讲解如何快速部署单机版，单机版的配套时序库是使用Prometheus。如果要监控的机器有几千台，服务有几百个，单机版的容量无法满足，可以上集群版，集群版的时序库建议使用VictoriaMetrics，也可以使用M3DB，不过M3DB的架构更复杂，很多朋友无法搞定，选择简单的VictoriaMetrics，对大部分公司来讲，足够用了。我们先来看一下服务端架构：\n 核心模块server：server是用来做告警的，会从数据库中同步告警规则，然后读取Prometheus的数据做告警判断。server也可以接收监控数据上报，然后通过remote write协议写入多个时序库。server也依赖redis，用redis存储了server本身以及监控对象的心跳信息 核心模块webapi：提供restful api，用于和前端JavaScript交互，把一些用户配置类的信息写入mysql，鉴权采用jwt，jwt的token使用redis存储，在单机部署的方式下，server的redis和webapi的redis可以复用  环境准备 依赖的组件有：mysql、redis、prometheus，这三个组件都是开源软件，请大家自行安装，其中prometheus在启动的时候要注意开启 --enable-feature=remote-write-receiver 这里也提供一个小脚本来安装这3个组件，大家可以参考：\n# install prometheus mkdir -p /opt/prometheus wget https://s3-gz01.didistatic.com/n9e-pub/prome/prometheus-2.28.0.linux-amd64.tar.gz -O prometheus-2.28.0.linux-amd64.tar.gz tar xf prometheus-2.28.0.linux-amd64.tar.gz cp -far prometheus-2.28.0.linux-amd64/* /opt/prometheus/ # service  cat \u003c\u003cEOF \u003e/etc/systemd/system/prometheus.service [Unit] Description=\"prometheus\" Documentation=https://prometheus.io/ After=network.target [Service] Type=simple ExecStart=/opt/prometheus/prometheus --config.file=/opt/prometheus/prometheus.yml --storage.tsdb.path=/opt/prometheus/data --web.enable-lifecycle --enable-feature=remote-write-receiver --query.lookback-delta=2m Restart=on-failure SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=prometheus [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable prometheus systemctl restart prometheus systemctl status prometheus # install mysql yum -y install mariadb* systemctl enable mariadb systemctl restart mariadb mysql -e \"SET PASSWORD FOR 'root'@'localhost' = PASSWORD('1234');\" # install redis yum install -y redis systemctl enable redis systemctl restart redis 上例中mysql的root密码设置为了1234，建议维持这个不变，后续就省去了修改配置文件的麻烦。\n安装夜莺组件 mkdir -p /opt/n9e \u0026\u0026 cd /opt/n9e # 去 https://github.com/didi/nightingale/releases 找最新版本的包，文档里的包地址可能已经不是最新的了 tarball=n9e-5.4.0.tar.gz urlpath=https://github.com/didi/nightingale/releases/download/v5.4.0/${tarball} wget $urlpath || exit 1 tar zxvf ${tarball} mysql -uroot -p1234 \u003c docker/initsql/a-n9e.sql nohup ./n9e server \u0026\u003e server.log \u0026 nohup ./n9e webapi \u0026\u003e webapi.log \u0026 # check logs # check port 如果启动成功，server默认会监听在19000端口，webapi会监听在18000端口，且日志没有报错。上面使用nohup简单演示，生产环境建议用systemd托管，相关service文件可以在etc/service目录下找到。\n配置文件etc/server.conf和etc/webapi.conf中都含有mysql的连接地址配置，检查一下用户名和密码，prometheus如果使用上面的脚本安装，默认会监听本机9090端口，server.conf和webapi.conf中的prometheus相关地址都不用修改就是对的。\n好了，浏览器访问webapi的端口（默认是18000）就可以体验相关功能了，默认用户是root，密码是root.2020。如果安装过程出现问题，可以参考 视频教程\n接下来，你可能需要：\n 安装Telegraf采集更多监控数据  ",
    "description": "",
    "tags": null,
    "title": "快速在生产环境部署启动单机版",
    "uri": "/quickstart/standalone/"
  },
  {
    "content": " Telegraf 是 InfluxData 开源的一款采集器，可以采集操作系统、各种中间件的监控指标，采集目标列表，看起来是非常丰富，Telegraf是一个大一统的设计，即一个二进制可以采集CPU、内存、mysql、mongodb、redis、snmp等，不像Prometheus的exporter，每个监控对象一个exporter，管理起来略麻烦。一个二进制分发起来确实比较方便。\n 这里提供快速安装的教程，Telegraf的更多知识，请参考Telegraf官网，笔者之前也写了一个Telegraf调研笔记，讲解了Telegraf的基本用法，一定要看！！！，大家亦可参考。\nTelegraf下载地址在这里，根据自己的平台选择对应的二进制下载即可。笔者的环境是CentOS，下面是安装脚本，/opt/telegraf/telegraf.conf 是一个经过删减的干净的配置文件，指定了opentsdb output plugin，这个plugin的写入地址配置的是n9e-server，所以，Telegraf采集的数据会被推送给n9e-server，二者贯通：\n#!/bin/sh  version=1.20.4 tarball=telegraf-${version}_linux_amd64.tar.gz wget https://dl.influxdata.com/telegraf/releases/$tarball tar xzvf $tarball mkdir -p /opt/telegraf cp -far telegraf-${version}/usr/bin/telegraf /opt/telegraf cat \u003c\u003cEOF \u003e /opt/telegraf/telegraf.conf [global_tags] [agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false [[outputs.opentsdb]] host = \"http://127.0.0.1\" port = 19000 http_batch_size = 50 http_path = \"/opentsdb/put\" debug = false separator = \"_\" [[inputs.cpu]] percpu = true totalcpu = true collect_cpu_time = false report_active = true [[inputs.disk]] ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\", \"iso9660\", \"overlay\", \"aufs\", \"squashfs\"] [[inputs.diskio]] [[inputs.kernel]] [[inputs.mem]] [[inputs.processes]] [[inputs.system]] fielddrop = [\"uptime_format\"] [[inputs.net]] ignore_protocol_stats = true EOF cat \u003c\u003cEOF \u003e /etc/systemd/system/telegraf.service [Unit] Description=\"telegraf\" After=network.target [Service] Type=simple ExecStart=/opt/telegraf/telegraf --config telegraf.conf WorkingDirectory=/opt/telegraf SuccessExitStatus=0 LimitNOFILE=65536 StandardOutput=syslog StandardError=syslog SyslogIdentifier=telegraf KillMode=process KillSignal=SIGQUIT TimeoutStopSec=5 Restart=always [Install] WantedBy=multi-user.target EOF systemctl daemon-reload systemctl enable telegraf systemctl restart telegraf systemctl status telegraf  Warning/opt/telegraf/telegraf.conf的内容是个删减版，只是为了让大家快速跑起来，如果要采集更多监控对象，比如mysql、redis、tomcat等，还是要仔细去阅读从tarball里解压出来的那个配置文件，那里有很详细的注释，也可以参考官方提供的各个采集插件下的README\n 网友分享  Telegraf的Linux版安装分享 Telegraf的Windows版安装分享  ",
    "description": "",
    "tags": null,
    "title": "使用Telegraf采集监控数据",
    "uri": "/quickstart/telegraf/"
  },
  {
    "content": " VictoriaMetrics 架构简单，可靠性高，在性能，成本，可扩展性方面表现出色，社区活跃，且和 Prometheus 生态绑定紧密。夜莺推荐您在生产环境中使用 VictoriaMetrics 作为时序数据库。\n VictoriaMetrics 提供单机版和集群版。如果您的每秒写入数据点数小于100万，VictoriaMetrics 官方默认推荐您使用单机版，单机版可以通过增加服务器的CPU核心数，增加内存，增加IOPS来获得线性的性能提升。且单机版易于配置和运维。\n接下来的文章，介绍在夜莺中，以 VictoriaMetrics 集群版本作为时序数据库为例，完整的安装和配置过程。\nvmstorage、vminsert、vmselect 三者组合构成 VictoriaMetrics 的集群功能，三者都可以通过启动多个实例来分担承载流量。\n vmstorage 是数据存储模块：\n  其数据保存在-storageDataPath指定的目录中，默认为./vmstorage-data/，vmstorage 是有状态模块，删除 storage node 会丢失约 1/N的历史数据（N 为集群中 vmstorage node 的节点数量）。增加 storage node，则需要同步修改 vminsert 和 vmselect 的启动参数，将新加入的storage node节点地址通过命令行参数 -storageNode传入给vminsert和vmselect。 vmstorage 启动后，会监听三个端口，分别是 -httpListenAddr :8482、-vminsertAddr :8400、-vmselectAddr :8401。端口8400负责接收来自 vminsert 的写入请求，端口8401负责接收来自 vmselect 的数据查询请求，端口8482则是 vmstorage 自身提供的 http api 接口。   vminsert 接收来自客户端的数据写入请求，并负责转发到选定的vmstorage：\n  vminsert 接收到数据写入请求后，按照 jump consistent hash 算法，将数据转发到选定的某个vmstorage node 上。vminsert 本身是无状态模块，可以增加或者删除一个或多个实例，而不会造成数据的损失。vminsert 模块通过启动时的参数 -storageNode xxx,yyy,zzz 来感知到整个 vmstorage 集群的完整 node 地址列表。 vminsert 启动后，会监听一个端口-httpListenAddr :8480。该端口实现了 prometheus remote_write协议，因此可以接收和解析通过 remote_write 协议写入的数据。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8480/insert/\u003caccount_id\u003e/prometheus/api/v1/write。 更多 URL Format 可以参考 VictoriaMetrics官网。   vmselect 接收来自客户端的数据查询请求，并负责转发到所有的 vmstorage 查询结果并合并：\n  vmselect 启动后，会监听一个端口-httpListenAddr :8481。该端口实现了 prometheus remote_query等协议，因此可以接收和解析 remote_query 协议的查询。不过要注意，VictoriaMetrics 集群版本具有多租户功能，因此租户ID会以如下形式出现在 API URL 中: http://vminsert:8481/select/\u003caccount_id\u003e/prometheus/api/v1/query。 更多 URL Format 可以参考 VictoriaMetrics官网。  下载和安装 VictoriaMetrics 集群版  去 vm release 下载编译好的二进制版本，比如我们选择下载 v1.69.0 amd64。 解压缩后得到：  $ls -l vm*-prod -rwxr-xr-x 1 work work 10946416 Nov 8 22:03 vminsert-prod* -rwxr-xr-x 1 work work 13000624 Nov 8 22:03 vmselect-prod* -rwxr-xr-x 1 work work 11476736 Nov 8 22:03 vmstorage-prod*  启动三个 vmstorage 实例(可以用下面的脚本快速生成不同实例的启动命令)：  #!/bin/bash  for i in `seq 0 2`; do if [ $i -eq 0 ]; then i=\"\" fi pp=$i httpListenAddr=${pp}8482 vminsertAddr=${pp}8400 vmselectAddr=${pp}8401 storageDataPath=./${pp}vmstorage-data prog=\"nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai \\ -storageDataPath $storageDataPath\\ -httpListenAddr :$httpListenAddr\\ -vminsertAddr :$vminsertAddr\\ -vmselectAddr :$vmselectAddr\\ \u0026\u003e ${pp}vmstor.log \u0026\" echo $prog (exec \"$prog\") done 也可以输入以下命令行启动三个实例：\nnohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./vmstorage-data -httpListenAddr :8482 -vminsertAddr :8400 -vmselectAddr :8401 \u0026\u003e vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./1vmstorage-data -httpListenAddr :18482 -vminsertAddr :18400 -vmselectAddr :18401 \u0026\u003e 1vmstor.log \u0026 nohup ./vmstorage-prod -loggerTimezone Asia/Shanghai -storageDataPath ./2vmstorage-data -httpListenAddr :28482 -vminsertAddr :28400 -vmselectAddr :28401 \u0026\u003e 2vmstor.log \u0026  启动一个 vminsert 实例：  nohup ./vminsert-prod -httpListenAddr :8480 -storageNode=127.0.0.1:8400,127.0.0.1:18400,127.0.0.1:28400 \u0026\u003evminsert.log \u0026  启动一个 vmselect 实例：  nohup ./vmselect-prod -httpListenAddr :8481 -storageNode=127.0.0.1:8401,127.0.0.1:18401,127.0.0.1:28401 \u0026\u003evmselect.log \u0026  查看 vmstorage，vminsert，vmselect 的 /metrics 接口:  curl http://127.0.0.1:8482/metrics curl http://127.0.0.1:18482/metrics curl http://127.0.0.1:28482/metrics curl http://127.0.0.1:8481/metrics curl http://127.0.0.1:8480/metrics  n9e-server通过remote write接口写入时序库，vm作为时序库的一个选择，其remote write接口地址为：http://127.0.0.1:8480/insert/0/prometheus/api/v1/write 把这个地址配置到server.conf当中即可，配置完了重启n9e-server  # Reader部分修改Url [Reader] Url = \"http://172.21.0.8:8481/select/0/prometheus\" # Writers部分修改Url [[Writers]] Url = \"http://172.21.0.8:8480/insert/0/prometheus/api/v1/write\"  修改您的 n9e-webapi 的配置文件 ./etc/webapi.conf 如下：  [[Clusters]] # Prometheus cluster name Name = \"Default\" # Prometheus APIs base url Prom = \"http://127.0.0.1:8481/select/0/prometheus\" 然后，重新启动n9e-webapi，这样夜莺就可以通过 remote query 查询到 victoriametrics 集群的数据了。\nInfon9e-webapi 的安装、配置和启动，请参考 这里。\n FAQ  VictoriaMetrics 单机版本如何保障数据的可靠性？  vm 针对磁盘IO有针对性的优化，单机版可以考虑将数据的可靠性保障交给 EBS 等云盘来保证。\n  VictoriaMetrics 如何评估容量？  参考vm的官方文档。\n  VictoriaMetrics 集群版本增加或者删除vmstorage Node的时候，数据如何再平衡？  vm 不支持扩缩容节点时，对数据进行自动的再平衡。\n  VictoriaMetrics 的数据大小如何查看？  可以通过 vmstorage 实例暴露的 /metrics 接口来获取到相应的统计数据，譬如：\n $ curl http://127.0.0.1:8482/metrics |grep -i data_size vm_data_size_bytes{type=\"indexdb\"} 609291 vm_data_size_bytes{type=\"storage/big\"} 0 vm_data_size_bytes{type=\"storage/small\"} 8749893  vminsert 在将数据写入多个 vmstorage Node的时候，是按照什么规则将数据写入到不同的 node 上的？  采用jump consistent hash 对数据进行分片，写入到相应的storage node上。\n  vmselect 在接到查询请求的时候，如何定位到请求的数据是在哪个 storage node上的？  vmselect 并不知道每个metrics对应的数据分布的storage node，vmselect会对所有的storage node发起查询请求，最后进行数据合并，并返回。\n  VictoriaMetrics 和 M3db 的对比和选择？  m3db架构设计上更高级，实现难度高，m3db在时序数据功能之后，重点解决了自动扩缩容，数据自动平衡等运维难题。但是因此也更复杂，可靠性目前也更难保证。VictoriaMetrics架构设计上的tradeoff 更倾向于简单可靠，重点优化了单机版的性能，强调垂直扩展，同时和prometheus 生态做到兼容，甚至于在很多的点上做到了加强。但是 VictoriaMetrics 对于时序数据downsample，节点的自动扩缩容，数据自动再平衡等高级功能和分布式能力，是有缺失的。\n   相关资料  使用 Docker Compose 快速部署 VictoriaMetrics。 使用 Helm Chart 快速在 Kubernetes中部署 VictoriaMetrics。 使用 VictoriaMetrics Operator 在 Kubernetes中部署 VictoriaMetrics。 VictoriaMetrics 集群版架构：   ",
    "description": "",
    "tags": null,
    "title": "使用VictoriaMetrics作为时序库",
    "uri": "/quickstart/victoriametrics/"
  },
  {
    "content": "由于Prometheus没有集群版本，受限于容量问题，很多公司会搭建多套Prometheus，比如按照业务拆分，不同的业务使用不同的Prometheus集群，或者按照地域拆分，不同的地域使用不同的Prometheus集群。这里是以Prometheus来举例，VictoriaMetrics、M3DB都有集群版本，不过有时为了不相互干扰和地域网络问题，也会拆成多个集群。对于多集群的协同，需要在夜莺里做一些配置，架构图如下：\n比如，我们有两个时序库，在北京搭建了一个Prometheus，在广州搭建了一个VictoriaMetrics，n9e-webapi会把这两个时序库作为DataSource，所以在n9e-webapi的配置文件中，要配置上这俩存储的地址，举例：\n[[Clusters]] # cluster name Name = \"Prom-Beijing\" # Prometheus APIs base url Prom = \"http://10.2.3.4:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 [[Clusters]] # cluster name Name = \"VM-Guangzhou\" # Prometheus APIs base url Prom = \"http://172.21.0.8:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 另外图上也可以看出，一个n9e-server对应一个时序库，所以在n9e-server的配置文件中，也需要配置对应的时序库的地址，比如北京的server，配置如下，Writers下面的Url配置的是remote write的地址，而Reader下面配置的Url是实现Prometheus原生查询接口的BaseUrl\n[Reader] # prometheus base url Url = \"http://127.0.0.1:9090\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Name = \"prom\" Url = \"http://127.0.0.1:9090/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 上海区域用的是VictoriaMetrics，所以Url略有不同，配置如下：\n[Reader] # prometheus base url Url = \"http://127.0.0.1:8481/select/0/prometheus\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 10 [[Writers]] Name = \"vm\" Url = \"http://127.0.0.1:8480/insert/0/prometheus/api/v1/write\" # Basic auth username BasicAuthUser = \"\" # Basic auth password BasicAuthPass = \"\" # timeout settings, unit: ms Timeout = 30000 DialTimeout = 10000 TLSHandshakeTimeout = 30000 ExpectContinueTimeout = 1000 IdleConnTimeout = 90000 # time duration, unit: ms KeepAlive = 30000 MaxConnsPerHost = 0 MaxIdleConns = 100 MaxIdleConnsPerHost = 100 n9e-webapi是要响应前端ajax请求的，前端会从n9e-webapi查询监控数据，n9e-webapi自身不存储监控数据，而是仅仅做了一个代理，把请求代理给后端的时序库，前端读取数据时会调用Prometheus的那些原生接口，即：/api/v1/query /api/v1/query_range /api/v1/labels 这种接口，所以注意啦，n9e-webapi中配置的Clusters下面的Url，都是要支持Prometheus原生接口的BaseUrl。\n对于n9e-server，有两个重要作用，一个是接收监控数据，然后转发给后端多个Writer，所以，Writer可以配置多个，配置文件是toml格式，[[Writers]]双中括号这种就表示数组，数据写给后端存储，走的协议是Prometheus的Remote Write，所以，所有支持Remote Write的存储，都可以使用。n9e-server的另一个重要作用，是做告警判断，会周期性从mysql同步告警规则，然后根据用户配置的Promeql调用时序库的 query 接口，所以n9e-server的Reader下面的Url，也是要配置支持Prometheus原生接口的BaseUrl。另外注意，Writer可以配置多个，但是Reader只能配置一个。比如监控数据可以写一份到Prometheus存储近期数据用于告警判断，再写一份到OpenTSDB存储长期数据，Writer就可以配置为Prometheus和OpenTSDB这两个，而Reader只配置Prometheus即可。\n",
    "description": "",
    "tags": null,
    "title": "接入多个Prom/VM/M3DB集群",
    "uri": "/quickstart/multitsdb/"
  },
  {
    "content": "对于规模相对较小的公司，比如几百台机器这个体量，个人认为单机版足够用了，使用云主机部署，性能不足可以直接升配，存储使用云存储保证，硬件故障云平台也会自动把虚拟机热迁移走，非常省心。那如果咱们体量确实比较大，或者没有云主机这种基础设施，这里会讲解集群版的部署方式。\n单中心，单集群，接入公司所有数据 首先，来讲解一种普适性比较高的架构方式，就是单中心大集群模式。比如某公司，虽然有3个机房，但是相互之间有专线打通，链路很好，为了便于维护，倾向于在中心搭建一套监控集群，其他机房的机器上只需要部署监控客户端（推荐Telegraf）即可，架构图如下：\n图中时序库使用Prometheus表示，当然，也可以选用VictoriaMetrics或者M3DB等，n9e-server部署了3台机器，n9e-webapi也部署了3台机器，当然，可以混部，即一台机器上既部署n9e-server，也部署n9e-webapi，监控客户端Telegraf要上报监控数据所以要调用n9e-server的接口，为了高可用，可以在n9e-server前面架设负载均衡，比如LVS，Telegraf的output plugin配置vip即可。负责与前端交互的n9e-webapi也部署了多个，为了高可用也是在前面架设负载均衡，这样终端用户访问的时候，也是访问vip，某个n9e-webapi如果挂掉，负载均衡可以自动感知并摘除，用户无感。\n图中redis画了两个，n9e-webapi依赖一个redis，n9e-server也依赖一个redis，在单中心、单集群模式下，可以复用一个redis。redis采用的是标准版，非集群版、非Sentinel版，这点大家要注意。\n多套存储，多套server集群，单套webapi集群 在接入多个Prom/VM/M3DB集群一节中，介绍了夜莺可以接入多个时序库，在夜莺的架构中，时序库和n9e-server是一一对应的，每接入一套时序库，就一定要部署一套n9e-server，所谓的这一套n9e-server，可以是单实例模式，也可以是多实例模式。\n比如在北京机房部署了一套Prometheus时序库，就需要在北京机房部署一套n9e-server，在广州机房部署了一套VictoriaMetrics，就需要在广州机房也部署一套n9e-server，每套n9e-server都要对应一个redis，此时，ne9-server的redis不建议与n9e-webapi的redis复用（虽然从原理上也支持），建议n9e-server的redis部署到n9e-server所在的机房，避免机房割裂时n9e-server连不上redis。\n",
    "description": "",
    "tags": null,
    "title": "生产环境部署高可用集群版",
    "uri": "/quickstart/clusters/"
  },
  {
    "content": "要说业务组这个概念，可能要先聊聊机器分组的设计，之前为此专门写过一篇公众号文章《设计篇-监控系统机器分组设计，你是我的知音么？》，建议感兴趣的朋友读一读。反正最终，以现在的认知来看，用标签来做机器分组是最合适的，虽然标签没有那么直观，但是足够灵活，再佐以业务组这个设计，做相关筛选的时候，先用业务组做第一层筛选，后面再用标签来筛，标签不够直观这个缺点可以被大大的规避。\n再说各种规则，比如告警规则、屏蔽规则、订阅规则，这些规则如果没有一种归组管理方式，就是全公司的规则都平铺到一个表格里，会显得非常混乱。比如我是某个业务线的研发人员，我肯定就关心自己业务线的那些规则，才不想看到别的业务线的规则呢。所以我们需要一个规则分组机制，类似一个namespace的东西，来对这些规则分个组。\n再就是权限，这些告警规则、监控对象、自愈脚本等，谁可以修改维护？总得关联到具体的一些人上。对于某个产品的相关规则、监控对象等，是由一批相同的人来维护的，所以抽象一个业务组这样的概念，把这些资产都归到这个业务组里，也方便配置权限。另外就是告警自愈以及机器上跑脚本，这个动作比较危险，要好好控制权限，机器隶属业务组，业务组有管理人员，这种管理模式相对比较简单清晰。\n综上，我们设计了业务组这个概念，夜莺中的各种实体大都是归到业务组的，比如监控对象、各类规则、自愈脚本等，业务组一般是一个自闭环的组织，他们自己管理自己的机器设备，自己管理自己的告警规则，跟其他的业务组没什么交集。举个例子，比如公司的DBA团队，管理了公司的所有mysql数据库以及相关的机器，这种就可以单独建立一个业务组；再比如基础网络的同学，管理了公司所有的网络设备，跟其他业务线关系不大，就可以建立一个专门的业务组，放置网络设备监控对象，以及相关的告警规则。\n当然了，公司也可能有个统一的运维团队，管理所有的告警规则，普通研发人员都不会去创建告警规则，这种情况，这个统一的运维团队可以创建一个业务组，比如叫infra，放置公司所有的监控对象，配置告警规则。其他各个团队，可以创建自己的业务组，然后订阅infra的告警规则（订阅可以跨业务组订阅），每个业务团队创建的业务组里只有订阅规则，与其他业务组隔离，比较清晰较为容易管理。\n 对于监控对象，只要有监控数据上报，n9e-server就会自动从监控对象中解析到ident标签，取其值当做监控对象，注册到mysql监控对象这个表里。刚注册上来的监控对象是未归组的，此时应该由Admin角色的人去把这些监控对象做分配，分配给不同的业务组，分完之后，各个业务组的人就自己玩自己的就好了。\n业务组的人，对于刚刚分配过来的监控对象设备，建议首先做的事情，就是打上一个bg的标签，比如bg=cloud表示相关的监控对象都隶属cloud这个Business Group。未来这些监控对象告警了，告警事件中会自动带上bg=cloud这个标签，收报警的人就可以立刻知道这是哪个bg的监控对象。\n",
    "description": "",
    "tags": null,
    "title": "探讨业务组的设计和最佳实践",
    "uri": "/best-practice/busi-group-design/"
  },
  {
    "content": "概述 所谓的告警自愈，典型手段是在告警触发时自动回调某个webhook地址，在这个webhook里写告警自愈的逻辑，夜莺默认支持这种方式。另外，夜莺还可以更进一步，配合ibex这个模块，在告警触发的时候，自动去告警的机器执行某个脚本，这种机制可以大幅简化构建运维自愈链路的工作量，毕竟，不是所有的运维人员都擅长写http server，但所有的运维人员，都擅长写脚本。这种方式是典型的物理机时代的产物，希望各位朋友用不到这个工具（说明贵司的IT技术已经走得非常靠前了）。\n架构 ibex模块，类似之前夜莺v3版本中的job模块，可以批量执行脚本，其架构非常简单，包括server和agentd两个模块，agentd周期性调用server的rpc接口，询问有哪些任务要执行，如果有分配给自己的任务，就从server拿到任务脚本信息，在本地fork一个进程运行，然后将结果上报给服务端。为了简化部署，server和agentd融合成了一个二进制，就是ibex，通过传入不同的参数来启动不同的角色。ibex架构图如下：\n项目地址  Git仓库：https://gitee.com/cnperl/ibex Linux安装包：http://49.233.250.79/ibex-1.0.0.tar.gz 其他环境的包需要自行编译，编译方法参考这里  安装启动 下载安装包之后，解压缩，在etc下可以找到服务端和客户端的配置文件，在sql目录下可以找到初始化sql脚本。\n初始化sql mysql \u003c sql/ibex.sql 启动server server的配置文件是etc/server.conf，注意修改里边的mysql连接地址，配置正确的mysql用户名和密码。然后就可以直接启动了：\nnohup ./ibex server \u0026\u003e server.log \u0026 ibex没有web页面，只提供api接口，鉴权方式是http basic auth，basic auth的用户名和密码默认都是ibex，在etc/server.conf中可以找到，如果ibex部署在互联网，一定要修改默认用户名和密码，当然，因为n9e要调用ibex，所以n9e的server.conf和webapi.conf中也配置了ibex的basic auth账号信息，要改就要一起改啦。\n启动agentd 客户端的配置非常非常简单，agentd.conf内容如下：\n# debug, release RunMode = \"release\" # task meta storage dir MetaDir = \"./meta\" [HTTP] Enable = true # http listening address Host = \"0.0.0.0\" # http listening port Port = 2090 # https cert file path CertFile = \"\" # https key file path KeyFile = \"\" # whether print access log PrintAccessLog = true # whether enable pprof PProf = false # http graceful shutdown timeout, unit: s ShutdownTimeout = 30 # max content length: 64M MaxContentLength = 67108864 # http server read timeout, unit: s ReadTimeout = 20 # http server write timeout, unit: s WriteTimeout = 40 # http server idle timeout, unit: s IdleTimeout = 120 [Heartbeat] # unit: ms Interval = 1000 # rpc servers Servers = [\"10.2.3.4:20090\"] # $ip or $hostname or specified string Host = \"telegraf01\" 客户端的HTTP接口用处不大，可以把Enable设置为false，关闭监听，重点关注Heartbeat这个部分，Interval是心跳频率，默认是1000毫秒，如果机器量比较小，比如小于1000台，维持1000没问题，如果机器量比较大，可以适当调大这个频率，比如2000或者3000，可以减轻服务端的压力。Servers是个数组，配置的是ibex-server的地址，ibex-server可以启动多个，多个地址都配置到这里即可，Host这个字段，是本机的唯一标识，有三种配置方式，如果配置为$ip，系统会自动探测本机的IP，如果是$hostname，系统会自动探测本机的hostname，如果是其他字符串，那就直接把该字符串作为本机的唯一标识。每个机器上都要部署ibex-agentd，不同的机器要保证Host字段获取的内容不能重复。\n另外，Telegraf的配置文件中，有下面这么一段：\n[agent] interval = \"10s\" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = \"0s\" flush_interval = \"10s\" flush_jitter = \"0s\" precision = \"\" hostname = \"\" omit_hostname = false 其中hostname默认留空，表示自动探测本机的hostname，如果写了具体的某个字符串，那就把写的那个字符串作为监控数据的host字段的内容，这个hostname字段要和ibex的agentd.conf中的Host字段保持一致，典型的做法有：\n Telegraf中把hostname配置为空，Telegraf自动获取本机hostname，ibex的Host配置为$hostname，ibex也会自动获取本机hostname，这样Telegraf和ibex可以获取到相同的标识内容 Telegraf中手工把hostname配置为本机的ip，ibex则把Host配置为$ip，这样二者也可以获取到相同的标识内容 Telegraf和ibex都使用某个特定写死的字符串来作为标识信息，这样也OK，但是要保证不同的机器，这个字符串不能重复  下面是启动ibex-agentd的命令：\nnohup ./ibex agentd \u0026\u003e agentd.log \u0026 另外，细心的读者应该会发现ibex的压缩包里的etc目录下有个service目录，里边准备好了两个service样例文件，便于大家使用systemd来管理ibex进程，生产环境，建议使用systemd来管理。\n",
    "description": "",
    "tags": null,
    "title": "告警自愈依赖的脚本下发执行模块",
    "uri": "/quickstart/ibex/"
  },
  {
    "content": " 本节讲述Nightingale的源码编译方式，分前后端两部分。另外，如果用到告警自愈模块，会用到ibex这个模块，本节也会一并讲解ibex模块的编译方法\n 后端 Nightingale后端采用Go语言编写，编译的前置条件就是配置Go的开发环境。\n配置Go环境 到Go官网选择对应的版本下载，我的环境是Linux，选择的go1.17.3.linux-amd64.tar.gz，直接下载到/root目录下了，然后解压缩，即Go的内容都放到了/root/go目录下了。同时准备gopath目录，如下：\ncd /root \u0026\u0026 mkdir -p gopath/src echo \"GOROOT=/root/go\" \u003e\u003e .bash_profile echo \"GOPATH=/root/gopath\" \u003e\u003e .bash_profile echo 'export PATH=$GOROOT/bin:$GOPATH/bin:$PATH' \u003e\u003e .bash_profile source .bash_profile 编译n9e git clone https://github.com/didi/nightingale.git # 国内配置一下代理，可以加速编译 export GOPROXY=https://goproxy.cn # 执行编译 cd n9e \u0026\u0026 make 编译完成之后如果生成二进制：n9e，就表示编译成功！想要快速入门Go语言？可以参考GOCN的资料！\n编译ibex 如果需要告警自愈能力，夜莺依赖ibex做命令下发执行，ibex的编译和n9e几乎一模一样，如下：\ngit clone https://gitee.com/cnperl/ibex.git # 国内配置一下代理，可以加速编译 export GOPROXY=https://goproxy.cn # 执行编译 cd ibex \u0026\u0026 make 编译完成之后如果生成二进制：ibex，就表示编译成功！\n前端 git clone https://github.com/n9e/fe-v5.git cd fe-v5 git checkout master npm install npm run build ",
    "description": "",
    "tags": null,
    "title": "源码编译夜莺前后端及告警自愈模块",
    "uri": "/quickstart/compile/"
  },
  {
    "content": "从夜莺5.1版本开始，摒弃了之前数据PUSH型的告警规则，完全使用PromQL来触发告警，相比之前确实灵活了很多，不过学习成本会略高一丢丢，权衡之下，我们认为这是值得的。下面用几条简单的PromQL来入门一下PromQL的用法，至于更多使用知识，请参考Prometheus官网\n需求1：客户端失联告警\ntarget_up == 0 target_up是夜莺自动生成的一个监控指标，用于监控采集客户端是否存活，如果采集客户端在持续上报监控数据，target_up的值就是1，如果采集客户端不再上报监控数据了，这个指标的值就变成0了，所以，PromQL如上配置，即可在监控客户端失联的时候告警，为了防止网络抖动的情况，或临时restart进程，告警规则里，持续时长一般配置为60秒，给出一定的容错周期。\n监控数据和监控客户端是如何关联的呢？就看监控数据中的ident标签，或host标签，如果有这俩标签中的一个，系统就认为这个监控数据是跟某个监控客户端相关的，就认为在这一时刻，监控客户端是活着的。\n需求2：对整机的CPU空闲率告警\nCPU空闲率的指标是cpu_usage_idle，我们直接用promql查询这个指标，可以看到，有很多Label，比如：cpu=\"cpu0\"说明这个监控指标标识的是0号cpu的数据，我们要处理整机的CPU空闲率，应该用这个Label：cpu=\"cpu-total\"\ncpu_usage_idle{cpu=\"cpu-total\"} \u003c 25 上面的promql只是指定了cpu=\"cpu-total\"这一个标签，没有指定是哪个机器，那就表示对所有机器生效，任何一台机器的CPU空闲率小于25就告警。\n 简单的PromQL一般就是指定metric，然后在{}中指定筛选标签，和之前夜莺的告警配置规则是一个道理，但是PromQL远不止可以做这些，还可以做很多更复杂的表达式计算，更多知识请参考：Prometheus官网\n 下面是一条Prometheus的告警规则，对照这条规则，咱们看一下是怎么对应到夜莺的功能的。\ngroups: - name: example # 报警规则组的名字 rules: - alert: InstanceDown # 检测job的状态，持续1分钟metrices不能访问会发给altermanager进行报警 expr: up == 0 for: 1m # 持续时间，表示持续一分钟获取不到信息，则触发报警 labels: severity: danger # 自定义标签 annotations: summary: \"Instance {{ $labels.instance }} down\" # 自定义摘要  description: \"{{ $labels.instance }} of job {{ $labels.job }} has been down for more than  groups.name，报警规则组的名称，有点像是夜莺里的业务组的概念 alert，表示告警规则名称，和夜莺里的规则名称类似 expr，是一条promql表达式，和夜莺的告警规则里的promql对应 for，对应夜莺告警规则里的持续时长 labels，对应夜莺告警规则里的附加标签 annotations，夜莺没有这个概念，夜莺在处理发送内容时，会有统一的几个模板来生成告警内容 evaluation_interval，这个是在Prometheus的global段的配置，表示规则执行频率，对应夜莺规则里的执行频率  当然，夜莺的告警规则还有一些其他配置，比如：\n 规则备注：未来发送告警消息的时候，会把备注信息带上 告警级别：默认分了3个级别，夜莺把告警级别做成一个单独的字段了，如果是Prometheus生态的话，做成标签即可 生效集群：夜莺可以接入多个Prometheus、VictoriaMetrics、M3DB集群，所以，告警规则具体是生效到哪个集群，需要有个配置指定 预案链接：每一条触发的告警，都应该对应一个预案，这是最佳实践，所以告警规则里可以指定预案链接，发送告警消息的时候也可以带上 生效配置：控制该条告警规则是否生效，如果生效，具体是在哪些时间点生效 通知媒介：配置告警发送的时候是发邮件、还是发钉钉、发企业微信等 告警接收组：配置告警通知的时候，通知哪些人，配置成组相当比较好管理，比如某人离职，只要从组里移除即可，不需要修改每条告警规则 启用恢复通知：一般告警的时候会发一条通知，恢复的时候也可以发一条通知，如果只想收告警，不想收恢复，可以在这里关闭 重复发送频率：即通道静默时间，告警发出之后，如果一直没有恢复，过xx时间之后，会重复通知 回调地址：可以配置多个webhook地址，告警之后，会依次调用，POST方式，把告警事件内容序列化为JSON，放到POST Body中，webhook对应的逻辑就可以从中解析出告警事件，做一些自动化处理逻辑  ",
    "description": "",
    "tags": null,
    "title": "告警规则",
    "uri": "/usage/alert-rule/"
  },
  {
    "content": "临时屏蔽部分告警通知 屏蔽规则，是针对告警事件的，大家在生成的告警事件中可以看到每个事件有很多标签，屏蔽规则就是针对这些标签配置过滤规则，满足过滤规则的，就不生成告警事件了。\n比如，我想屏蔽所有设备失联的告警，把标签key配置为：__name__，运算符：==，标签value：target_up即可。运算符=~表示正则，针对标签value，可以填写正则表达式，匹配一批的告警事件。运算符in表示数组包含的关系，即value可以配置多个。\n系统整体维护关掉所有通知 比如在某个时间段，全公司要做整体维护，预知会生成大量告警事件，就想把所有告警都先不发送，就只生成事件便于后面留档排查。这种情况不好做屏蔽规则，毕竟，不同的告警事件，标签很多都不一样。提供一个简单办法，把notify.py临时改个名字，这样n9e-server发送的时候就找不到这个脚本了，于是就没法发送了，此时页面上仍然可以看到告警事件。\n",
    "description": "",
    "tags": null,
    "title": "屏蔽规则",
    "uri": "/usage/alert-mute/"
  },
  {
    "content": "某个告警除了某个组的人关心，可能其他人也关心，就配置订阅规则，比如K8S平台的运维人员要作为告警接收人来接收所有K8S的告警，但是K8S的一些重大网络故障会影响整个K8S集群上面的业务方，上层业务也会关心这类告警，此时业务方就可以订阅K8S集群的部分重大告警。\n对于订阅规则，还有一种场景，比如运维团队管理了公司所有的告警规则，比如内存利用率的告警，不同业务线的人只关心自己的，那不同业务线的人就可以通过订阅规则，只订阅自己业务线的机器的告警。只需简单的为这批机器打上业务线标签，就可以通过这些标签做过滤。\n当然，有的公司推行DevOps文化，自己的狗粮自己吃，自己的服务自己运维，我这个业务线关心哪些告警，就自己创建一个业务组，配置相关策略，跟别的业务线没有任何关系，也不需要由特定的某个团队帮我配置，这样也是可以的，不同公司文化不同，组织架构职能分工不同，大家就根据自己的公司情况来规划即可。\n不过，从性能上讲，建议多使用订阅规则，让整体的告警规则变少，因为告警规则每次判断，都要查询时序库，如果告警规则量很大，对时序库的压力是很大的。当然，对性能的影响也没有那么夸张，把这个信息透传给大家，大家自行把握就好。\n",
    "description": "",
    "tags": null,
    "title": "订阅规则",
    "uri": "/usage/alert-subscribe/"
  },
  {
    "content": "告警引擎模块是n9e-server，发送也是这个模块，查看server.conf，可以看到Alerting相关的一些配置，都是和告警发送相关的：\n[SMTP] Host = \"smtp.163.com\" Port = 994 User = \"username\" Pass = \"password\" From = \"username@163.com\" InsecureSkipVerify = true Batch = 5 [Alerting] TemplatesDir = \"./etc/template\" NotifyConcurrency = 10 # use builtin go code notify by default NotifyBuiltinEnable = true [Alerting.CallScript] # built in sending capability in go code # so, no need enable script sender Enable = false ScriptPath = \"./etc/script/notify.py\" [Alerting.CallPlugin] Enable = false # use a plugin via `go build -buildmode=plugin -o notify.so` PluginPath = \"./etc/script/notify.so\" Caller = \"n9eCaller\" [Alerting.RedisPub] Enable = false # complete redis key: ${ChannelPrefix} + ${Cluster} ChannelPrefix = \"/alerts/\" [Alerting.Webhook] Enable = false Url = \"http://a.com/n9e/callback\" BasicAuthUser = \"\" BasicAuthPass = \"\" Timeout = \"5s\" Headers = [\"Content-Type\", \"application/json\", \"X-From\", \"N9E\"] SMTP相关的是邮件发送的配置；剩下的Alerting相关的配置，都可以不用动，默认夜莺支持了邮件、钉钉、企微、飞书四种通知机制；对于发送的消息内容，有个通知模板，在Alerting.TemplatesDir指定的配置目录里可以看到一堆模板文件，采用Go的模板语法，如果想修改消息内容就是修改这些模板文件即可。\n如果想二次开发，自行对告警做处理，可以启用Alerting.CallScript、Alerting.CallPlugin、Alerting.RedisPub、Alerting.Webhook等配置段，分别表示，通过脚本的方式自行处理发送告警、通过Plugin的方式来发送告警、让系统把告警消息统一推送给Redis，启用全局的Webhook，告警之后夜莺回调一个全局的Url，您可以在这个回调地址里写自己的定制逻辑。\n",
    "description": "",
    "tags": null,
    "title": "告警通知媒介",
    "uri": "/usage/alert-notify/"
  },
  {
    "content": "本节并无太多要讲的内容，菜单里的【活跃告警】，就是列出了当前所有的未恢复活跃告警，如果某个告警恢复了，就会自动从这个列表中删除，这个页面还是蛮重要的，可以作为日常巡检的一项，每天上下班的时候都看一下，看看哪些事件还没恢复，漏了处理。\n活跃告警可以删除，这个操作比较危险，一定要弄明白原理。通常情况下，我们是无需手工删除的，比如cpu_usage_idle告警了，会自动创建一条告警事件，当cpu_usage_idle的值恢复了，即这条告警变成恢复状态了，系统就会自动从活跃告警中删除，所以，通常情况下，就让系统自动处理就好了。\n但是，如果某个指标的标签发生变化，或者机器下线，相关的告警就再也无法恢复了，这个不好理解，详细解释一下：\n指标标签发生变化\n比如这个告警规则：cpu_usage_idle{cpu=\"cpu-total\"} \u003c 25，拿着这个promql去promdash查询，得到的结果可以看到，有cpu和ident两个标签，ident表示的监控对象，此时，如果我们去对象管理页面，修改这个监控对象的标签，后面新上报的监控数据，就会自动打上新标签，继续拿着刚才的promql去promdash查询，会发现表格里很快会出现新的记录，和之前的记录并存，从时序库的角度来看，就是多了一条新的series。\n就相当于：之前有个series告警了，还没恢复呢，又来了一个新的series，老的series不再上报监控数据，所以老的告警事件就永远都不会恢复了。当然，我们可以调整一下这个promql，忽略掉其他的额外的标签，比如avg(cpu_usage_idle{cpu=\"cpu-total\"}) by (ident)，这样一来，即使在监控对象的页面修改了标签，这个新的promql永远都只有ident这一个标签，因为这个新的promql是根据ident做了聚合。虽然标签稳定了，但是本人不推荐大家这么做，这样做了之后，cpu=\"cpu-total\"这个标签就丢了。\n机器下线\n比如某个机器的某个指标报警了，比如内存利用率的一个指标，还没恢复呢，这个机器下线了，上面的客户端也不再上报监控数据了，那这个告警事件就永远都不会消失了，这种情况，我们知道是怎么回事，就可以手工删除对应的告警事件。省的放那没用，还碍眼。\n 另外，左侧的业务组旁边，带有一个数字徽章，表示的是这个业务组下的活跃告警数量，这种方式可以让我们快速知道哪个业务组下的告警规则触发了及其活跃事件数量。\n",
    "description": "",
    "tags": null,
    "title": "当前告警活跃事件",
    "uri": "/usage/alert-cur-event/"
  },
  {
    "content": "相比【活跃告警】，【历史告警】数量更多，会把恢复状态的消息也存档展示，用处不是很大，主要是留档查问题用的，这个表的数量增加会比较快，大家要经常关注一下，如果表的数量很多，比如超过100万，建议做一下清理，量太大的话会影响告警处理的速度，因为每一条告警事件都要往这个表里插入。\n",
    "description": "",
    "tags": null,
    "title": "全部历史告警事件",
    "uri": "/usage/alert-his-event/"
  },
  {
    "content": "部署了Telegraf即可采集到常见的监控指标了，Telegraf具体使用前面有章节介绍了，这里不再赘述，这里主要提供常见大盘配置和告警规则配置的JSON，便于大家快速上手。\nLinux操作系统监控大盘 [ { \"name\": \"Linux基本监控指标-Telegraf采集\", \"tags\": \"HOST\", \"configs\": \"{\\\"var\\\":[{\\\"name\\\":\\\"host\\\",\\\"definition\\\":\\\"label_values(mem_used_percent, ident)\\\"}]}\", \"chart_groups\": [ { \"name\": \"Default chart group\", \"weight\": 0, \"charts\": [ { \"configs\": \"{\\\"name\\\":\\\"整机CPU空闲率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"cpu_usage_idle{cpu=\\\\\\\"cpu-total\\\\\\\", ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":35,\\\"yplotline2\\\":15,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"asc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":0,\\\"i\\\":\\\"0\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"内存可用率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mem_available_percent{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":30,\\\"yplotline2\\\":15,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"asc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":0,\\\"i\\\":\\\"1\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"硬盘利用率(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"disk_used_percent{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":87,\\\"yplotline2\\\":92,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":0,\\\"i\\\":\\\"2\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"IO.UTIL(%)\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(diskio_io_time{ident=\\\\\\\"$host\\\\\\\"}[1m])/10\\\"}],\\\"yplotline1\\\":90,\\\"yplotline2\\\":null,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"origin\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":2,\\\"i\\\":\\\"3\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"网卡每分钟丢包数（个）\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"increase(net_drop_in{ident=\\\\\\\"$host\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"net_drop_in ident:{{ident}} interface:{{interface}}\\\"},{\\\"PromQL\\\":\\\"increase(net_drop_out{ident=\\\\\\\"$host\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"net_drop_out ident:{{ident}} interface:{{interface}}\\\"}],\\\"yplotline1\\\":5,\\\"yplotline2\\\":20,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":2,\\\"i\\\":\\\"4\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"TCP_TIME_WAIT数量\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"netstat_tcp_time_wait{ident=\\\\\\\"$host\\\\\\\"}\\\"}],\\\"yplotline1\\\":null,\\\"yplotline2\\\":20000,\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":2,\\\"i\\\":\\\"5\\\"}}\", \"weight\": 0 } ] } ] } ] Linux操作系统常用告警规则 [ { \"name\": \"有地址PING不通，请注意\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"ping_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"有监控对象失联\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"target_up != 1\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"有端口探测失败，请注意\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"net_response_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"机器负载-CPU较高，请关注\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"cpu_usage_idle{cpu=\\\"cpu-total\\\"} \u003c 25\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"机器负载-内存较高，请关注\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"mem_available_percent \u003c 25\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"硬盘-IO非常繁忙\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"rate(diskio_io_time[1m])/10 \u003e 99\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"硬盘-预计再有4小时写满\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"predict_linear(disk_free[1h], 4*3600) \u003c 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网卡-入向有丢包\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"increase(net_drop_in[1m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网卡-出向有丢包\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"increase(net_drop_out[1m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"网络连接-TME_WAIT数量超过2万\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"netstat_tcp_time_wait \u003e 20000\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-有进程数为0，某进程可能挂了\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_lookup_running == 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-进程句柄限制过小\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_rlimit_num_fds_soft \u003c 2048\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"进程监控-采集失败\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"procstat_lookup_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] } ] Grafana大盘 笔者做了一个Grafana大盘：https://grafana.com/grafana/dashboards/15365使用Telegraf做采集、Prometheus做数据源、Nightingale生成的target_up指标来标识机器是否up，欢迎试用\n",
    "description": "",
    "tags": null,
    "title": "监控Linux操作系统",
    "uri": "/best-practice/linux_host/"
  },
  {
    "content": "Telegraf内置支持snmp的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在telegraf.conf中搜索inputs.snmp，即可找到对应的配置，例子如下：\n[[inputs.snmp]] agents = [\"udp://172.25.79.194:161\"] timeout = \"5s\" version = 3 agent_host_tag = \"ident\" retries = 1 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysUpTime.0\" name = \"uptime\" [[inputs.snmp.field]] oid = \"RFC1213-MIB::sysName.0\" name = \"source\" is_tag = true [[inputs.snmp.table]] oid = \"IF-MIB::ifTable\" name = \"interface\" inherit_tags = [\"source\"] [[inputs.snmp.table.field]] oid = \"IF-MIB::ifDescr\" name = \"ifDescr\" is_tag = true 上面非常关键的部分是：agent_host_tag = \"ident\"，因为夜莺对ident这个标签会特殊对待处理，把携有这个标签的数据当做隶属某个监控对象的数据，机器和网络设备都是典型的期望作为监控对象来管理的，所以snmp的采集中，我们把网络设备的ip放到ident这个标签里带上去。\n另外这个采集规则是v3的校验方法，不同的公司可能配置的校验方式不同，请各位参照telegraf.conf中那些snmp相关的注释仔细核对，如果是v2会简单很多，把上例中的如下部分：\nversion = 3 sec_name = \"managev3user\" auth_protocol = \"SHA\" auth_password = \"example.Demo.c0m\" 换成：\nversion = 2 community = \"public\" 即可，当然了，community要改成你们自己的，这里写的public只是举个例子。\ninputs.snmp.field相关的那些配置，可以采集到各个网口的监控指标，更多的使用方式请参考官网\n 另外，snmp的采集，建议大家使用专门的Telegraf来做，因为和机器、中间件等的采集频率可能不同，比如边缘交换机，我们5min采集一次就够了，如果按照默认的配置可是10s采集一次，实在是太频繁了，可能会给一些老式交换机造成比较大的压力，采集频率在telegraf.conf的最上面[agent]部分，边缘交换机建议配置为：\n[agent] interval = \"300s\" flush_interval = \"300s\" 核心交换机可以配置的频繁一些，比如60s或者120s，请各位网络工程师朋友自行斟酌。\n",
    "description": "",
    "tags": null,
    "title": "使用SNMP采集网络设备的指标",
    "uri": "/best-practice/snmp/"
  },
  {
    "content": "所谓的告警自愈，主要是靠告警规则中配置webhook，即在告警和恢复的时候，自动调用指定的webhook地址，在这个webhook中写自动处理的逻辑。这个功能大部分监控系统都支持，不过对于运维人员，这个门槛可能稍高。夜莺和ibex（类似之前v3版本中的job模块）整合，可以做到告警的时候自动执行某个脚本，运维人员只需要写脚本即可，这个门槛会低一些。\n自愈脚本 在这个页面提前准备好一些自愈脚本，python、perl、ruby都行，只要机器上有对应的运行环境，系统会为每个自愈脚本生成一个ID，这个ID后面用于配置到告警规则那里形成联动。\n执行历史 保存了所有告警自愈的调用历史，可以查看执行结果，包括脚本的stdout和stderr等\n告警规则关联自愈脚本 告警规则中可以配置回调地址，比如${ibex}/11就表示这个回调是个特殊的回调，是要和告警自愈脚本打通，11表示的是自愈脚本的编号。如果我想在某个告警规则触发告警的时候，执行第22号脚本，就配置为：${ibex}/22，告警规则和自愈脚本都是要归属某个业务组的，规则关联的脚本只能是同业务组的。\n默认情况下，脚本的执行是去告警的那个机器执行，如果想把脚本放在特定的机器执行，可以这么配置：${ibex}/11/c3-center01.bj，c3-center01.bj表示希望脚本放到这个机器执行，这个机器需要和告警规则隶属于相同的业务组。典型的是这个机器是这个业务组的中控机，在中控机上跑一些自愈逻辑。\n额外说明 对于告警回调的处理，这里额外交代一下，默认情况下，不管是告警消息还是恢复消息，都会调用webhook，有时，webhook只需要在告警的时候才做处理，在恢复的时候啥都不做，此时，webhook逻辑要去看IsRecovered这个字段，这个字段如果是1就表示是恢复消息，如果这个字段是0就表示是告警消息。如果是${ibex}这种回调，系统会自动判断，只在告警的时候才触发，恢复的时候不触发，这点也请注意。因为从使用角度，自愈脚本只需要在告警的时候运行，恢复的时候，脚本是无需执行的。\n",
    "description": "",
    "tags": null,
    "title": "告警自愈",
    "uri": "/usage/selfhealing/"
  },
  {
    "content": "Google提出了应用监控的4个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面3个指标都可以通过内嵌SDK的方式埋点采集。夜莺核心模块有两个，webapi主要是提供http接口给JavaScript调用，server主要是负责接收监控数据，处理告警规则，这两个模块都引入了Prometheus的Go的SDK，用此方式做App Performance监控，本节以夜莺的代码为例，讲解如何使用Prometheus的SDK。\nwebapi监控 webapi模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的Label做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于HTTP请求，规划4个核心Label，分别是：service、code、path、method。service标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如webapi模块，就定义为n9e-webapi，code是http返回的状态码，200就表示成功数量，其他code就是失败的，后面我们可以据此统计成功率，method是HTTP方法，GET、POST、PUT、DELETE等，比如新增用户和获取用户列表可能都是/api/n9e/users，从路径上无法区分，只能再加上method才能区分开。\npath着重说一下，表示请求路径，比如上面提到的/api/n9e/users，但是，在restful实践中，url中经常会有参数，比如获取编号为1的用户的信息，接口是/api/n9e/user/1，获取编号为2的用户信息，接口是/api/n9e/user/2，如果这俩带有用户编号的url都作为Label，会造成时序库索引爆炸，而且从业务方使用角度来看，我们也不关注编号为1的用户获取请求还是编号为2的用户获取请求，而是关注整体的GET /api/n9e/user/:id这个接口的监控数据。所以我们在设置Label的时候，要把path设置为/api/n9e/user/:id，而不是那具体的带有用户编号的url路径。夜莺用的gin框架，gin框架有个FullPath方法就是获取这个信息的，比较方便。\n首先，我们在webapi下面创建一个stat包，放置相关统计变量：\npackage stat import ( \"time\" \"github.com/prometheus/client_golang/prometheus\" ) const Service = \"n9e-webapi\" var ( labels = []string{\"service\", \"code\", \"path\", \"method\"} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"uptime\", Help: \"HTTP service uptime.\", }, []string{\"service\"}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: \"http_request_count_total\", Help: \"Total number of HTTP requests made.\", }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: \"http_request_duration_seconds\", Help: \"HTTP request latencies in seconds.\", }, labels, ) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( uptime, RequestCounter, RequestDuration, ) go recordUptime() } // recordUptime increases service uptime per second. func recordUptime() { for range time.Tick(time.Second) { uptime.WithLabelValues(Service).Inc() } } uptime变量是顺手为之，统计进程启动了多久时间，不用太关注，RequestCounter和RequestDuration，分别统计请求流量和请求延迟。Init方法是在webapi模块进程初始化的时候调用，所以进程一起，就会自动注册好。\n然后我们写一个middleware，在请求进来的时候拦截一下，省的每个请求都要去统计，middleware方法的代码如下：\nimport ( ... promstat \"github.com/didi/nightingale/v5/src/webapi/stat\" ) func stat() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Next() code := fmt.Sprintf(\"%d\", c.Writer.Status()) method := c.Request.Method labels := []string{promstat.Service, code, c.FullPath(), method} promstat.RequestCounter.WithLabelValues(labels...).Inc() promstat.RequestDuration.WithLabelValues(labels...).Observe(float64(time.Since(start).Seconds())) } } 有了这个middleware之后，new出gin的engine的时候，就立马Use一下，代码如下：\n... r := gin.New() r.Use(stat()) ... 最后，监控数据要通过/metrics接口暴露出去，我们要暴露这个请求端点，代码如下：\nimport ( ... \"github.com/prometheus/client_golang/prometheus/promhttp\" ) func configRoute(r *gin.Engine, version string) { ... r.GET(\"/metrics\", gin.WrapH(promhttp.Handler())) } 如上，每个webapi的接口的流量和成功率都可以监控到了。如果你也部署了夜莺，请求webapi的端口(默认是18000)的/metrics接口看看吧。\nInfo如果服务部署多个实例，甚至多个region，多个环境，上面的4个Label就不够用了，因为只有这4个Label不足以唯一标识一个具体的实例，此时需要env、region、instance这种Label，这些Label不需要在代码里埋点，在采集的时候一般可以附加额外的标签，通过附加标签的方式来处理即可\n server监控 server模块的监控，和webapi模块的监控差异较大，因为关注点不同，webapi关注的是HTTP接口的请求量和延迟，而server模块关注的是接收了多少监控指标，内部事件队列的长度，从数据库同步告警规则花费多久，同步了多少条数据等，所以，我们也需要在server的package下创建一个stat包，stat包下放置stat.go，内容如下：\npackage stat import ( \"github.com/prometheus/client_golang/prometheus\" ) const ( namespace = \"n9e\" subsystem = \"server\" ) var ( // 各个周期性任务的执行耗时 \tGaugeCronDuration = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_duration\", Help: \"Cron method use duration, unit: ms.\", }, []string{\"cluster\", \"name\"}) // 从数据库同步数据的时候，同步的条数 \tGaugeSyncNumber = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"cron_sync_number\", Help: \"Cron sync number.\", }, []string{\"cluster\", \"name\"}) // 从各个接收接口接收到的监控数据总量 \tCounterSampleTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"samples_received_total\", Help: \"Total number samples received.\", }, []string{\"cluster\", \"channel\"}) // 产生的告警总量 \tCounterAlertsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alerts_total\", Help: \"Total number alert events.\", }, []string{\"cluster\"}) // 内存中的告警事件队列的长度 \tGaugeAlertQueueSize = prometheus.NewGaugeVec(prometheus.GaugeOpts{ Namespace: namespace, Subsystem: subsystem, Name: \"alert_queue_size\", Help: \"The size of alert queue.\", }, []string{\"cluster\"}) ) func Init() { // Register the summary and the histogram with Prometheus's default registry. \tprometheus.MustRegister( GaugeCronDuration, GaugeSyncNumber, CounterSampleTotal, CounterAlertsTotal, GaugeAlertQueueSize, ) } 定义一个监控指标，除了name之外，还可以设置namespace、subsystem，最终通过/metrics接口暴露的时候，可以发现：监控指标的最终名字，就是$namespace_$subsystem_$name，三者拼接在一起。webapi模块的监控代码中我们看到了counter类型和histogram类型的处理，这次我们拿GaugeAlertQueueSize举例，这是个GAUGE类型的统计数据，起一个goroutine周期性获取队列长度，然后Set到GaugeAlertQueueSize中：\npackage engine import ( \"context\" \"time\" \"github.com/didi/nightingale/v5/src/server/config\" promstat \"github.com/didi/nightingale/v5/src/server/stat\" ) func Start(ctx context.Context) error { ... go reportQueueSize() return nil } func reportQueueSize() { for { time.Sleep(time.Second) promstat.GaugeAlertQueueSize.WithLabelValues(config.C.ClusterName).Set(float64(EventQueue.Len())) } } 另外，Init方法要在server模块初始化的时候调用，server的router.go中要暴露/metrics端点路径，这些就不再详述了，大家可以扒拉一下夜莺的代码看一下。\n数据抓取 应用自身的监控数据已经通过/metrics接口暴露了，后续采集规则可以在prometheus.yml中配置，prometheus.yml中有个section叫：scrape_configs可以配置抓取目标，这是Prometheus范畴的知识了，大家可以参考Prometheus官网。\n参考资料  https://prometheus.io/docs/instrumenting/clientlibs/ https://github.com/prometheus/client_golang/tree/master/examples  ",
    "description": "",
    "tags": null,
    "title": "内嵌Prometheus SDK做APM",
    "uri": "/best-practice/promapm/"
  },
  {
    "content": "StatsD简介 在内嵌Prometheus SDK做APM一节中，我们介绍了业务进程内嵌Prometheus的SDK做埋点，这种方式，会把监控数据聚合计算的逻辑放在业务进程中，比如一些平均值、分位值的计算，可能会对业务进程造成影响，本节要介绍的StatsD的方式，理念是把指标聚合计算的逻辑挪到业务进程之外，业务进程调用埋点函数的时候，通过UDP推送给StatsD，即使StatsD挂了，也不会对业务进程造成影响。\nStatsD的简介，网上一搜一大把，请大家自行Google，这里就不重复描述了。核心要理解一下StatsD的设计理念、协议、支持的各个语言的SDK（在附录里有）即可，下面直接拿一个小例子讲解如何利用Telegraf支持StatsD协议的数据，数据只要进了Telegraf了，就意味着可以推到夜莺了，夜莺就相当于支持了StatsD的埋点监控采集能力。\nTelegraf启用StatsD 在Telegraf的配置文件中搜索inputs.statsd就能看到对应的section：\n[[inputs.statsd]] protocol = \"udp\" service_address = \":8125\" percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0] metric_separator = \"_\" 启用如上配置，percentiles略微有点多，可以配置的少一点，比如percentiles = [50.0, 90.0, 99.0, 100.0]，这样整体计算存储压力也会小一些。重启Telegraf，Telegraf就会在8125端口监听udp协议，接收业务埋点数据的上报。即，Telegraf实现了StatsD的协议，可以作为StatsD的Server使用。\n在业务程序中埋点 附录里罗列了一些客户端SDK，这里笔者使用Go语言的一个SDK来测试，实现了一个很小的web程序，代码如下：\npackage main import ( \"fmt\" \"math/rand\" \"net/http\" \"time\" \"github.com/smira/go-statsd\" ) var client *statsd.Client func homeHandler(w http.ResponseWriter, r *http.Request) { start := time.Now() // random sleep \tnum := rand.Int31n(100) time.Sleep(time.Duration(num) * time.Millisecond) fmt.Fprintf(w, \"duration: %d\", num) client.Incr(\"requests.counter,page=home\", 1) client.PrecisionTiming(\"requests.latency,page=home\", time.Since(start)) } func main() { // init client \tclient = statsd.NewClient(\"localhost:8125\", statsd.TagStyle(statsd.TagFormatInfluxDB), statsd.MaxPacketSize(1400), statsd.MetricPrefix(\"http.\"), statsd.DefaultTags(statsd.StringTag(\"service\", \"n9e-webapi\"), statsd.StringTag(\"region\", \"bj\")), ) defer client.Close() http.HandleFunc(\"/\", homeHandler) http.ListenAndServe(\":8000\", nil) } 这个web服务只有一个根路径，逻辑也很简单，就是随机sleep几十个毫秒当做业务处理时间。整体逻辑是这样的：首先，我们要通过statsd.NewClient初始化一个statsd的客户端，参数中指定了StatsD的Server地址（在本例中就是Telegraf的8125），指定了所有监控指标的前缀是http.，还指定了两个全局Tag，一个是service=n9e-webapi，另一个是region=bj，通过TagStyle指定了要发送的是InfluxDB样式（因为数据是发给Telegraf的，Telegraf是InfluxDB生态的）的标签。然后，在请求的具体处理逻辑里上报了两个监控指标，一个是requests.counter，另一个是requests.latency，并且，为这俩指标指定了一个指标级别的标签page=home，整体看起来还是比较简单的。\n测试方法 上面的Go程序编译一下，启动，会作为一个web server监听在8000端口，然后周期性请求这个web server的地址做测试，这个web server接收到请求之后，就调用statsd的sdk，statsd的sdk的核心逻辑就是把数据发给Telegraf的8125，然后就是Telegraf处理聚合逻辑，聚合之后的数据每10s（默认flush频率）发给夜莺。\n在页面上，应该可以看到http_requests_latency和http_requests_counter打头的相关指标，比如http_requests_latency_mean这个指标，会看到这个指标有如下几个标签：\n ident: VM-0-4-centos 这个标签其实是Telegraf原始的host标签，夜莺的规范里叫ident，所以做了一下rename metric_type: timing 这个显然是把statsd的数据类型也做为标签了，其他数据类型还有gauge、counter、set等 page: home 这是我们代码里附到监控指标后面的标签，Telegraf自动帮解析出来了 service: n9e-webapi NewClient时候附加的全局默认标签 region: bj NewClient时候附加的全局默认标签  附录资料  Measure Anything, Measure Everything Statsd支持的的客户端SDK列表  ",
    "description": "",
    "tags": null,
    "title": "内嵌Statsd SDK做APM",
    "uri": "/best-practice/statsd/"
  },
  {
    "content": "人员组织 虽然人员组织这个菜单是放到了最后，但是文档里还是要先讲一下，绝大部分功能都依赖业务组这个概念。不过一旦业务组创建完成，就基本不怎么变动操作了，所以菜单放到了后面。\n用户管理 简单，就是管理系统中的所有用户，系统默认会初始化进去一个root账号，这个root账号是个管理角色，可以创建其他普通用户、修改其他用户的信息。用户认证也可以对接LDAP，这样就无需管理员去创建用户了，LDAP的配置在webapi.conf中。\n团队管理 团队就是用户组，包含多个用户。主要有两个作用：1、作为告警接收组，配置告警规则的时候，可以通过指定告警接收组的方式告诉系统当发生告警的时候通知哪些人；2、管理业务组，业务组下可以有多个团队，有的团队是ro权限，即只读，有的是rw权限，即读写权限。\n业务组管理 业务组相当于一个namespace，下面可以包含用户组、监控对象、告警规则、订阅规则、屏蔽规则、监控大盘、自愈脚本等，是一个可以自闭环的组织，类似一个BU，或者大的业务线。当然，一些小的组织，如果管理（主要是指管理监控对象、告警规则等）上可以自闭环（无需假手其他团队，自己这个团队就能搞定），也可以创建一个单独的业务组。比如夜莺研发团队，管理了100台机器，部署了夜莺的服务，这些机器、这些服务/机器的告警规则都是夜莺研发团队自己搞，那完全可以创建一个夜莺的业务组自己去管理。\n对象管理 对象管理主要是针对机器和网络设备的管理，如果监控数据推送给n9e-server，n9e-server会从监控数据结构中解析出监控对象的标识信息（标签中的ident或host字段），然后把监控对象信息写入数据库，之后，用户可以在对象管理页面，对监控对象做管理：包括分配这些对象给指定的业务组、给这些监控对象设置标签、修改备注等。\n这个版本的夜莺，取消了之前版本的树状结构，主要是靠业务组+标签的方式来配合解决机器分组的问题，关于这块的设计，有一篇文章来专门探讨：《探讨业务组的设计和最佳实践》\n监控看图 为了让大家尽量用一个平台搞定监控告警的所有事情，夜莺中内置了查看监控数据的能力，包括即时查询（就是类似PromDash的看图能力）、监控大盘（是类似Grafana的Dashboard配置，不过图表类型支持较少）、对象视角看图（是一个先选择监控对象再看相关监控数据的特殊视角，运维工程师会很喜欢）\n即时查询 解决以下问题：\n 检查某个监控数据是否在正常上报 测试promql，测试好的promql用于配置告警规则 生产环境故障，临时查一些监控指标的数据  监控大盘 解决以下问题：\n 日常巡检 知识传递，由专业的人做好大盘，新同事看这些大盘能更便于理解和达成监控目标 生产环境故障，查看监控数据  对象视角 在夜莺系统里，认为监控对象是个很关键的概念，值得赋予一定的管理功能。比如很多监控数据都隶属于某个监控对象，比如某个机器的磁盘利用率，或者某个交换机的某个网口的流量，那在查看这些监控数据的时候，我们会倾向于先找到对应的监控对象，再根据监控对象查找相关监控指标。对象视角的看图方式，就是为此而生。\n什么样的监控数据认为是隶属于某个监控对象的？就看监控数据中是否有ident这个tag，如果有，就认为ident指定的是监控对象的标识，就认为这条监控数据是关联到某个监控对象的，当然，Telegraf采集的监控数据，会打上host标签，标识这个监控数据是来自哪个机器，host这个标签会被夜莺rename成ident。\n告警管理 夜莺对告警的处理，分为3个规则的管理：告警规则、屏蔽规则、订阅规则；活跃告警和历史告警的展示；以及告警自愈。\n告警规则 最主要用的是告警规则，用于配置告警阈值，有些监控数据可能不想告警，比如有规划的维护周期，可以配置屏蔽规则，某个告警除了某个组的人关心，可能其他人也关心，就配置订阅规则，比如K8S平台的运维人员要作为告警接收人来接收所有K8S的告警，但是K8S的一些重大网络故障会影响整个K8S集群，上层业务也会关心这类告警，此时业务方就可以订阅K8S集群的部分重大告警。\n对于订阅规则，还有一种场景，比如运维团队管理了公司所有的告警规则，比如内存利用率的告警，不同业务线的人只关心自己的，那不同业务线的人就可以通过订阅规则，只订阅自己业务线的机器的告警。只需简单的为这批机器打上业务线标签，就可以通过这些标签做过滤。\n告警事件 活跃告警，即当前未恢复的告警，这个信息很关键，通常每天都要巡检，甚至投到作战大屏上，时刻关注；历史告警，就是所有历史告警，包括报警消息和恢复消息，算是一个存档。\n告警自愈 告警自愈是类似夜莺v4里边的job平台，可以在告警发生的时候，自动触发某个脚本的执行，比如某个宿主机报警说硬盘不够用，可以自动跑个脚本清理一下无用的数据，比如K8S宿主机的话，可以清理一些没用的镜像。\n",
    "description": "",
    "tags": null,
    "title": "功能介绍",
    "uri": "/usage/"
  },
  {
    "content": "大家对产品功能有哪些疑问可以告诉我们，我们补充到最佳实践章节。\n",
    "description": "",
    "tags": null,
    "title": "夜莺实战",
    "uri": "/best-practice/"
  },
  {
    "content": "对于MySQL、Redis、MongoDB、Tomcat、RabbitMQ、Ceph、Cassandra、Consul等等各类中间件、数据库，Telegraf都可以监控，Prometheus生态也提供了各类Exporter，直接用就好了，如果有优化建议，就提PR，夜莺生态再搞一套采集意义不大，能够良好的集成，与社区协同起来才是关键。\n本节起了一个巨大的标题，不过并不准备事无巨细的讲解每个中间件的采集配置，Telegraf的入门在这里，每个中间件都在这里成一个目录，目录下README就是文档。如果有Telegraf解决不了的，Google一下Exporter解决方案，互相补充一下。\n数据采集有了Telegraf和Exporter，问题就不大了，但是，对于某一个具体的监控对象，比如MySQL，各个指标是什么意思？应该着重关注哪些指标？哪些指标应该配置告警规则？报警的时候应该如何处理？这就是非常专业的领域知识了，欢迎大家写博客分享，并把博客链接放到本节下面 :)\n 一文说透MySQL监控，使用Prometheus生态的Exporter - By UlricQin  ",
    "description": "",
    "tags": null,
    "title": "使用Telegraf和Exporter监控中间件",
    "uri": "/best-practice/middleware/"
  },
  {
    "content": "kube-prometheus kube-prometheus 这个项目大家可以参考下。Kubernetes集群本身的运维管理，应该由一个专门的团队来做，这个专门的团队应该比较资深，对Kubernetes、对Prometheus都是比较熟悉的，用operator这种方式信手拈来。所以，在这个场景下，其实不太需要用到夜莺，那如果大家仍然想用夜莺来配置Kubernetes的告警规则、查看Kubernetes相关的监控数据，也没啥问题，只要把使用kube-prometheus启动的Prometheus接入夜莺即可。\n后面，我们会针对Kubernetes场景在夜莺里做专门的功能支持，不过目前尚未开始，这里把kube-prometheus项目中的各类告警规则，整理转换成了夜莺系统中可导入的告警规则JSON，大家如果需要的话可以自取。\n Alertmanager KubeControlPlane KubePrometheus KubeStateMetrics NodeExporter PromOperator PrometheusSelf  如果用夜莺来做告警，其实就不需要Alertmanager了，所以下面kube-prometheus项目中提供的Alertmanager相关的告警规则，其实也用不上了，不过还是放在了这里，大家看自己的场景需求吧。\n另外，kube-operator项目的告警规则，很多用到了recording rule，这些recording rule还是需要继续在Prometheus中配置，夜莺不提供recording rule的UI化管理。\nTelegraf Telegraf监控Kubernetes有两个input plugin大家可以看看，一个是kube_inventory，一个是kubernetes 具体我还没有研究，大家如果有已经研究过的，欢迎写文章分享哈\n",
    "description": "",
    "tags": null,
    "title": "监控Kubernetes",
    "uri": "/best-practice/k8s/"
  },
  {
    "content": "之前在写调研笔记的时候，测试了PING监控和TCP探测监控，调研笔记在 这里 这个章节主要给大家讲解域名URL探测。直接上测试配置：\n[[inputs.http_response]] urls = [\"https://www.baidu.com\", \"http://ulricqin.io/ping\"] response_timeout = \"5s\" method = \"GET\" fielddrop = [\"result_type\"] tagexclude = [\"result\", \"status_code\"] https://www.baidu.com 显然是通的，http://ulricqin.io/ping 这个是个假的URL，不通，我们测试一下输出的内容：\n[root@10-255-0-34 telegraf-1.20.3]# ./usr/bin/telegraf --config etc/telegraf/telegraf.conf --input-filter http_response --test 2021-12-13T04:16:43Z I! Starting Telegraf 1.20.3 \u003e http_response,host=10-255-0-34,method=GET,server=https://www.baidu.com content_length=227i,http_response_code=200i,response_time=0.028757521,result_code=0i 1639369003000000000 \u003e http_response,host=10-255-0-34,method=GET,server=http://ulricqin.io/ping result_code=5i 1639369003000000000 这里有个字段是result_code，用这个字段配置告警即可，正常可以访问的URL，result_code是0，不正常就是非0，告警规则里可以配置如下promql：\nhttp_response_result_code != 0 或者直接在夜莺的告警规则页面导入这条告警规则JSON：\n[ { \"name\": \"有URL探测失败，请注意\", \"note\": \"\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 60, \"prom_ql\": \"http_response_result_code != 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] } ] 如果想对域名返回的statuscode或者response body的内容做判断，Telegraf也是支持的，使用response_status_code和response_string_match这些字段配置，配置文件里有样例，大家可以自行参考下。\n",
    "description": "",
    "tags": null,
    "title": "监控URL",
    "uri": "/best-practice/http_response/"
  },
  {
    "content": "前言 说到日志监控，大家第一反应的可能是ELK的方案，或者Loki的方案，这两个方案都是把日志采集了发到中心，在中心存储、查看、分析，不过这个方案相对比较重量级一些，如果我们的需求只是从日志中提取一些metrics数据，比如统计一些日志中出现的Error次数之类的，则有一个更简单的方案。\n这个方案在夜莺v4版本中是有的，不过后来推荐大家客户端使用Telegraf，Telegraf没有这个能力，所以v5版本的夜莺没法监控日志，怎么办呢？这里给大家介绍一个Google出品的小工具，mtail，mtail和夜莺v4的方案类似，就是流式读取日志，通过正则表达式匹配的方式从日志中提取metrics指标，这种方式可以利用目标机器的算力，不过如果量太大，可能会影响目标机器上的业务程序，另外一个好处是无侵入性，不需要业务埋点，如果业务程序是第三方供应商提供的，我们改不了其代码，mtail此时就非常合适了。当然了，如果业务程序是我们公司的人自己写的，那还是建议用埋点的方式采集指标，mtail只是作为一个补充吧。\nmtail简介 mtail的使用方案，参考如下两个文档（下载的话参考Releases页面）：\n Deploying Programming Guide  我们拿mtail的启动命令来举例其用法：\nmtail --progs /etc/mtail --logs /var/log/syslog --logs /var/log/ntp/peerstats 通过 --progs 参数指定一个目录，这个目录里放置一堆的*.mtail文件，每个mtail文件就是描述的正则提取规则，通过 --logs 参数来指定要监控的日志目录，可以写通配符，--logs 可以写多次，上例中只是指定了 --progs 和 --logs ，没有其他参数，mtail启动之后会自动监听一个端口3903，在3903的/metrics接口暴露符合Prometheus协议的监控数据，Prometheus（或者Telegraf）就可以从 /metrics 接口提取监控数据。\n这样看起来，原理就很清晰了，mtail启动之后，根据 --logs 找到相关日志文件文件，seek到文件末尾，开始流式读取，每读到一行，就根据 --progs 指定的那些规则文件做匹配，看是否符合某些正则，从中提取时序数据，然后通过3903的/metrics暴露采集到的监控指标。当然，除了Prometheus这种/metrics方式暴露，mtail还支持把监控数据直接推给graphite或者statsd，具体可以参考：这里\nmtail样例 这里我用mtail监控一下n9e-server的日志，从中提取一下各个告警规则触发的notify的数量，这个日志举例：\n2021-12-27 10:00:30.537582 INFO engine/logger.go:19 event(cbb8d4be5efd07983c296aaa4dec5737 triggered) notify: rule_id=9 [__name__=net_response_result_code author=qin ident=10-255-0-34 port=4567 protocol=tcp server=localhost]2@1640570430 很明显，日志中有这么个关键字：notify: rule_id=9，可以用正则来匹配，统计出现的行数，ruleid也可以从中提取到，这样，我们可以把ruleid作为标签上报，于是乎，我们就可以写出这样的mtail规则了：\n[root@10-255-0-34 nightingale]# cat /etc/mtail/n9e-server.mtail counter mtail_alert_rule_notify_total by ruleid /notify: rule_id=(?P\u003cruleid\u003e\\d+)/ { mtail_alert_rule_notify_total[$ruleid]++ } 然后启动也比较简单，我这里就用nohup简单来做：\nnohup mtail -logtostderr --progs /etc/mtail --logs server.log \u0026\u003e stdout.log \u0026 mtail没有指定绝对路径，是因为我把mtail的二进制直接放在了 /usr/bin 下面了，mtail默认会监听在3903，所以我们可以用如下命令验证：\ncurl -s localhost:3903/metrics 可以看到输出如下内容：\n# HELP mtail_alert_rule_notify_total defined at n9e-server.mtail:1:9-37 # TYPE mtail_alert_rule_notify_total counter mtail_alert_rule_notify_total{prog=\"n9e-server.mtail\",ruleid=\"9\"} 6 上面的输出只是挑选了部分内容，没有全部放出来哈，这就表示正常采集到了，如果n9e的server.log中当前没有打印notify相关的日志，那请求/metrics接口是没法得到上面的输出的，可以手工配置一条必然会触发的规则，待日志里有相关输出的时候再次请求 /metrics 接口，应该就有了\n最后，我们使用Telegraf来采集一下 localhost:3903/metrics 这个地址的输出，在telegraf.conf中添加如下配置：\n[[inputs.prometheus]] urls = [\"http://localhost:3903/metrics\"] 完事重启Telegraf或者给Telegraf进程发一个SIGHUP信号：\nkill -HUP `pidof telegraf` 等一会，就可以在页面上查到相关指标了，我们拿着mtail_alert_rule_notify_total这个指标去即时查询里查，会发现查不到数据，而是出现了一个mtail_alert_rule_notify_total_counter这样的指标，看起来像是Telegraf对于Prometheus协议的监控数据，自动加了后缀，无所谓了，大家注意一下就好。如果在prometheus.yaml中配置scrape_config来抓取mtail，应该不会自动加上_counter的后缀。\n另外，mtail的配置文件如果发生变化，是需要重启mtail才能生效的，或者也是类似Telegraf那样发一个SIGHUP信号给mtail，mtail收到信号就会重新加载配置。\nmtail更多样例 mtail的github repo中有一个examples，里边有挺多例子，大家可以参考。我在这里再给大家举1个简单例子，比如我们要统计/var/log/messages文件中的 Out of memory 关键字，mtail规则应该怎么写呢？其实比上面举例的mtail_alert_rule_notify_total还要更简单：\ncounter mtail_oom_total /Out of memory/ { mtail_oom_total++ } 关于时间戳 最后说一下时间戳的问题，日志中每一行一般都是有个时间戳的，夜莺v4版本在页面上配置采集规则的时候，就是要选择时间戳的，但是mtail，上面的例子中没有处理时间戳，为啥？其实mtail也可以支持从日志中提取时间戳，如果没有配置的话，就用系统当前时间，个人认为，用系统当前时间就可以了，从日志中提取时间稍微还有点麻烦，当然，系统当前时间和日志中的时间可能稍微有差别，但是不会差很多的，可以接受，examples中的mtail样例，也基本都没有给出时间戳的提取，估计这就是最佳实践。\n",
    "description": "",
    "tags": null,
    "title": "监控日志（超级轻量的方案）",
    "uri": "/best-practice/mtail/"
  },
  {
    "content": "使用Telegraf监控MySQL也较为简单，会采集很多指标，但是具体应该关注哪些指标，是个难点，本章会提供一些例子，欢迎大家补充最佳实践。\nTelegraf的配置为了便于管理，可以拆成多个文件，放到统一目录中，使用 --config-directory 参数指定具体的目录，举例：\n# telegraf 启动命令： ./usr/bin/telegraf --config ./etc/telegraf/telegraf.conf --config-directory ./etc/telegraf.d # 后面如果修改了telegraf.conf或者修改了telegraf.d下的配置，可以通过如下方式让Telegraf重新加载配置 kill -HUP `pidof telegraf` 我们创建一个mysql.conf的配置放到telegraf.d下，内容如下：\n[[inputs.mysql]] servers = [\"root:1234@tcp(localhost:3306)/?tls=false\"] metric_version = 2 gather_global_variables = true interval_slow = \"1m\" tagexclude = [\"innodb_version\"] mysql采集插件的具体使用方式，参考 这里 的文档。下面笔者整理了监控大盘和告警规则，供大家参考：\n大盘JSON：\n[ { \"name\": \"MySQL关键指标 - by Telegraf\", \"tags\": \"MySQL\", \"configs\": \"{\\\"var\\\":[{\\\"name\\\":\\\"ident\\\",\\\"selected\\\":\\\"10-255-0-34\\\",\\\"definition\\\":\\\"label_values(mysql_uptime, ident)\\\"},{\\\"name\\\":\\\"server\\\",\\\"definition\\\":\\\"label_values(mysql_uptime{ident=\\\\\\\"$ident\\\\\\\"}, server)\\\",\\\"selected\\\":\\\"localhost_3306\\\"}]}\", \"chart_groups\": [ { \"name\": \"MySQL关键指标\", \"weight\": 0, \"charts\": [ { \"configs\": \"{\\\"name\\\":\\\"Connections\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_aborted_connects{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"aborted_connections - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"mysql_variables_max_connections{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"max_connections - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"mysql_threads_connected{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"threads_connected - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":0,\\\"i\\\":\\\"0\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Slow Queries\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_slow_queries{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"slow_queries - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":0,\\\"i\\\":\\\"1\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Open Files\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mysql_variables_open_files_limit{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"open_files_limit - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"mysql_variables_innodb_open_files{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"open_files_used - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":0,\\\"i\\\":\\\"2\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Queries per second\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_queries{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"mysql_queries - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":2,\\\"i\\\":\\\"3\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Writes per second\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_com_insert{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"command_insert - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"rate(mysql_com_update{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"command_update - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"rate(mysql_com_delete{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"command_delete - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":2,\\\"i\\\":\\\"4\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Threads\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mysql_threads_running{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"threads_running - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"mysql_threads_connected{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\",\\\"Legend\\\":\\\"threads_connected - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":16,\\\"y\\\":4,\\\"i\\\":\\\"5\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Data Reads/Writes per second\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_innodb_data_reads{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"mysql_innodb_data_reads - {{ident}} - {{server}}\\\"},{\\\"PromQL\\\":\\\"rate(mysql_innodb_data_writes{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"mysql_innodb_data_writes - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":0,\\\"y\\\":4,\\\"i\\\":\\\"6\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"InnoDB Buffer Pool Size\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mysql_variables_innodb_buffer_pool_size{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":4,\\\"i\\\":\\\"7\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"InnoDB Buffer Pool Pages\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"mysql_innodb_buffer_pool_pages_free{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"mysql_innodb_buffer_pool_pages_data{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"mysql_innodb_buffer_pool_pages_total{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":11,\\\"x\\\":0,\\\"y\\\":6,\\\"i\\\":\\\"8\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"TPS\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(mysql_com_commit{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m]) + rate(mysql_com_rollback{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"tps - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":8,\\\"x\\\":8,\\\"y\\\":2,\\\"i\\\":\\\"9\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"InnoDB Buffer Pool Hit Rate\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"100 - increase(mysql_innodb_buffer_pool_reads{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m]) / increase(mysql_innodb_buffer_pool_read_requests{ident=\\\\\\\"$ident\\\\\\\", server=\\\\\\\"$server\\\\\\\"}[5m]) * 100\\\",\\\"Legend\\\":\\\"rate - {{ident}} - {{server}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":13,\\\"x\\\":11,\\\"y\\\":6,\\\"i\\\":\\\"10\\\"}}\", \"weight\": 0 } ] } ] } ] 告警规则JSON：\n[ { \"name\": \"MySQL InnoDB buffer pool 命中率太低\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"100 - increase(mysql_innodb_buffer_pool_reads[5m]) / increase(mysql_innodb_buffer_pool_read_requests[5m]) * 100 \u003c 99\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"MySQL出现慢查询\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"rate(mysql_slow_queries[5m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"MySQL出现连接失败的情况\", \"note\": \"或许需要调整max_connections\", \"severity\": 1, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"rate(mysql_aborted_connects[5m]) \u003e 0\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"MySQL句柄快用完了\", \"note\": \"\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"100 * mysql_variables_innodb_open_files / mysql_variables_open_files_limit \u003e 90\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"MySQL近期有重启\", \"note\": \"\", \"severity\": 3, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"mysql_uptime \u003c 1800\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] }, { \"name\": \"MySQL连接数快用完了\", \"note\": \"或许需要调整max_connections\", \"severity\": 2, \"disabled\": 0, \"prom_for_duration\": 0, \"prom_ql\": \"100 * mysql_threads_connected / mysql_variables_max_connections \u003e 90\", \"prom_eval_interval\": 15, \"enable_stime\": \"00:00\", \"enable_etime\": \"23:59\", \"enable_days_of_week\": [ \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"0\" ], \"notify_recovered\": 1, \"notify_channels\": [ \"email\", \"dingtalk\", \"wecom\" ], \"notify_repeat_step\": 60, \"callbacks\": [], \"runbook_url\": \"\", \"append_tags\": [] } ] ",
    "description": "",
    "tags": null,
    "title": "监控MySQL",
    "uri": "/best-practice/mysql/"
  },
  {
    "content": "Telegraf可以监控Redis，相关配置如下：\n[[inputs.redis]] servers = [\"tcp://localhost:6379\"] 这是最简单的一个配置了，更多的参数可以参考telegraf.conf中的inputs.redis部分的注释，也可以把这个配置独立成一个单独的文件，参考 监控MySQL 章节。\n关键是下面的监控大盘配置，json如下，可以直接导入监控大盘使用。\n[ { \"name\": \"Redis关键指标 - by Telegraf\", \"tags\": \"Redis\", \"configs\": \"{\\\"var\\\":[{\\\"name\\\":\\\"ident\\\",\\\"definition\\\":\\\"label_values(redis_used_memory, ident)\\\",\\\"selected\\\":\\\"10-255-0-34\\\",\\\"multi\\\":true,\\\"allOption\\\":true},{\\\"name\\\":\\\"server\\\",\\\"definition\\\":\\\"label_values(redis_used_memory{ident=~\\\\\\\"$ident\\\\\\\"}, server)\\\",\\\"multi\\\":true,\\\"selected\\\":[\\\"all\\\"],\\\"options\\\":[\\\"localhost\\\"],\\\"allOption\\\":true},{\\\"name\\\":\\\"port\\\",\\\"definition\\\":\\\"label_values(redis_used_memory{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\"}, port)\\\",\\\"multi\\\":true,\\\"selected\\\":[\\\"all\\\"],\\\"options\\\":[\\\"6379\\\"],\\\"allOption\\\":true}]}\", \"chart_groups\": [ { \"name\": \"Default chart group\", \"weight\": 0, \"charts\": [ { \"configs\": \"{\\\"name\\\":\\\"Redis memory\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"redis_used_memory{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"redis_used_memory_lua{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"redis_used_memory_peak{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"redis_used_memory_rss{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"redis_maxmemory{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":0,\\\"y\\\":0,\\\"i\\\":\\\"0\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Redis clients\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"redis_clients{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"},{\\\"PromQL\\\":\\\"redis_blocked_clients{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":12,\\\"y\\\":0,\\\"i\\\":\\\"1\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"commands_processed / sec\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(redis_total_commands_processed{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[1m])\\\",\\\"Legend\\\":\\\"commands_processed_per_sec - {{ident}} - {{server}}:{{port}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":0,\\\"y\\\":2,\\\"i\\\":\\\"2\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"keyspace hits and misses\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"irate(redis_keyspace_hits{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"hits - {{ident}} - {{server}}:{{port}}\\\"},{\\\"PromQL\\\":\\\"irate(redis_keyspace_misses{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"misses - {{ident}} - {{server}}:{{port}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":12,\\\"y\\\":2,\\\"i\\\":\\\"3\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Network IO\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(redis_total_net_input_bytes{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"in_bytes - {{ident}} - {{server}}:{{port}}\\\"},{\\\"PromQL\\\":\\\"rate(redis_total_net_output_bytes{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"out_bytes - {{ident}} - {{server}}:{{port}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1024},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":0,\\\"y\\\":4,\\\"i\\\":\\\"4\\\"}}\", \"weight\": 0 }, { \"configs\": \"{\\\"name\\\":\\\"Expired Evicted keys\\\",\\\"QL\\\":[{\\\"PromQL\\\":\\\"rate(redis_expired_keys{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"expired_keys - {{ident}} - {{server}}:{{port}}\\\"},{\\\"PromQL\\\":\\\"rate(redis_evicted_keys{ident=~\\\\\\\"$ident\\\\\\\", server=~\\\\\\\"$server\\\\\\\", port=~\\\\\\\"$port\\\\\\\"}[5m])\\\",\\\"Legend\\\":\\\"evicted_keys - {{ident}} - {{server}}:{{port}}\\\"}],\\\"legend\\\":false,\\\"highLevelConfig\\\":{\\\"shared\\\":true,\\\"sharedSortDirection\\\":\\\"desc\\\",\\\"precision\\\":\\\"short\\\",\\\"formatUnit\\\":1000},\\\"version\\\":1,\\\"layout\\\":{\\\"h\\\":2,\\\"w\\\":12,\\\"x\\\":12,\\\"y\\\":4,\\\"i\\\":\\\"5\\\"}}\", \"weight\": 0 } ] } ] } ] ",
    "description": "",
    "tags": null,
    "title": "监控Redis",
    "uri": "/best-practice/redis/"
  },
  {
    "content": "对于监控系统的API，通常有如下几个使用场景：1、读写监控数据 2、以个人用户身份调用API做一些操作，不想去WEB上操作 3、第三方系统调用监控的API做包装，用户在第三方系统操作，实际这个第三方系统底层是调用的监控的接口。\n1.读写监控数据 对于这个场景，大家可以直接绕过夜莺，调用后端时序库的读写接口。对于写监控数据而言，如果想要走夜莺的接口，请调用n9e-server的/opentsdb/put接口，POST方法，该接口实现了OpenTSDB的数据协议，监控数据做成JSON放到HTTP Request Body中，举例：\n[ { \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 }, { \"metric\": \"cpu_usage_util\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 69.5 } ] 显然，JSON最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：\n{ \"metric\": \"cpu_usage_idle\", \"timestamp\": 1637732157, \"tags\": { \"cpu\": \"cpu-total\", \"ident\": \"c3-ceph01.bj\" }, \"value\": 30.5 } 服务端会看第一个字符是否是[，来判断上报的是数组，还是单个对象，自动做相应的Decode。如果觉得上报的内容太过占用带宽，也可以做gzip压缩，此时上报的数据，要带有Content-Encoding: gzip的Header。\nInfo注意ident这个标签，ident是identity的缩写，表示设备的唯一标识，如果标签中有ident标签，n9e-server就认为这个监控数据是来自某个机器的，会自动获取ident的value，注册到监控对象的列表里，这样后续就可以在对象看图视角页面根据监控对象筛选指标了。\n如果没有ident这个标签，就没法在对象视角的看图页面筛选看图了，只能去即时查询页面通过promql查询。\n OK，上面是推送监控数据的接口，至于查询监控数据，请大家直接调用后端时序库的接口，即Prometheus那些/api/v1/query /api/v1/query_range之类的接口。相关接口文档请参考：Prometheus官网\n2.以个人身份模仿WEB操作 这种方式，页面上JavaScript可以调用的所有接口，你都可以用程序调用，打开chrome的开发者工具，扒拉这些接口，还是非常容易的。当然，要先登录，登录调用webapi模块的/api/n9e/auth/login接口，系统使用jwt认证，如果登录成功，会返回access_token和refresh_token，每次调用的时候都要把access_token放到Header里，access_token差不多15分钟过期，之后可以重新调用登录接口换token，也可以调用/api/n9e/auth/refresh接口用refresh_token换一个新的access_token，当然，也会顺道返回一个新的refresh_token，举例：\n# 调用登录接口拿到access_token和refresh_token记录下来，后面调用其他接口的时候会用到 [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/login' -d '{\"username\": \"root\", \"password\": \"root.2020\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\",\"user\":{\"id\":1,\"username\":\"root\",\"nickname\":\"超管\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true}},\"err\":\"\"} # access_token放到Authorization这个Header里，Bearer的验证方式 [root@10-255-0-34 ~]# curl -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzA1OSwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.nJ56Pc7qS5Ik_UaVmlNWu_QlABaBc4pZ_WkU45u2wWk\" 'http://localhost:18000/api/n9e/self/profile' {\"dat\":{\"id\":1,\"username\":\"root\",\"nickname\":\"超管\",\"phone\":\"\",\"email\":\"\",\"portrait\":\"\",\"roles\":[\"Admin\"],\"contacts\":{},\"create_at\":1637545881,\"create_by\":\"system\",\"update_at\":1637546351,\"update_by\":\"root\",\"admin\":true},\"err\":\"\"} # 如果token过期了，后端会返回异常HTTP状态码，此时要调用refresh接口换取新的token [root@10-255-0-34 ~]# curl -X POST 'http://localhost:18000/api/n9e/auth/refresh' -d '{\"refresh_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzc4NTksInJlZnJlc2hfdXVpZCI6ImIxNTcyMjgwLWZlNzAtNDhjZi1hNDQ3LWVlMjVhZmYwMjRhZCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.JKsbfTYBCOOfR_oPsf496N9ml9yXbP7BHb4E8Yfnzbo\"}' {\"dat\":{\"access_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCIsImF1dGhvcml6ZWQiOnRydWUsImV4cCI6MTYzNzgyMzMxOCwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.2BeWyYfcnRi3qw69zecaaeFnPFUNAGsiPIZBBnd5lug\",\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2MzgzMzgxMTgsInJlZnJlc2hfdXVpZCI6IjAxMzkzYzkxLTk5MWItNGE0Yi04ODk2LTJhZGRjMDUwYjcxMCsrMS1yb290IiwidXNlcl9pZGVudGl0eSI6IjEtcm9vdCJ9.zFZaRYcJI6G5maSgDVF-jZzxQ3Tb5dybIqufJhBy034\"},\"err\":\"\"} 3.第三方系统调用夜莺 比如第三方系统想获取夜莺中的所有未恢复告警，或者获取夜莺中的全量用户列表，这些需求，建议走/v1/n9e打头的接口，这些接口走BasicAuth认证，BasicAuth的用户名和密码在webapi.conf中可以找到，就是BasicAuth那个section的配置。当前这个阶段，还没有哪个系统会依赖夜莺的接口，所以，这个/v1/n9e前缀的接口目前一个都还没有提供，不过代码框架已经搭起来了，代码在src/webapi/router/router.go文件中，service那个路由Group，如果贵司要封装夜莺的接口，可能要在这个路由分组下加一些路由配置了。作为开源软件，说清楚原理就好了，如果贵司仍然搞不明白可以联系我们，我们提供商业技术支持服务 :-)\n",
    "description": "",
    "tags": null,
    "title": "API",
    "uri": "/api/"
  },
  {
    "content": "  多集群部署的时候MySQL、Redis分别部署几个？   公众号有个视频讲解了 如何接入多个时序存储， 请先查看。MySQL是只需要一个，不管部署多少个n9e-webapi多少个n9e-server。redis也可以只用一个，所有的n9e-webapi和n9e-server共享，但是，如果部署多套n9e-server（一套n9e-server可能是多个n9e-server实例组成一个集群）分布在不同的地域，网络链路可能不太好，此时是建议一套n9e-server对应一个redis，n9e-webapi自己用一个redis\n 架构中可以完全不用Prometheus吗？   原理上是可以的，Prometheus在夜莺的架构中，是作为时序库使用，除了Prometheus，也可以使用VictoriaMetrics、M3DB等，因为这些时序库都实现了Prometheus的Querier接口，而夜莺依赖这些接口拉取监控数据和做告警判断。\n 机器只能归属一个业务组吗？   是的。\n用户可能会继续追问：一台机器可能有混部的情况，同时部署多个服务，那如何来描述这种现实（毕竟，软件就是对现实的建模）呢？其实，这种关联信息在监控中是使用标签来反映的。比如某个监控数据带有这几个标签：host=cs-node001.hna service=n9e-server method=get api=/ping statuscode=200 表示：这个监控数据是n9e-server这个服务的，来自cs-node001.hna这个机器，这条监控数据描述的是/ping接口，/ping接口是个get接口，statuscode是200，这个信息非常丰富，里边既有服务名称，又有机器信息，通过这种方式我们就知道服务和机器的关联关系。\n大家不要把CMDB中的机器分组需求放到夜莺中来维护，这是职责上的错配。\n那为何还要提供业务组这个概念？岂不是多余了？业务组更多的是想处理权限的问题，比如我们的告警规则、屏蔽规则、订阅规则、监控大盘、自愈脚本等，只能由我们自己管理，不能被无关人员修改了或删除了。把这些规则类信息放到某个业务组中，只有这个业务组的管理员有权限管理，其他人就没有权限乱搞了。\n那机器为何要归属业务组？其实也是从权限上考虑的，自愈脚本是归属业务组的，脚本的执行需要有权限控制，不能随便去机器上运行，现在的控制逻辑是脚本只能在自己的业务组下辖的机器上运行。\n综上，坦白讲，我没有想到什么场景是必须让机器（即系统中的监控对象）归属到多个业务组的。关键原因是监控数据上报的时候就是自描述的，已经包含了各类信息了，不需要通过外挂的方式重新归类监控数据，而机器的分组，虽然有需求，但那是CMDB的需求，也不是监控要处理的。\n更新：另外，机器（即系统中的监控对象）可以打标签，可以通过标签体现一定的分类信息，比如region=bj env=prod表示bj区的生产环境的机器。标签是K=V的格式，K可以体现维度信息，大部分归类需求都可以通过标签来解决，唯独比较麻烦的是，在同一个维度有多个值的情况，比如K=V1 K=V2这种情况，这种情况目前不支持，因为标签信息会被附到监控对象的时序数据上，时序数据的标签是map结构，所以K=V1 K=V2这种K相同的情况会产生覆盖，故而页面上监控对象打标签的时候压根就不允许这种标签。\n 为何我的target_up指标一会是0一会是1，导致一会有告警一会又恢复了   这个很可能是因为调整了客户端采集上报频率导致的，默认Telegraf上报频率是10s，不会有这个问题，n9e-server每15s生成一次target_up的值，标识机器是否在正常上报数据，如果发现机器有指标在上报，target_up就置为1，否则就是0，如果把客户端采集上报频率调大，比如改成60s，那n9e-server在某些周期检查的时候，确实就发现客户端没有上报数据，毕竟上报频率太大了。此时可以调整server.conf的配置，把检测客户端是否存活的周期也放大一些，比如调整为60秒：\n[NoData] Metric = \"target_up\" # unit: second Interval = 60 告警规则也可以针对这种情况做一些调整，比如改成：\n# 告警规则的持续时长设置为0，该PromQL表示130s内一直都没有监控数据上报，故而要报警。 max_over_time(target_up[130s]) == 0 target_up指标是0，还有可能的原因是客户端夯住了，可以重启一下客户端试试，或者是客户端所在机器当前压力过大，影响了客户端到服务端的网络通信。\n 夜莺用的redis支持cluster版本或者sentinel版本吗？   不支持，就是用的单机版，改造成cluster版本或者sentinel应该也没啥太大问题，一般公有云会提供高可用的redis，一主一从那种，足够用了，自己搭建也可以，机器挂掉的概率其实很小，满足sla问题不大的\n Telegraf上报的主机标识默认用的机器名，可以让它自动上报IP作为本机标识吗？   可以让它上报IP作为唯一标识，但是要想自动获取IP，做不到。个人建议是使用一些批量执行工具，比如ansible之类的，批量部署Telegraf，部署脚本里自动获取目标机器的IP，然后填充到telegraf.conf中。\n 触发告警和触发恢复的逻辑是什么？   告警规则里有3个配置非常关键，promql、执行频率、持续时长，意思就是按照执行频率，每隔一段时间执行promql查询（即时查询，即调用Prometheus协议的/api/v1/query接口），如果查到数据就认为触发了阈值，触发了阈值是否会产生告警事件，不一定，还要看持续时长，如果持续时长为0，就相当于不用等待，触发了阈值就立马生成事件，如果持续时长大于0，那就要等待，要保证持续时长这段时间内，每次执行promql的查询都触发阈值，才认为应该生成事件。持续时长就相当于prometheus.yml中的alert rule中的for。\n比如promql为 cpu_usage_idle{cpu=\"cpu-total\"} \u003c 20，执行频率是10s，持续时长是60s，就表示在60s内每10s执行一次promql查询，看promql查询是否返回内容，如果6次都返回了，说明应该生成告警事件。\n恢复的逻辑：比如已经产生了告警事件，然后再次拿着promql去查询，发现没有返回内容，那就说明当前的监控数据已经不符合promql中指定的阈值条件了，就表示恢复了。当然， 如果数据丢点了，promql自然也查不到，这种情况也是会报恢复，因为夜莺确实无法区分到底是因为丢点了，还是因为没有满足阈值而导致没有返回内容。那你可能会问，把promql解析一下，去掉promql中的操作符和阈值，只拿着前面部分去查询，不就能区分到底是没数据还是因为没有满足阈值了吗？其实很难，上面举例的promql是一种简单情况，复杂的promql非常复杂，没法这么轻易的拿掉操作符和阈值。\n 如何监控机器的CPU、内存、磁盘、IO、网络、进程？   这个问题，文档里有答案，Telegraf章节，有个调研笔记的链接，调研笔记中描述的很清楚了，除了机器层面的这些监控项，还有讲如何做PING监控，TCP探测等\n 夜莺可以接入到Grafana来展示吗？   可以。但不是把夜莺作为DataSource，因为实在是没必要。夜莺后端可以接入多个时序库：Prometheus、M3DB、VictoriaMetrics等，这些时序库都可以直接作为Grafana的DataSource，所以，只要监控数据进了这些时序库了，Grafana就可以直接展示了\n 夜莺可以配置InfluxDB的QL做告警规则吗？   不支持，当前只支持配置promql，夜莺接入时序库，有两个层面的接入，一是通过remote write，把夜莺收到的数据转发给时序库，所有支持remote write 接口的存储都可以通过这种方式接入夜莺，接收夜莺转发过来的数据；二是时序库如果开放兼容Prometheus的Querier接口，那夜莺还可以读取时序库的数据做告警判断，即Prometheus、M3DB、VictoriaMetrics、Thanos等这些存储，都完全兼容Prometheus的Querier接口，则夜莺可以配置告警规则，从这些存储中读取监控数据做告警判断。而OpenTSDB、InfluxDB等，因为不支持Prometheus的Querier接口，所以夜莺的告警规则，没法读取这些存储的数据做判断，这些存储只能作为remote write的写入端。\n 从哪里获取微信机器人token？   首先，是企业微信，不是微信，在企业微信里建个群，点开群管理，添加机器人，完事查看这个机器人的信息，即可看到webhook地址，webhook地址中包含一个key的参数，key=后面就是token。拿着这个token，去夜莺里创建一个用户，比如就叫xx企微机器人，给这个用户设置一下Wecom Robot Token，配置为刚才从webhook中获取的token，后面把这个人加入告警接收组，相关的告警就会发给企业微信的这个群组。\n 监控对象列表中如何添加监控对象？看到监控对象列表和对象视角都是空的   公众号的视频教程要整体看一遍，就理解整个设计了。简而言之，监控数据需要上报给n9e-server，然后由n9e-server转发给时序库，即监控数据要流经n9e-server，n9e-server才有可能从监控数据中提取ident标签的值，n9e-server会把ident标签的值作为监控对象注册到数据库中，才能在列表中看到。如果监控数据的整个传输过程没有流经n9e-server，或监控数据中没有ident标签，也就没法提取到了。\n夜莺可以支持Telegraf作为客户端采集器，也可以支持grafana-agent作为采集器，这俩采集器实际都没法上报ident标签，但是Telegraf会上报host标签，grafana-agent会上报agent_hostname标签，这俩标签会被自动转换为ident字段。\n当然，即使没有注册到对象视角中，其实也不耽误，没啥大不了的，只是未来看监控图表的时候，没法使用对象视角看图罢了。后面夜莺也会持续优化，增加自定义视图，到时候对象视角的看图可能就可有可无了。\n v5版本如何通过api接口上报数据的时候顺便带上alias字段？   v5目前支持的上报接口是opentsdb的协议、remote write协议、datadog的协议，都不支持alias字段，而数据库中也干掉了这个字段，所以，v5没法通过api上报这个字段了，不过v5有备注字段，和自定义标签字段，可以考虑用这俩字段放置别名，这需要直接操作DB，或者通过API修改监控对象，总之，无法通过上报数据的接口来搞定\n v5邮件告警的服务器配置（smtp）在哪里？   v5.4（含）之后的版本，在server.conf中，v5.4之前的版本，在etc/script/notify.py中，脚本的前面几行，很容易找到\n 我在A业务组配置的告警规则，为何收到了B业务组的机器的告警？   告警规则的逻辑可以查看009号问题，每次就是用promql查询时序库，而时序库里是没有业务组的信息的，所以promql就生效到了全量的监控对象上了。推荐做法：a业务组的机器，统一打上bg=a的标签，b业务组的机器统一打上bg=b的标签，配置告警规则的时候，要带上这个标签做筛选，比如 cpu_usage_idle{bg=\"a\"}\u003c15 就表示只有bg=a这个标签的机器生效，即只有a业务组的机器生效。\n近期夜莺新版本支持在告警规则配置的时候指定只在本业务组生效，一定程度上解决了这个问题，后续也会支持把业务组直接作为标签附到时序数据上，到时候就更方便了\n Telegraf推送数据给n9e-server，如何加上认证机制保证安全？   Telegraf使用datadog的output吐数据给n9e-server（版本要在5.2.1以上）\n[[outputs.datadog]] timeout = \"5s\" url = \"http://localhost:19000/datadog/api/v1/series\" apikey = \"datadog-api-key\" n9e-server中加上这个配置：\n[BasicAuth] apiKey = \"datadog-api-key\" 注意：这样配置之后，表示n9e-server的所有请求都走basic auth认证，原来Telegraf通过openTSDB的接口吐数据的链路就走不通了\n 从低版本怎么向高版本升级？   首先去github的 releases 页面 找到自己的版本，然后挨个查看每个比你高的版本，看看各个版本的release log中写了要更新哪些内容，重点关注sql相关的，比如你的版本是5.1.0，当前版本是5.3.0，那你要看 ( 5.1.0, 5.3.0 ]之间的所有版本，从低到高挨个查看，把每个版本的release log中的sql都执行一遍（如果release log中没有提sql语句，说明这几个版本没有DB表结构变更，那更简单了），最后替换n9e二进制和etc下的内容到最新版本，如果你之前etc下有些特殊配置，记得要基于最新的配置文件再修改下\n telegraf的基本配置和中间件采集的配置都放到一个telegraf.conf中不好管理怎么办？   telegraf启动的时候支持两个参数–config和–config-directory，这俩参数可以一并使用，通过–config指定主配置文件，通过–config-directory指定配置目录，各种非通用的配置，都可以放到配置目录里，每个配置文件以.conf结尾，这样telegraf就可以都识别到了，比如：\n./usr/bin/telegraf --config etc/telegraf/telegraf.conf --config-directory etc/telegraf.d 然后我做了一个mysql.conf放到telegraf.d目录下，专门用于监控mysql，内容如下，供大家参考：\n[[inputs.mysql]] servers = [\"root:1234@tcp(localhost:3306)/?tls=false\"] metric_version = 2 gather_global_variables = true interval_slow = \"1m\" tagexclude = [\"innodb_version\"] ",
    "description": "",
    "tags": null,
    "title": "FAQ",
    "uri": "/faq/"
  },
  {
    "content": " Telegraf Windows版本的安装，保姆级教程 - by SL Telegraf Linux版本的安装，保姆级教程 - by SL 弃用Prometheus，搭建单机版本的VictoriaMetrics - by SL 一键部署夜莺到Kubernetes - by 陶柒 使用Telegraf做夜莺5.0的数据采集，样例包含Linux基本信息采集、MySQL、Redis的采集 - by 柴今栋@艾派 修改notify.py为夜莺增加短信通知能力 - by 柴今栋@艾派 使用notify.py接入阿里云语音通知 - by 果 Oracle的简单监控实现 - by 柴今栋@艾派 RocketMQ简单监控的实现 - by 柴今栋@艾派 手把手教你接入钉钉告警 一文说透MySQL监控，使用Prometheus生态的Exporter  ",
    "description": "",
    "tags": null,
    "title": "社区用户实践分享",
    "uri": "/usecase/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": " 夜莺是新一代国产智能监控系统。对云原生场景、传统物理机虚拟机场景，都有很好的支持，10分钟完成搭建，1小时熟悉使用，经受了滴滴生产环境海量数据的验证，希望打造国产监控的标杆之作，一起参与进来吧！\n 新版简介 Nightingale在2020.3.20发布v1版本，目前是v5.0版本，从这个版本开始，与Prometheus、VictoriaMetrics、Grafana、Telegraf等生态做了协同集成，力争打造国内最好用的开源运维监控系统。\n与Open-Falcon的区别 因为开发Open-Falcon和Nightingale的是一拨人，所以很多社区伙伴会比较好奇，为何要新做一个监控开源软件。核心点是Open-Falcon和Nightingale的差异点实在是太大了，Nightingale并非是Open-Falcon设计逻辑的一个延续，就看做两个不同的软件就好。\nOpen-Falcon是14年开发的，当时是想解决Zabbix的一些容量问题，可以看做是物理机时代的产物，整个设计偏向运维视角，虽然数据结构上已经开始设计了标签，但是查询语法还是比较简单，无法应对比较复杂的场景。\nNightingale直接支持PromQL，支持Prometheus、M3DB、VictoriaMetrics多种时序库，支持Telegraf做监控数据采集，支持Grafana看图，整个设计更加云原生，虽然也保留了机器归组的逻辑以应对物理机时代的需求，但是设计上，更倾向于使用标签来分组，而不是HostGroup或者树形结构。\n与Prometheus的区别 Nightingale可以简单看做是Prometheus的一个企业级版本，把Prometheus当做Nightingale的一个内部组件-时序库，当然，也不是必须的，时序库除了Prometheus，还可以使用VictoriaMetrics、M3DB等。各种Exporter也可以继续使用，不过我们更推荐使用All-in-one的Telegraf，运维代价会更小一些。\nNightingale可以接入多个Prometheus/M3DB/VictoriaMetrics，可以允许用户在页面上配置告警规则、屏蔽规则、订阅规则，在页面上查看告警事件，配置告警自愈机制，管理监控对象，配置监控大盘等，就把Nightingale看做是Prometheus的一个WEBUI也是可以的，不过实际上，它远远不止是一个WEBUI，用一下就会深有感触。\n项目代码  后端：💡 https://github.com/didi/nightingale 前端：💡 https://github.com/n9e/fe-v5  系统架构 夜莺5.1的设计非常简单，核心是server和webapi两个模块，webapi无状态，放到中心端，承接前端请求，将用户配置写入数据库；server是告警引擎和数据转发模块，一般随着时序库走，一个时序库就对应一套server，每套server可以只用一个server实例，也可以多个实例组成集群，server可以接收Telegraf上报的数据，写入后端时序库，周期性从数据库同步告警规则，然后查询时序库做告警判断。每套server依赖一个redis。架构图如下：\n加入社区  微信公号:__n9e__（夜莺监控） 知识星球：夜莺开源社区  钉钉交流群：\n",
    "description": "",
    "tags": null,
    "title": "夜莺手册",
    "uri": "/"
  }
]
