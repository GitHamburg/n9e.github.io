<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数据采集 on N9E</title>
    <link>https://n9e.github.io/data-collection/</link>
    <description>Recent content in 数据采集 on N9E</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://n9e.github.io/data-collection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用SNMP采集网络设备的指标</title>
      <link>https://n9e.github.io/data-collection/snmp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/data-collection/snmp/</guid>
      <description>Telegraf内置支持snmp的采集，本节给一个入门例子，让大家快速上手，更多具体知识可以参考这里。在telegraf.conf中搜索inputs.snmp，即可找到对应的配置，例子如下：
[[inputs.snmp]] agents = [&amp;#34;udp://172.25.79.194:161&amp;#34;] timeout = &amp;#34;5s&amp;#34; version = 3 agent_host_tag = &amp;#34;ident&amp;#34; retries = 1 sec_name = &amp;#34;managev3user&amp;#34; auth_protocol = &amp;#34;SHA&amp;#34; auth_password = &amp;#34;example.Demo.c0m&amp;#34; [[inputs.snmp.field]] oid = &amp;#34;RFC1213-MIB::sysUpTime.0&amp;#34; name = &amp;#34;uptime&amp;#34; [[inputs.snmp.field]] oid = &amp;#34;RFC1213-MIB::sysName.0&amp;#34; name = &amp;#34;source&amp;#34; is_tag = true [[inputs.snmp.table]] oid = &amp;#34;IF-MIB::ifTable&amp;#34; name = &amp;#34;interface&amp;#34; inherit_tags = [&amp;#34;source&amp;#34;] [[inputs.snmp.table.field]] oid = &amp;#34;IF-MIB::ifDescr&amp;#34; name = &amp;#34;ifDescr&amp;#34; is_tag = true 上面非常关键的部分是：agent_host_tag = &amp;quot;ident&amp;quot;，因为夜莺对ident这个标签会特殊对待处理，把携有这个标签的数据当做隶属某个监控对象的数据，机器和网络设备都是典型的期望作为监控对象来管理的，所以snmp的采集中，我们把网络设备的ip放到ident这个标签里带上去。
另外这个采集规则是v3的校验方法，不同的公司可能配置的校验方式不同，请各位参照telegraf.conf中那些snmp相关的注释仔细核对，如果是v2会简单很多，把上例中的如下部分：
version = 3 sec_name = &amp;#34;managev3user&amp;#34; auth_protocol = &amp;#34;SHA&amp;#34; auth_password = &amp;#34;example.</description>
    </item>
    <item>
      <title>内嵌Prometheus SDK做APM</title>
      <link>https://n9e.github.io/data-collection/promapm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/data-collection/promapm/</guid>
      <description>Google提出了应用监控的4个黄金指标，分别是：流量、延迟、错误、饱和度，其中前面3个指标都可以通过内嵌SDK的方式埋点采集。夜莺核心模块有两个，webapi主要是提供http接口给JavaScript调用，server主要是负责接收监控数据，处理告警规则，这两个模块都引入了Prometheus的Go的SDK，用此方式做App Performance监控，本节以夜莺的代码为例，讲解如何使用Prometheus的SDK。
webapi监控 webapi模块主要统计两个内容，一个是请求的数量统计，一个是请求的延迟统计，统计时，要用不同的Label做维度区分，后面就可以通过不同的维度做多种多样的统计分析，对于HTTP请求，规划4个核心Label，分别是：service、code、path、method。service标识服务名称，要求全局唯一，便于和其他服务名称区分开，比如webapi模块，就定义为n9e-webapi，code是http返回的状态码，200就表示成功数量，其他code就是失败的，后面我们可以据此统计成功率，method是HTTP方法，GET、POST、PUT、DELETE等，比如新增用户和获取用户列表可能都是/api/n9e/users，从路径上无法区分，只能再加上method才能区分开。
path着重说一下，表示请求路径，比如上面提到的/api/n9e/users，但是，在restful实践中，url中经常会有参数，比如获取编号为1的用户的信息，接口是/api/n9e/user/1，获取编号为2的用户信息，接口是/api/n9e/user/2，如果这俩带有用户编号的url都作为Label，会造成时序库索引爆炸，而且从业务方使用角度来看，我们也不关注编号为1的用户获取请求还是编号为2的用户获取请求，而是关注整体的GET /api/n9e/user/:id这个接口的监控数据。所以我们在设置Label的时候，要把path设置为/api/n9e/user/:id，而不是那具体的带有用户编号的url路径。夜莺用的gin框架，gin框架有个FullPath方法就是获取这个信息的，比较方便。
首先，我们在webapi下面创建一个stat包，放置相关统计变量：
package stat import ( &amp;#34;time&amp;#34; &amp;#34;github.com/prometheus/client_golang/prometheus&amp;#34; ) const Service = &amp;#34;n9e-webapi&amp;#34; var ( labels = []string{&amp;#34;service&amp;#34;, &amp;#34;code&amp;#34;, &amp;#34;path&amp;#34;, &amp;#34;method&amp;#34;} uptime = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: &amp;#34;uptime&amp;#34;, Help: &amp;#34;HTTP service uptime.&amp;#34;, }, []string{&amp;#34;service&amp;#34;}, ) RequestCounter = prometheus.NewCounterVec( prometheus.CounterOpts{ Name: &amp;#34;http_request_count_total&amp;#34;, Help: &amp;#34;Total number of HTTP requests made.&amp;#34;, }, labels, ) RequestDuration = prometheus.NewHistogramVec( prometheus.HistogramOpts{ Buckets: []float64{.01, .1, 1, 10}, Name: &amp;#34;http_request_duration_seconds&amp;#34;, Help: &amp;#34;HTTP request latencies in seconds.</description>
    </item>
    <item>
      <title>内嵌Statsd SDK做APM</title>
      <link>https://n9e.github.io/data-collection/statsd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/data-collection/statsd/</guid>
      <description>StatsD简介 在内嵌Prometheus SDK做APM一节中，我们介绍了业务进程内嵌Prometheus的SDK做埋点，这种方式，会把监控数据聚合计算的逻辑放在业务进程中，比如一些平均值、分位值的计算，可能会对业务进程造成影响，本节要介绍的StatsD的方式，理念是把指标聚合计算的逻辑挪到业务进程之外，业务进程调用埋点函数的时候，通过UDP推送给StatsD，即使StatsD挂了，也不会对业务进程造成影响。
StatsD的简介，网上一搜一大把，请大家自行Google，这里就不重复描述了。核心要理解一下StatsD的设计理念、协议、支持的各个语言的SDK（在附录里有）即可，下面直接拿一个小例子讲解如何利用Telegraf支持StatsD协议的数据，数据只要进了Telegraf了，就意味着可以推到夜莺了，夜莺就相当于支持了StatsD的埋点监控采集能力。
Telegraf启用StatsD 在Telegraf的配置文件中搜索inputs.statsd就能看到对应的section：
[[inputs.statsd]] protocol = &amp;#34;udp&amp;#34; service_address = &amp;#34;:8125&amp;#34; percentiles = [50.0, 90.0, 99.0, 99.9, 99.95, 100.0] metric_separator = &amp;#34;_&amp;#34; 启用如上配置，percentiles略微有点多，可以配置的少一点，比如percentiles = [50.0, 90.0, 99.0, 100.0]，这样整体计算存储压力也会小一些。重启Telegraf，Telegraf就会在8125端口监听udp协议，接收业务埋点数据的上报。即，Telegraf实现了StatsD的协议，可以作为StatsD的Server使用。
在业务程序中埋点 附录里罗列了一些客户端SDK，这里笔者使用Go语言的一个SDK来测试，实现了一个很小的web程序，代码如下：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/smira/go-statsd&amp;#34; ) var client *statsd.Client func homeHandler(w http.ResponseWriter, r *http.Request) { start := time.Now() // random sleep 	num := rand.Int31n(100) time.Sleep(time.Duration(num) * time.Millisecond) fmt.Fprintf(w, &amp;#34;duration: %d&amp;#34;, num) client.Incr(&amp;#34;requests.counter,page=home&amp;#34;, 1) client.</description>
    </item>
    <item>
      <title>使用Telegraf和Exporter监控中间件</title>
      <link>https://n9e.github.io/data-collection/middleware/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/data-collection/middleware/</guid>
      <description>对于MySQL、Redis、MongoDB、Tomcat、RabbitMQ、Ceph、Cassandra、Consul等等各类中间件、数据库，Telegraf都可以监控，Prometheus生态也提供了各类Exporter，直接用就好了，如果有优化建议，就提PR，夜莺生态再搞一套采集意义不大，能够良好的集成，与社区协同起来才是关键。
本节起了一个巨大的标题，不过并不准备事无巨细的讲解每个中间件的采集配置，Telegraf的入门在这里，每个中间件都在这里成一个目录，目录下README就是文档。如果有Telegraf解决不了的，Google一下Exporter解决方案，互相补充一下。
数据采集有了Telegraf和Exporter，问题就不大了，但是，对于某一个具体的监控对象，比如MySQL，各个指标是什么意思？应该着重关注哪些指标？哪些指标应该配置告警规则？报警的时候应该如何处理？这就是非常专业的领域知识了，欢迎大家写博客分享，并把博客链接放到本节下面 :)
 MySQL监控分享 By xxx  </description>
    </item>
  </channel>
</rss>