<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>夜莺手册 on N9E</title>
    <link>https://n9e.github.io/</link>
    <description>Recent content in 夜莺手册 on N9E</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://n9e.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>安装部署</title>
      <link>https://n9e.github.io/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/quickstart/</guid>
      <description>如果您对Docker的使用非常熟悉，建议利用Docker compose的方式快速启动测试，请参考使用Docker Compose快速部署，如果对Docker不熟悉，那就用二进制方式部署，也非常简单，最小的可运行环境是Prometheus+MySQL+Redis+Nightingale，请参考快速在生产环境部署启动单机版。这个最小的环境只有Prometheus采集到的自身的一些监控指标，略显单薄，此时，我们可以引入Telegraf，采集机器、网络设备、各类中间件的指标，请参考使用Telegraf采集监控数据。
如果公司体量很大，建议把单机版本的Prometheus替换为VictoriaMetrics，请参考使用VictoriaMetrics作为时序库。或者直接部署多个Prometheus，按照业务线或者按照地域来划分集群，此时你可能需要接入多个Prom/VM/M3DB集群，在引入多个TSDB的过程中，就要同步使用夜莺的多Server部署模型了，请参考生产环境部署高可用集群版</description>
    </item>
    <item>
      <title>功能介绍</title>
      <link>https://n9e.github.io/usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/usage/</guid>
      <description>人员组织 虽然人员组织这个菜单是放到了最后，但是文档里还是要先讲一下，绝大部分功能都依赖业务组这个概念。不过一旦业务组创建完成，就基本不怎么变动操作了，所以菜单放到了后面。
用户管理 简单，就是管理系统中的所有用户，系统默认会初始化进去一个root账号，这个root账号是个管理角色，可以创建其他普通用户、修改其他用户的信息。用户认证也可以对接LDAP，这样就无需管理员去创建用户了，LDAP的配置在webapi.conf中。
团队管理 团队就是用户组，包含多个用户。主要有两个作用：1、作为告警接收组，配置告警规则的时候，可以通过指定告警接收组的方式告诉系统当发生告警的时候通知哪些人；2、管理业务组，业务组下可以有多个团队，有的团队是ro权限，即只读，有的是rw权限，即读写权限。
业务组管理 业务组相当于一个namespace，下面可以包含用户组、监控对象、告警规则、订阅规则、屏蔽规则、监控大盘、自愈脚本等，是一个可以自闭环的组织，类似一个BU，或者大的业务线。当然，一些小的组织，如果管理（主要是指管理监控对象、告警规则等）上可以自闭环（无需假手其他团队，自己这个团队就能搞定），也可以创建一个单独的业务组。比如夜莺研发团队，管理了100台机器，部署了夜莺的服务，这些机器、这些服务/机器的告警规则都是夜莺研发团队自己搞，那完全可以创建一个夜莺的业务组自己去管理。
对象管理 对象管理主要是针对机器和网络设备的管理，如果监控数据推送给n9e-server，n9e-server会从监控数据结构中解析出监控对象的标识信息（标签中的ident或host字段），然后把监控对象信息写入数据库，之后，用户可以在对象管理页面，对监控对象做管理：包括分配这些对象给指定的业务组、给这些监控对象设置标签、修改备注等。
这个版本的夜莺，取消了之前版本的树状结构，主要是靠业务组+标签的方式来配合解决机器分组的问题，关于这块的设计，有一篇文章来专门探讨：《探讨业务组的设计和最佳实践》
监控看图 为了让大家尽量用一个平台搞定监控告警的所有事情，夜莺中内置了查看监控数据的能力，包括即时查询（就是类似PromDash的看图能力）、监控大盘（是类似Grafana的Dashboard配置，不过图表类型支持较少）、对象视角看图（是一个先选择监控对象再看相关监控数据的特殊视角，运维工程师会很喜欢）
即时查询 解决以下问题：
 检查某个监控数据是否在正常上报 测试promql，测试好的promql用于配置告警规则 生产环境故障，临时查一些监控指标的数据  监控大盘 解决以下问题：
 日常巡检 知识传递，由专业的人做好大盘，新同事看这些大盘能更便于理解和达成监控目标 生产环境故障，查看监控数据  对象视角 在夜莺系统里，认为监控对象是个很关键的概念，值得赋予一定的管理功能。比如很多监控数据都隶属于某个监控对象，比如某个机器的磁盘利用率，或者某个交换机的某个网口的流量，那在查看这些监控数据的时候，我们会倾向于先找到对应的监控对象，再根据监控对象查找相关监控指标。对象视角的看图方式，就是为此而生。
什么样的监控数据认为是隶属于某个监控对象的？就看监控数据中是否有ident这个tag，如果有，就认为ident指定的是监控对象的标识，就认为这条监控数据是关联到某个监控对象的，当然，Telegraf采集的监控数据，会打上host标签，标识这个监控数据是来自哪个机器，host这个标签会被夜莺rename成ident。
告警管理 夜莺对告警的处理，分为3个规则的管理：告警规则、屏蔽规则、订阅规则；活跃告警和历史告警的展示；以及告警自愈。
告警规则 最主要用的是告警规则，用于配置告警阈值，有些监控数据可能不想告警，比如有规划的维护周期，可以配置屏蔽规则，某个告警除了某个组的人关心，可能其他人也关心，就配置订阅规则，比如K8S平台的运维人员要作为告警接收人来接收所有K8S的告警，但是K8S的一些重大网络故障会影响整个K8S集群，上层业务也会关心这类告警，此时业务方就可以订阅K8S集群的部分重大告警。
对于订阅规则，还有一种场景，比如运维团队管理了公司所有的告警规则，比如内存利用率的告警，不同业务线的人只关心自己的，那不同业务线的人就可以通过订阅规则，只订阅自己业务线的机器的告警。只需简单的为这批机器打上业务线标签，就可以通过这些标签做过滤。
告警事件 活跃告警，即当前未恢复的告警，这个信息很关键，通常每天都要巡检，甚至投到作战大屏上，时刻关注；历史告警，就是所有历史告警，包括报警消息和恢复消息，算是一个存档。
告警自愈 告警自愈是类似夜莺v4里边的job平台，可以在告警发生的时候，自动触发某个脚本的执行，比如某个宿主机报警说硬盘不够用，可以自动跑个脚本清理一下无用的数据，比如K8S宿主机的话，可以清理一些没用的镜像。</description>
    </item>
    <item>
      <title>夜莺实战</title>
      <link>https://n9e.github.io/best-practice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/best-practice/</guid>
      <description>大家对产品功能有哪些疑问可以告诉我们，我们补充到最佳实践章节。</description>
    </item>
    <item>
      <title>API</title>
      <link>https://n9e.github.io/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/api/</guid>
      <description>对于监控系统的API，通常有如下几个使用场景：1、读写监控数据 2、以个人用户身份调用API做一些操作，不想去WEB上操作 3、第三方系统调用监控的API做包装，用户在第三方系统操作，实际这个第三方系统底层是调用的监控的接口。
1.读写监控数据 对于这个场景，大家可以直接绕过夜莺，调用后端时序库的读写接口。对于写监控数据而言，如果想要走夜莺的接口，请调用n9e-server的/opentsdb/put接口，POST方法，该接口实现了OpenTSDB的数据协议，监控数据做成JSON放到HTTP Request Body中，举例：
[ { &amp;#34;metric&amp;#34;: &amp;#34;cpu_usage_idle&amp;#34;, &amp;#34;timestamp&amp;#34;: 1637732157, &amp;#34;tags&amp;#34;: { &amp;#34;cpu&amp;#34;: &amp;#34;cpu-total&amp;#34;, &amp;#34;ident&amp;#34;: &amp;#34;c3-ceph01.bj&amp;#34; }, &amp;#34;value&amp;#34;: 30.5 }, { &amp;#34;metric&amp;#34;: &amp;#34;cpu_usage_util&amp;#34;, &amp;#34;timestamp&amp;#34;: 1637732157, &amp;#34;tags&amp;#34;: { &amp;#34;cpu&amp;#34;: &amp;#34;cpu-total&amp;#34;, &amp;#34;ident&amp;#34;: &amp;#34;c3-ceph01.bj&amp;#34; }, &amp;#34;value&amp;#34;: 69.5 } ] 显然，JSON最外层是个数组，如果只上报一条监控数据，也可以不要外面的中括号，直接把对象结构上报：
{ &amp;#34;metric&amp;#34;: &amp;#34;cpu_usage_idle&amp;#34;, &amp;#34;timestamp&amp;#34;: 1637732157, &amp;#34;tags&amp;#34;: { &amp;#34;cpu&amp;#34;: &amp;#34;cpu-total&amp;#34;, &amp;#34;ident&amp;#34;: &amp;#34;c3-ceph01.bj&amp;#34; }, &amp;#34;value&amp;#34;: 30.5 } 服务端会看第一个字符是否是[，来判断上报的是数组，还是单个对象，自动做相应的Decode。如果觉得上报的内容太过占用带宽，也可以做gzip压缩，此时上报的数据，要带有Content-Encoding: gzip的Header。
Info注意ident这个标签，ident是identity的缩写，表示设备的唯一标识，如果标签中有ident标签，n9e-server就认为这个监控数据是来自某个机器的，会自动获取ident的value，注册到监控对象的列表里，这样后续就可以在对象看图视角页面根据监控对象筛选指标了。
如果没有ident这个标签，就没法在对象视角的看图页面筛选看图了，只能去即时查询页面通过promql查询。
 OK，上面是推送监控数据的接口，至于查询监控数据，请大家直接调用后端时序库的接口，即Prometheus那些/api/v1/query /api/v1/query_range之类的接口。相关接口文档请参考：Prometheus官网
2.以个人身份模仿WEB操作 这种方式，页面上JavaScript可以调用的所有接口，你都可以用程序调用，打开chrome的开发者工具，扒拉这些接口，还是非常容易的。当然，要先登录，登录调用webapi模块的/api/n9e/auth/login接口，系统使用jwt认证，如果登录成功，会返回access_token和refresh_token，每次调用的时候都要把access_token放到Header里，access_token差不多15分钟过期，之后可以重新调用登录接口换token，也可以调用/api/n9e/auth/refresh接口用refresh_token换一个新的access_token，当然，也会顺道返回一个新的refresh_token，举例：
# 调用登录接口拿到access_token和refresh_token记录下来，后面调用其他接口的时候会用到 [root@10-255-0-34 ~]# curl -X POST &amp;#39;http://localhost:18000/api/n9e/auth/login&amp;#39; -d &amp;#39;{&amp;#34;username&amp;#34;: &amp;#34;root&amp;#34;, &amp;#34;password&amp;#34;: &amp;#34;root.</description>
    </item>
    <item>
      <title>FAQ</title>
      <link>https://n9e.github.io/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/faq/</guid>
      <description>多集群部署的时候MySQL、Redis分别部署几个？   公众号有个视频讲解了 如何接入多个时序存储， 请先查看。MySQL是只需要一个，不管部署多少个n9e-webapi多少个n9e-server。redis也可以只用一个，所有的n9e-webapi和n9e-server共享，但是，如果部署多套n9e-server（一套n9e-server可能是多个n9e-server实例组成一个集群）分布在不同的地域，网络链路可能不太好，此时是建议一套n9e-server对应一个redis，n9e-webapi自己用一个redis
 架构中可以完全不用Prometheus吗？   原理上是可以的，Prometheus在夜莺的架构中，是作为时序库使用，除了Prometheus，也可以使用VictoriaMetrics、M3DB等，因为这些时序库都实现了Prometheus的Querier接口，而夜莺依赖这些接口拉取监控数据和做告警判断。
 机器只能归属一个业务组吗？   是的。
用户可能会继续追问：一台机器可能有混部的情况，同时部署多个服务，那如何来描述这种现实（毕竟，软件就是对现实的建模）呢？其实，这种关联信息在监控中是使用标签来反映的。比如某个监控数据带有这几个标签：host=cs-node001.hna service=n9e-server method=get api=/ping statuscode=200 表示：这个监控数据是n9e-server这个服务的，来自cs-node001.hna这个机器，这条监控数据描述的是/ping接口，/ping接口是个get接口，statuscode是200，这个信息非常丰富，里边既有服务名称，又有机器信息，通过这种方式我们就知道服务和机器的关联关系。
大家不要把CMDB中的机器分组需求放到夜莺中来维护，这是职责上的错配。
那为何还要提供业务组这个概念？岂不是多余了？业务组更多的是想处理权限的问题，比如我们的告警规则、屏蔽规则、订阅规则、监控大盘、自愈脚本等，只能由我们自己管理，不能被无关人员修改了或删除了。把这些规则类信息放到某个业务组中，只有这个业务组的管理员有权限管理，其他人就没有权限乱搞了。
那机器为何要归属业务组？其实也是从权限上考虑的，自愈脚本是归属业务组的，脚本的执行需要有权限控制，不能随便去机器上运行，现在的控制逻辑是脚本只能在自己的业务组下辖的机器上运行。
综上，坦白讲，我没有想到什么场景是必须让机器（即系统中的监控对象）归属到多个业务组的。关键原因是监控数据上报的时候就是自描述的，已经包含了各类信息了，不需要通过外挂的方式重新归类监控数据，而机器的分组，虽然有需求，但那是CMDB的需求，也不是监控要处理的。
更新：另外，机器（即系统中的监控对象）可以打标签，可以通过标签体现一定的分类信息，比如region=bj env=prod表示bj区的生产环境的机器。标签是K=V的格式，K可以体现维度信息，大部分归类需求都可以通过标签来解决，唯独比较麻烦的是，在同一个维度有多个值的情况，比如K=V1 K=V2这种情况，这种情况目前不支持，因为标签信息会被附到监控对象的时序数据上，时序数据的标签是map结构，所以K=V1 K=V2这种K相同的情况会产生覆盖，故而页面上监控对象打标签的时候压根就不允许这种标签。
 为何我的target_up指标一会是0一会是1，导致一会有告警一会又恢复了   这个很可能是因为调整了客户端采集上报频率导致的，默认Telegraf上报频率是10s，不会有这个问题，n9e-server每15s生成一次target_up的值，标识机器是否在正常上报数据，如果发现机器有指标在上报，target_up就置为1，否则就是0，如果把客户端采集上报频率调大，比如改成60s，那n9e-server在某些周期检查的时候，确实就发现客户端没有上报数据，毕竟上报频率太大了。此时可以调整server.conf的配置，把检测客户端是否存活的周期也放大一些，比如调整为60秒：
[NoData] Metric = &amp;#34;target_up&amp;#34; # unit: second Interval = 60 告警规则也可以针对这种情况做一些调整，比如改成：
# 告警规则的持续时长设置为0，该PromQL表示130s内一直都没有监控数据上报，故而要报警。 max_over_time(target_up[130s]) == 0 target_up指标是0，还有可能的原因是客户端夯住了，可以重启一下客户端试试，或者是客户端所在机器当前压力过大，影响了客户端到服务端的网络通信。
 夜莺用的redis支持cluster版本或者sentinel版本吗？   不支持，就是用的单机版，改造成cluster版本或者sentinel应该也没啥太大问题，一般公有云会提供高可用的redis，一主一从那种，足够用了，自己搭建也可以，机器挂掉的概率其实很小，满足sla问题不大的
 Telegraf上报的主机标识默认用的机器名，可以让它自动上报IP作为本机标识吗？   可以让它上报IP作为唯一标识，但是要想自动获取IP，做不到。个人建议是使用一些批量执行工具，比如ansible之类的，批量部署Telegraf，部署脚本里自动获取目标机器的IP，然后填充到telegraf.conf中。
 触发告警和触发恢复的逻辑是什么？   告警规则里有3个配置非常关键，promql、执行频率、持续时长，意思就是按照执行频率，每隔一段时间执行promql查询（即时查询，即调用Prometheus协议的/api/v1/query接口），如果查到数据就认为触发了阈值，触发了阈值是否会产生告警事件，不一定，还要看持续时长，如果持续时长为0，就相当于不用等待，触发了阈值就立马生成事件，如果持续时长大于0，那就要等待，要保证持续时长这段时间内，每次执行promql的查询都触发阈值，才认为应该生成事件。持续时长就相当于prometheus.yml中的alert rule中的for。</description>
    </item>
    <item>
      <title>社区用户实践分享</title>
      <link>https://n9e.github.io/usecase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/usecase/</guid>
      <description> Telegraf Windows版本的安装，保姆级教程 - by SL Telegraf Linux版本的安装，保姆级教程 - by SL 弃用Prometheus，搭建单机版本的VictoriaMetrics - by SL 一键部署夜莺到Kubernetes - by 陶柒 使用Telegraf做夜莺5.0的数据采集，样例包含Linux基本信息采集、MySQL、Redis的采集 - by 柴今栋@艾派 修改notify.py为夜莺增加短信通知能力 - by 柴今栋@艾派 使用notify.py接入阿里云语音通知 - by 果 Oracle的简单监控实现 - by 柴今栋@艾派 RocketMQ简单监控的实现 - by 柴今栋@艾派 手把手教你接入钉钉告警 一文说透MySQL监控，使用Prometheus生态的Exporter  </description>
    </item>
  </channel>
</rss>