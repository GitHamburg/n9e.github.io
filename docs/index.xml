<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>夜莺手册 on N9E</title>
    <link>https://n9e.github.io/</link>
    <description>Recent content in 夜莺手册 on N9E</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://n9e.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>安装部署</title>
      <link>https://n9e.github.io/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/quickstart/</guid>
      <description>如果您对Docker的使用非常熟悉，建议利用Docker compose的方式快速启动测试，请参考使用Docker Compose快速部署，如果对Docker不熟悉，那就用二进制方式部署，也非常简单，最小的可运行环境是Prometheus+MySQL+Redis+Nightingale，请参考快速在生产环境部署启动单机版。这个最小的环境只有Prometheus采集到的自身的一些监控指标，略显单薄，此时，我们可以引入Telegraf，采集机器、网络设备、各类中间件的指标，请参考使用Telegraf采集监控数据。
如果您运行和维护着K8s集群，并且希望把Nightingale部署到K8s中，我们推荐您使用n9e-helm-chart来部署、升级、管理。
如果公司体量很大，建议把单机版本的Prometheus替换为VictoriaMetrics，请参考使用VictoriaMetrics作为时序库。或者直接部署多个Prometheus，按照业务线或者按照地域来划分集群，此时你可能需要接入多个Prom/VM/M3DB集群，在引入多个TSDB的过程中，就要同步使用夜莺的多Server部署模型了，请参考生产环境部署高可用集群版。</description>
    </item>
    <item>
      <title>功能介绍</title>
      <link>https://n9e.github.io/usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/usage/</guid>
      <description>请参考如下视频教程：
 01-使用Docker Compose一行命令安装夜莺v5 02-快速在生产环境部署启动单机版夜莺v5 03-讲解夜莺v5人员组织相关功能 04-讲解夜莺v5监控看图相关功能 05-讲解夜莺v5告警规则的使用 06-讲解夜莺v5告警屏蔽规则的使用 07-讲解夜莺告警订阅规则的使用 08-讲解夜莺v5活跃告警和历史告警 09-讲解夜莺v5告警自愈脚本的使用 10-讲解夜莺监控对象的管理功能 11-夜莺v5如何接入多个时序存储 12-讲解夜莺v5配置文件  使用 Telegraf 采集监控数据，可以参考如下调研笔记：
 Telegraf监控客户端调研笔记（1）-介绍、安装、初步测试 Telegraf监控客户端调研笔记（2）-CPU、MEM、DISK、IO相关指标采集 Telegraf监控客户端调研笔记（3）-kernel、system、processes相关指标采集 Telegraf监控客户端调研笔记（4）-exec、net、netstat相关指标采集 Telegraf监控客户端调研笔记（5）-本地端口监控&amp;amp;远程TCP探测 Telegraf监控客户端调研笔记（6）-PING监控、进程监控  如果仍然有使用问题，可以联系我们，联系方式如下，公众号：</description>
    </item>
    <item>
      <title>API</title>
      <link>https://n9e.github.io/api/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/api/</guid>
      <description></description>
    </item>
    <item>
      <title>FAQ</title>
      <link>https://n9e.github.io/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/faq/</guid>
      <description>多集群部署的时候MySQL、Redis分别部署几个？   公众号有个视频讲解了 如何接入多个时序存储， 请先查看。MySQL是只需要一个，不管部署多少个n9e-webapi多少个n9e-server。redis也可以只用一个，所有的n9e-webapi和n9e-server共享，但是，如果部署多套n9e-server（一套n9e-server可能是多个n9e-server实例组成一个集群）分布在不同的地域，网络链路可能不太好，此时是建议一套n9e-server对应一个redis，n9e-webapi自己用一个redis
 架构中可以完全不用Prometheus吗？   原理上是可以的，Prometheus在夜莺的架构中，是作为时序库使用，除了Prometheus，也可以使用VictoriaMetrics、M3DB等，因为这些时序库都实现了Prometheus的Querier接口，而夜莺依赖这些接口拉取监控数据和做告警判断。
 机器只能归属一个业务组吗？   是的。
用户可能会继续追问：一台机器可能有混部的情况，同时部署多个服务，那如何来描述这种现实（毕竟，软件就是对现实的建模）呢？其实，这种关联信息在监控中是使用标签来反映的。比如某个监控数据带有这几个标签：host=cs-node001.hna service=n9e-server method=get api=/ping statuscode=200 表示：这个监控数据是n9e-server这个服务的，来自cs-node001.hna这个机器，这条监控数据描述的是/ping接口，/ping接口是个get接口，statuscode是200，这个信息非常丰富，里边既有服务名称，又有机器信息，通过这种方式我们就知道服务和机器的关联关系。
大家不要把CMDB中的机器分组需求放到夜莺中来维护，这是职责上的错配。
那为何还要提供业务组这个概念？岂不是多余了？业务组更多的是想处理权限的问题，比如我们的告警规则、屏蔽规则、订阅规则、监控大盘、自愈脚本等，只能由我们自己管理，不能被无关人员修改了或删除了。把这些规则类信息放到某个业务组中，只有这个业务组的管理员有权限管理，其他人就没有权限乱搞了。
那机器为何要归属业务组？其实也是从权限上考虑的，自愈脚本是归属业务组的，脚本的执行需要有权限控制，不能随便去机器上运行，现在的控制逻辑是脚本只能在自己的业务组下辖的机器上运行。
综上，坦白讲，我没有想到什么场景是必须让机器（即系统中的监控对象）归属到多个业务组的。关键原因是监控数据上报的时候就是自描述的，已经包含了各类信息了，不需要通过外挂的方式重新归类监控数据，而机器的分组，虽然有需求，但那是CMDB的需求，也不是监控要处理的。
更新：另外，机器（即系统中的监控对象）可以打标签，可以通过标签体现一定的分类信息，比如region=bj env=prod表示bj区的生产环境的机器。标签是K=V的格式，K可以体现维度信息，大部分归类需求都可以通过标签来解决，唯独比较麻烦的是，在同一个维度有多个值的情况，比如K=V1 K=V2这种情况，这种情况目前不支持，因为标签信息会被附到监控对象的时序数据上，时序数据的标签是map结构，所以K=V1 K=V2这种K相同的情况会产生覆盖，故而页面上监控对象打标签的时候压根就不允许这种标签。
 为何我的target_up指标一会是0一会是1，导致一会有告警一会又恢复了   这个很可能是因为调整了客户端采集上报频率导致的，默认Telegraf上报频率是10s，不会有这个问题，n9e-server每15s生成一次target_up的值，标识机器是否在正常上报数据，如果发现机器有指标在上报，target_up就置为1，否则就是0，如果把客户端采集上报频率调大，比如改成60s，那n9e-server在某些周期检查的时候，确实就发现客户端没有上报数据，毕竟上报频率太大了。此时可以调整server.conf的配置，把检测客户端是否存活的周期也放大一些，比如调整为60秒：
[NoData] Metric = &amp;#34;target_up&amp;#34; # unit: second Interval = 60 告警规则也可以针对这种情况做一些调整，比如改成：
# 告警规则的持续时长设置为0，该PromQL表示130s内一直都没有监控数据上报，故而要报警。 max_over_time(target_up[130s]) == 0 target_up指标是0，还有可能的原因是客户端夯住了，可以重启一下客户端试试，或者是客户端所在机器当前压力过大，影响了客户端到服务端的网络通信。
 夜莺用的redis支持cluster版本或者sentinel版本吗？   不支持，就是用的单机版，改造成cluster版本或者sentinel应该也没啥太大问题，一般公有云会提供高可用的redis，一主一从那种，足够用了，自己搭建也可以，机器挂掉的概率其实很小，满足sla问题不大的
 Telegraf上报的主机标识默认用的机器名，可以让它自动上报IP作为本机标识吗？   可以让它上报IP作为唯一标识，但是要想自动获取IP，做不到。个人建议是使用一些批量执行工具，比如ansible之类的，批量部署Telegraf，部署脚本里自动获取目标机器的IP，然后填充到telegraf.conf中。
 触发告警和触发恢复的逻辑是什么？   告警规则里有3个配置非常关键，promql、执行频率、持续时长，意思就是按照执行频率，每隔一段时间执行promql查询（即时查询，即调用Prometheus协议的/api/v1/query接口），如果查到数据就认为触发了阈值，触发了阈值是否会产生告警事件，不一定，还要看持续时长，如果持续时长为0，就相当于不用等待，触发了阈值就立马生成事件，如果持续时长大于0，那就要等待，要保证持续时长这段时间内，每次执行promql的查询都触发阈值，才认为应该生成事件。持续时长就相当于prometheus.yml中的alert rule中的for。</description>
    </item>
    <item>
      <title>社区用户实践分享</title>
      <link>https://n9e.github.io/usecase/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/usecase/</guid>
      <description> Telegraf Windows版本的安装，保姆级教程 - by SL Telegraf Linux版本的安装，保姆级教程 - by SL 弃用Prometheus，搭建单机版本的VictoriaMetrics - by SL 一键部署夜莺到Kubernetes - by 陶柒 使用Telegraf做夜莺5.0的数据采集，样例包含Linux基本信息采集、MySQL、Redis的采集 - by 柴今栋@艾派 telegraf常用中间件采集 修改notify.py为夜莺增加短信通知能力 - by 柴今栋@艾派 使用notify.py接入阿里云语音通知 - by 果 Oracle的简单监控实现 - by 柴今栋@艾派 RocketMQ简单监控的实现 - by 柴今栋@艾派 手把手教你接入钉钉告警 一文说透MySQL监控，使用Prometheus生态的Exporter Vsphere-monitor数据上报夜莺V5监控 使用pg作为数据库替换MySQL  </description>
    </item>
    <item>
      <title>使用Grafana-agent采集监控数据</title>
      <link>https://n9e.github.io/grafana-agent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://n9e.github.io/grafana-agent/</guid>
      <description>Acknowledgement: Grafana Agent is a lightweight telemetry collector based on Prometheus that only performs its scraping and remote_write functions. Agent can also collect metrics, logs, and traces for storage in Grafana Cloud and Grafana Enterprise, as well as OSS deployments of Loki (logs), and Tempo (traces), Prometheus (metrics), and Cortex (metrics). Grafana Agent also contains several integrations (embedded metrics exporters) like node-exporter, a MySQL exporter, and many more.
 如果您使用和管理着Kubernetes集群以及您的应用运行在Kubernetes之上，请参考 在K8s中使用grafana-agent。</description>
    </item>
  </channel>
</rss>